---
layout: default
title: Validations_Report 
parent: Validations
nav_order: 5
has_children: false
---

<h1>HostOS Validation Report</h1>

<div class="grid-container">
    <div class="grid-item"><p>Mzone</p><h5>mzone2114</h5></div>
    <div class="grid-item"><p>Release Bundle</p><h5>hostos-validate-release:2.1.1-20241217T162402Z_6c81899</h5></div>
    <div class="grid-item"><p>Payload Version</p><h5>1.0.0-e5d742db</h5></div>
    <div class="grid-item"><p>Tool Version</p><h5>1.0.0-e4556a2</h5></div>
</div>

<table id="myTable" class="styled-table">
  <tr>
    <th>Test Case<i onclick="sortTable(0)" class="fa fa-sort sort-btn"></i></th>
    <th>Status<i onclick="sortTable(1)" class="fa fa-sort sort-btn"></i></th>
    <th>Start Time<i onclick="sortTable(2)" class="fa fa-sort sort-btn"></i></th>
    <th>Duration (Seconds)<i onclick="sortTable(3)" class="fa fa-sort sort-btn"></i></th>
    <th>Node<i onclick="sortTable(4)" class="fa fa-sort sort-btn"></i></th>
    <th>OS<i onclick="sortTable(5)" class="fa fa-sort sort-btn"></i></th>
  </tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:39:52.668898</td>
    <td>1.27</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:52.668882</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:39:52.668892</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:39:52.668896</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:52.668941</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:39:52.668946</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:39:52.668949</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:39:53.942484</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     836K  107M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      35M  114G KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3     836K  107M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4      35M  114G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5      36M  115G HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     119K 7313K KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2     119K 7313K KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3      35M  639G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4      36M  639G HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    2939K  325M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      11M 3964M KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3    2928K  324M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4    2928K  324M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5    2928K  324M DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
6    2928K  324M DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
7        0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
8        0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0           
9        0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0           
10       0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0           
11       0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
12   2928K  324M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 2 packets, 144 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      680  346K KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      618  341K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      680  346K KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      618  341K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5      991  502K HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     1128 79968 KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4     1264 87624 HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2     1190 69328 KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     1190 69328 HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION                                                                   
  acpid.service                        loaded    inactive dead    ACPI event daemon                                                             
# am-utils.service                     not-found inactive dead    am-utils.service                                                              
# apache2.service                      not-found inactive dead    apache2.service                                                               
  apparmor.service                     loaded    active   exited  AppArmor initialization                                                       
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities                                        
# apt-daily.service                    masked    inactive dead    apt-daily.service                                                             
# atd.service                          not-found inactive dead    atd.service                                                                   
  auditd.service                       loaded    active   running Security Auditing Service                                                     
  auth-rpcgss-module.service           loaded    inactive dead    Kernel Module supporting RPCSEC_GSS                                           
  autofs.service                       loaded    active   running Automounts filesystems on demand                                              
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats                       
  blk-availability.service             loaded    active   exited  Availability of block devices                                                 
  ceph-crash.service                   loaded    active   running Ceph crash dump collector                                                     
# citadel.service                      not-found inactive dead    citadel.service                                                               
  cld-blockagent-server.service        loaded    active   running Genesis block-agent Service                                                   
  cld-coalesce-agent-nr.service        loaded    active   running Genesis coalesce-agent-nr Service                                             
  cld-coalesce-agent.service           loaded    active   running Genesis coalesce-agent Service                                                
  cld-computeproxy.service             loaded    active   running Genesis computeproxy Service                                                  
  cld-consolemultiplexer.service       loaded    active   running Console Multiplexer Service                                                   
  cld-cos-transfer-agent-nr.service    loaded    active   running Genesis cos-transfer-agent-nr Service                                         
  cld-cos-transfer-agent.service       loaded    active   running Genesis cos-transfer-agent Service                                            
  cld-guest-proxy.service              loaded    active   running Instance Metadata Service                                                     
  cld-net-block-agent.service          loaded    active   running Genesis net-block-agent Service                                               
  cld-threadbare.service               loaded    active   running threadbare sets CPU process pin policy via sched_setaffinity for compute nodes
  cloudnet-gobgp.service               loaded    inactive dead    gobgpd service                                                                
  containerd.service                   loaded    active   running containerd container runtime                                                  
# courier-ldap.service                 not-found inactive dead    courier-ldap.service                                                          
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service                                                       
# courier-mta.service                  not-found inactive dead    courier-mta.service                                                           
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service                                                       
# courier-pop.service                  not-found inactive dead    courier-pop.service                                                           
  cron.service                         loaded    active   running Regular background program processing daemon                                  
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service                                                           
  dbus.service                         loaded    active   running D-Bus System Message Bus                                                      
# display-manager.service              not-found inactive dead    display-manager.service                                                       
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon                                                    
  docker.service                       loaded    active   running Docker Application Container Engine                                           
# dovecot.service                      not-found inactive dead    dovecot.service                                                               
  ebtables.service                     loaded    active   exited  ebtables ruleset management                                                   
  emergency.service                    loaded    inactive dead    Emergency Shell                                                               
# exim4.service                        not-found inactive dead    exim4.service                                                                 
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service                                     
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.       
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor                                                     
# fcoe.service                         not-found inactive dead    fcoe.service                                                                  
# firewalld.service                    not-found inactive dead    firewalld.service                                                             
  frr.service                          loaded    active   running FRRouting                                                                     
  fstrim.service                       loaded    inactive dead    Discard unused blocks                                                         
# gdm3.service                         not-found inactive dead    gdm3.service                                                                  
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available                       
  getty@tty1.service                   loaded    active   running Getty on tty1                                                                 
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes                                     
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service                                                  
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service                                                           
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service                                                           
  hmonagent-mlx.service                loaded    active   running Genesis Fabric-3 Health Monitor Agent                                         
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device           
  irqbalance.service                   loaded    active   running irqbalance daemon                                                             
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service                                                        
# iscsi.service                        not-found inactive dead    iscsi.service                                                                 
# iscsid.service                       not-found inactive dead    iscsid.service                                                                
# kdm.service                          not-found inactive dead    kdm.service                                                                   
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service                                             
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec                                             
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system                            
# keylime_agent.service                masked    inactive dead    keylime_agent.service                                                         
  kmod-static-nodes.service            loaded    active   exited  Create list of required static device nodes for the current kernel            
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service                                                    
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service                                                              
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster                                                  
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent                                            
  libvirt-guests.service               loaded    active   exited  Suspend/Resume Running libvirt Guests                                         
  libvirtd.service                     loaded    active   running Virtualization daemon                                                         
  lldpd.service                        loaded    active   running LLDP daemon                                                                   
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service                                                       
  lvm2-lvmetad.service                 loaded    active   running LVM2 metadata daemon                                                          
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon                                                              
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service                                                  
# masqmail.service                     not-found inactive dead    masqmail.service                                                              
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.                       
  motd-news.service                    loaded    inactive dead    Message of the Day                                                            
  mst.service                          loaded    active   exited  LSB: mst                                                                      
  nessusagent.service                  loaded    active   running The Nessus Client Agent                                                       
# network.service                      not-found inactive dead    network.service                                                               
  networking.service                   loaded    inactive dead    Raise network interfaces                                                      
  nfs-blkmap.service                   loaded    inactive dead    pNFS block layout mapping daemon                                              
  nfs-config.service                   loaded    inactive dead    Preprocess NFS configuration                                                  
  nfs-idmapd.service                   loaded    inactive dead    NFSv4 ID-name mapping service                                                 
  nfs-mountd.service                   loaded    inactive dead    NFS Mount Daemon                                                              
  nfs-server.service                   loaded    inactive dead    NFS server and services                                                       
  nfs-utils.service                    loaded    active   exited  NFS server and client services                                                
  nftables.service                     loaded    active   exited  nftables                                                                      
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon                                                   
# nullmailer.service                   not-found inactive dead    nullmailer.service                                                            
  osqueryd.service                     loaded    active   running The osquery Daemon                                                            
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service                                                    
# plymouth-start.service               not-found inactive dead    plymouth-start.service                                                        
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics                                       
  qemu-kvm.service                     loaded    active   exited  QEMU KVM preparation - module, ksm, hugepages                                 
  rbdmap.service                       loaded    active   exited  Map RBD devices                                                               
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility                                                   
  rclone-agent@rclone-agent.service    loaded    inactive dead    rclone wrapper agent service                                                  
  rclone-validate.service              loaded    inactive dead    Rclone config validator service                                               
  rescue.service                       loaded    inactive dead    Rescue Shell                                                                  
  rpc-gssd.service                     loaded    active   running RPC security service for NFS client and server                                
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart                                                 
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.                                       
  rpc-svcgssd.service                  loaded    inactive dead    RPC security service for NFS server                                           
  rpcbind.service                      loaded    inactive dead    RPC bind portmap service                                                      
  rsync.service                        loaded    inactive dead    fast remote file copy program daemon                                          
  rsyslog.service                      loaded    active   running System Logging Service                                                        
# sendmail.service                     not-found inactive dead    sendmail.service                                                              
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0                                                         
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1                                                         
# set-hostname.service                 not-found inactive dead    set-hostname.service                                                          
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service                                                            
  skydive.service                      loaded    active   running Skydive                                                                       
# slapd.service                        not-found inactive dead    slapd.service                                                                 
# slim.service                         not-found inactive dead    slim.service                                                                  
  smartd.service                       loaded    inactive dead    Self Monitoring and Reporting Technology (SMART) Daemon                       
  ssh.service                          loaded    active   running OpenBSD Secure Shell server                                                   
# sssd.service                         not-found inactive dead    sssd.service                                                                  
  strongswan.service                   loaded    active   running strongSwan IPsec IKEv1/IKEv2 daemon using ipsec.conf                          
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console                                         
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall                                             
  systemd-binfmt.service               loaded    inactive dead    Set Up Additional Binary Formats                                              
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device                                              
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status                                     
  systemd-hwdb-update.service          loaded    inactive dead    Rebuild Hardware Database                                                     
  systemd-initctl.service              loaded    inactive dead    /dev/initctl Compatibility Daemon                                             
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage                                           
  systemd-journald.service             loaded    active   running Journal Service                                                               
  systemd-logind.service               loaded    active   running Login Service                                                                 
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk                                         
  systemd-machined.service             loaded    active   running Virtual Machine and Container Registration Service                            
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules                                                           
  systemd-networkd-wait-online.service loaded    active   exited  Wait for Network to be Configured                                             
  systemd-networkd.service             loaded    active   running Network Service                                                               
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed                                                         
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems                                          
  systemd-resolved.service             loaded    active   running Network Name Resolution                                                       
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables                                                        
# systemd-sysusers.service             not-found inactive dead    systemd-sysusers.service                                                      
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization                                                  
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories                                              
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev                                            
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories                                         
  systemd-udev-trigger.service         loaded    active   exited  udev Coldplug all Devices                                                     
  systemd-udevd.service                loaded    active   running udev Kernel Device Manager                                                    
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service                                                   
  systemd-update-utmp-runlevel.service loaded    inactive dead    Update UTMP about System Runlevel Changes                                     
  systemd-update-utmp.service          loaded    active   exited  Update UTMP about System Boot/Shutdown                                        
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions                                                          
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service                                                
  taniumclient.service                 loaded    active   running Tanium Client                                                                 
  user@1000.service                    loaded    active   running User Manager for UID 1000                                                     
  uuidd.service                        loaded    active   running Daemon for generating UUIDs                                                   
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent                                       
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent                                        
  vagentx.service                      loaded    active   running service wrapper around vault agent                                            
  virtlockd.service                    loaded    inactive dead    Virtual machine lock manager                                                  
  virtlogd.service                     loaded    active   running Virtual machine log manager                                                   
# wdm.service                          not-found inactive dead    wdm.service                                                                   
# xdm.service                          not-found inactive dead    xdm.service                                                                   
# xencommons.service                   not-found inactive dead    xencommons.service                                                            
# xendomains.service                   not-found inactive dead    xendomains.service                                                            
# ypbind.service                       not-found inactive dead    ypbind.service                                                                

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.

167 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State   Recv-Q  Send-Q         Local Address:Port      Peer Address:Port                                                                                  
udp   UNCONN  0       0                    0.0.0.0:22784          0.0.0.0:*      users:(("rpc.statd",pid=163936,fd=8))                                          
udp   UNCONN  0       0                11.50.204.2:50052          0.0.0.0:*      users:(("fabcon_server",pid=174086,fd=14))                                     
udp   UNCONN  0       0              127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=111481,fd=12))                                   
udp   UNCONN  0       0                    0.0.0.0:500            0.0.0.0:*      users:(("charon",pid=13635,fd=14))                                             
udp   UNCONN  0       0                  127.0.0.1:872            0.0.0.0:*      users:(("rpc.statd",pid=163936,fd=5))                                          
udp   UNCONN  0       0                    0.0.0.0:4500           0.0.0.0:*      users:(("charon",pid=13635,fd=15))                                             
udp   UNCONN  0       0                    0.0.0.0:4789           0.0.0.0:*                                                                                     
udp   UNCONN  0       0                       [::]:38395             [::]:*      users:(("rpc.statd",pid=163936,fd=10))                                         
udp   UNCONN  0       0                          *:500                  *:*      users:(("charon",pid=13635,fd=12))                                             
udp   UNCONN  0       0                          *:4500                 *:*      users:(("charon",pid=13635,fd=13))                                             
tcp   LISTEN  0       16384              127.0.0.1:27519          0.0.0.0:*      users:(("containerd",pid=103311,fd=14))                                        
tcp   LISTEN  0       1024             11.50.204.2:17472          0.0.0.0:*      users:(("TaniumClient",pid=14913,fd=65))                                       
tcp   LISTEN  0       1024               127.0.0.1:17473          0.0.0.0:*      users:(("TaniumClient",pid=14913,fd=67))                                       
tcp   LISTEN  0       128                  0.0.0.0:31843          0.0.0.0:*      users:(("rpc.statd",pid=163936,fd=9))                                          
tcp   LISTEN  0       16384              127.0.0.1:50055          0.0.0.0:*      users:(("fabcon_server",pid=174086,fd=18))                                     
tcp   LISTEN  0       16384              127.0.0.1:10248          0.0.0.0:*      users:(("kubelet",pid=133430,fd=19))                                           
tcp   LISTEN  0       16384              127.0.0.1:10249          0.0.0.0:*      users:(("kube-proxy",pid=114480,fd=8))                                         
tcp   LISTEN  0       3                  127.0.0.1:2601           0.0.0.0:*      users:(("zebra",pid=196563,fd=26))                                             
tcp   LISTEN  0       16384              127.0.0.1:50059          0.0.0.0:*      users:(("fabcon_server",pid=174086,fd=20))                                     
tcp   LISTEN  0       16384              127.0.0.1:9100           0.0.0.0:*      users:(("prometheus-node",pid=172097,fd=3))                                    
tcp   LISTEN  0       3                  127.0.0.1:2605           0.0.0.0:*      users:(("bgpd",pid=196568,fd=18))                                              
tcp   LISTEN  0       16384            169.254.2.2:18193          0.0.0.0:*      users:(("metadataagent",pid=179754,fd=9))                                      
tcp   LISTEN  0       16384            169.254.2.0:18065          0.0.0.0:*      users:(("metadataagent",pid=179344,fd=9))                                      
tcp   LISTEN  0       16384            169.254.2.0:18066          0.0.0.0:*      users:(("metadataagent",pid=180811,fd=9))                                      
tcp   LISTEN  0       16384            169.254.2.2:18194          0.0.0.0:*      users:(("metadataagent",pid=180778,fd=9))                                      
tcp   LISTEN  0       128                  0.0.0.0:179            0.0.0.0:*      users:(("bgpd",pid=196568,fd=22))                                              
tcp   LISTEN  0       128            127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=111481,fd=13))                                   
tcp   LISTEN  0       128                  0.0.0.0:22             0.0.0.0:*      users:(("sshd",pid=181226,fd=3))                                               
tcp   LISTEN  0       3                  127.0.0.1:2616           0.0.0.0:*      users:(("staticd",pid=196576,fd=11))                                           
tcp   LISTEN  0       1000                       *:16514                *:*      users:(("libvirtd",pid=168952,fd=5),("systemd",pid=1,fd=68))                   
tcp   LISTEN  0       128                        *:51010                *:*      users:(("guestproxysvc",pid=88337,fd=9))                                       
tcp   LISTEN  0       16384                      *:50051                *:*      users:(("fabcon_server",pid=174086,fd=21))                                     
tcp   LISTEN  0       16384                      *:50057                *:*      users:(("fabcon_server",pid=174086,fd=19))                                     
tcp   LISTEN  0       16384                      *:10250                *:*      users:(("kubelet",pid=133430,fd=16))                                           
tcp   LISTEN  0       128                     [::]:17199             [::]:*      users:(("rpc.statd",pid=163936,fd=11))                                         
tcp   LISTEN  0       16384                      *:10256                *:*      users:(("kube-proxy",pid=114480,fd=16))                                        
tcp   LISTEN  0       128       [::ffff:127.0.0.1]:10514                *:*      users:(("iobricksd",pid=72950,fd=47))                                          
tcp   LISTEN  0       128                     [::]:179               [::]:*      users:(("bgpd",pid=196568,fd=23))                                              
tcp   LISTEN  0       128                     [::]:22                [::]:*      users:(("sshd",pid=181226,fd=4))                                               

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==
#	$OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/bin:/bin:/usr/sbin:/sbin

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# PasswordAuthentication.  Depending on your PAM configuration,
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#UseLogin no
#Compression delayed
#UseDNS no
#PidFile /var/run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:

#includedir /etc/sudoers.d
Defaults use_pty
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:consolemux
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
lxd:x:104:
input:x:105:
crontab:x:106:
messagebus:x:107:
ssh:x:108:
admin:x:110:
netdev:x:111:
uuidd:x:109:
syslog:x:112:
sysop:x:1000:
rdma:x:113:
ceph:x:64045:
nslcd:x:114:
_lldpd:x:115:
kvm:x:116:consolemux
libvirt:x:200:consolemux
libvirt-qemu:x:64055:libvirt-qemu
libvirt-dnsmasq:x:118:
docker:x:999:
ssl-cert:x:119:
postfix:x:120:
postdrop:x:121:
tss:x:122:
frrvty:x:123:frr
frr:x:124:
vault:x:998:
rmds:x:997:
consolemux:x:60102:
prometheus:x:62700:
systemd-timesync:x:996:
sugroup:x:1001:
sysgt:x:1002:
no_user:x:995:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_tally2.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth  [success=2 default=ignore] pam_unix.so nullok_secure
auth  [success=1 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth  required                   pam_deny.so
auth  required                   pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900
auth  required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so remember=5
password [success=2 default=ignore] pam_unix.so obscure use_authtok try_first_pass sha512
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

session optional /usr/lib/pam_osquery.so

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows root logins except on tty\'s listed in /etc/securetty
# (Replaces the `CONSOLE\' setting from login.defs)
#
# With the default control of this module:
#   [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die]
# root will not be prompted for a password on insecure lines.
# if an invalid username is entered, a password is prompted (but login
# will eventually be rejected)
#
# You can change it to a "requisite" module if you think root may mis-type
# her login and should not be prompted for a password in that case. But
# this will leave the system as vulnerable to user enumeration attacks.
#
# You can change it to a "required" module if you think it permits to
# guess valid user names of your system (invalid user names are considered
# as possibly being root on insecure lines), but root passwords may be
# communicated over insecure lines.
auth [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die] pam_securetty.so

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/polkit-1 <==
#%PAM-1.0

@include common-auth
@include common-account
@include common-password
session       required   pam_env.so readenv=1 user_readenv=0
session       required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-session-noninteractive

==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_04_17_51 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group root
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "root" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/sudo <==
#%PAM-1.0

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/systemd-user <==
# This file is part of systemd.
#
# Used by systemd --user instances.

@include common-account

session  required pam_selinux.so close
session  required pam_selinux.so nottys open
session  required pam_loginuid.so
session  required pam_limits.so
@include common-session-noninteractive
session optional pam_systemd.so

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd:x:103:65534::/var/lib/lxd/:/bin/false
messagebus:x:105:107::/nonexistent:/usr/sbin/nologin
sshd:x:106:65534::/run/sshd:/usr/sbin/nologin
uuidd:x:107:109::/run/uuidd:/usr/sbin/nologin
syslog:x:109:112::/home/syslog:/usr/sbin/nologin
sysop:x:1000:1000::/home/sysop:/bin/bash
ceph:x:64045:64045:Ceph storage service:/var/lib/ceph:/usr/sbin/nologin
nslcd:x:104:114:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd:x:108:115::/var/run/lldpd:/usr/sbin/nologin
strongswan:x:110:65534::/var/lib/strongswan:/usr/sbin/nologin
libvirt-qemu:x:64055:116:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
libvirt-dnsmasq:x:111:118:Libvirt Dnsmasq,,,:/var/lib/libvirt/dnsmasq:/usr/sbin/nologin
postfix:x:112:120::/var/spool/postfix:/usr/sbin/nologin
statd:x:113:65534::/var/lib/nfs:/usr/sbin/nologin
tss:x:114:122:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:x:115:122:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:x:116:124:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:998::/home/vault:/bin/false
rmds:x:998:997:VPC Metadata Services:/home/rmds:/usr/sbin/nologin
consolemux:x:60101:60102:VSI Console Multiplexer account:/home/consolemux:/usr/sbin/nologin
genctl:x:60000:200:GenCTL User,,,:/home/genctl:/usr/sbin/nologin
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:x:997:996:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt:x:1001:1002::/home/sysgt:/bin/bash
no_user:x:65535:995:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
mail.*				-/var/log/mail.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.28.12504.0aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        compute-agent-vjwb4                                               3/3     Running     2 (25h ago)   25h     11.50.204.5    dal1-qz2-sr2-rk203-s12   <none>           <none>
genctl        fabcon-manager-xkwpg                                              2/2     Running     3 (25h ago)   25h     11.50.204.4    dal1-qz2-sr2-rk203-s12   <none>           <none>
genctl        fluentbit-logs-57fbs                                              4/4     Running     0             25h     11.50.204.6    dal1-qz2-sr2-rk203-s12   <none>           <none>
genctl        fluentd-qradar-ds-rz6ct                                           1/1     Running     0             25h     11.50.204.3    dal1-qz2-sr2-rk203-s12   <none>           <none>
genctl        storage-agent-ndt8g                                               2/2     Running     0             8h      11.50.204.9    dal1-qz2-sr2-rk203-s12   <none>           <none>
kube-system   kube-proxy-7lpwm                                                  1/1     Running     0             25h     10.22.64.54    dal1-qz2-sr2-rk203-s12   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
83 profiles are loaded.
52 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/process-monitoring
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /sbin/block-agent-server
   /sbin/capause
   /sbin/coalesce-agent
   /sbin/coalesce-agent-nr
   /sbin/computeproxy
   /sbin/consolemultiplexer
   /sbin/cos-transfer-agent
   /sbin/cos-transfer-agent-nr
   /sbin/dhclient
   /sbin/guestproxysvc
   /sbin/launch_rmds_agent
   /sbin/metadataagent
   /sbin/threadbare
   /usr/bin/autofs_rclone
   /usr/bin/prometheus-node-exporter
   /usr/bin/rclone-agent
   /usr/bin/rclone-configurator
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/lib/ipsec/charon
   /usr/lib/ipsec/stroke
   /usr/sbin/canonical-livepatchd
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /usr/sbin/swanctl
   /usr/sbin/tcpdump
   /{,usr/}sbin/net-block-agent
   cri-containerd.apparmor.d
   docker-default
   fluentbit-logs
   genctl-ingress-controller
   libvirt-531d1985-3a4b-46e5-9857-3562f93537ea
   libvirt-60973d9f-dc2d-4cd1-833d-fa4bae9a67c5
   libvirt-8ba3f1f9-ae76-46b5-a6c1-527c3ee378f9
   libvirt-96f3a64c-4002-4029-b777-a44021c28925
   libvirtd
   libvirtd//qemu_bridge_helper
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
   virt-aa-helper
31 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/bin/grep
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/bin/mkdir
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/bin/rm
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/find
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/gawk
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/install
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/jq
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/kubectl
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/base64
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/jq
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/wc
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/hmonagent
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
61 processes have profiles defined.
46 processes are in enforce mode.
   /sbin/block-agent-server (179901) 
   /sbin/coalesce-agent (89589) 
   /sbin/coalesce-agent-nr (169190) 
   /sbin/computeproxy (169034) 
   /sbin/consolemultiplexer (169094) 
   /sbin/cos-transfer-agent (89795) 
   /sbin/cos-transfer-agent-nr (169251) 
   /sbin/dhclient (40501) 
   /sbin/guestproxysvc (88337) 
   /sbin/metadataagent (179344) 
   /sbin/metadataagent (179754) 
   /sbin/metadataagent (180778) 
   /sbin/metadataagent (180811) 
   /sbin/threadbare (88447) 
   /usr/bin/prometheus-node-exporter (172097) 
   /usr/lib/ipsec/charon (13635) 
   /usr/sbin/sshd (181226) 
   /usr/sbin/sshd//sysop (92743) 
   /usr/sbin/sshd//sysop (92764) 
   /usr/sbin/sshd//sysop (182487) 
   /usr/sbin/sshd//sysop (182499) 
   /{,usr/}sbin/net-block-agent (89958) 
   cri-containerd.apparmor.d (141883) 
   cri-containerd.apparmor.d (141907) 
   cri-containerd.apparmor.d (141994) 
   cri-containerd.apparmor.d (170895) 
   cri-containerd.apparmor.d (171043) 
   cri-containerd.apparmor.d (172113) 
   cri-containerd.apparmor.d (172139) 
   cri-containerd.apparmor.d (172312) 
   cri-containerd.apparmor.d (172352) 
   cri-containerd.apparmor.d (172424) 
   cri-containerd.apparmor.d (172473) 
   cri-containerd.apparmor.d (172474) 
   cri-containerd.apparmor.d (173234) 
   cri-containerd.apparmor.d (173255) 
   cri-containerd.apparmor.d (173305) 
   cri-containerd.apparmor.d (173484) 
   cri-containerd.apparmor.d (173556) 
   cri-containerd.apparmor.d (176349) 
   cri-containerd.apparmor.d (177510) 
   libvirt-531d1985-3a4b-46e5-9857-3562f93537ea (181092) 
   libvirt-60973d9f-dc2d-4cd1-833d-fa4bae9a67c5 (179850) 
   libvirt-8ba3f1f9-ae76-46b5-a6c1-527c3ee378f9 (179485) 
   libvirt-96f3a64c-4002-4029-b777-a44021c28925 (180901) 
   libvirtd (168952) 
15 processes are in complain mode.
   /usr/lib/frr/bgpd (196568) 
   /usr/lib/frr/staticd (196576) 
   /usr/lib/frr/watchfrr (196546) 
   /usr/lib/frr/zebra (196563) 
   /usr/local/fabcon/fabcon_server (174086) 
   /usr/local/fabcon/fabcon_server (175260) 
   /usr/local/fabcon/fabcon_server (175269) 
   /usr/local/fabcon/fabcon_server (175276) 
   /usr/local/fabcon/fabcon_server (175290) 
   /usr/local/fabcon/fabcon_server (175302) 
   /usr/local/iobricks/iobricksd (72950) 
   /usr/local/skydive/skydive (70847) 
   /usr/local/skydive/skydive (70903) 
   /usr/local/skydive/skydive (70978) 
   /usr/sbin/hmonagent (74175) 
0 processes are unconfined but have a profile defined.
'
<i>2024-12-17 17:39:53.942746</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:39:54.043096</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:54.043084</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:39:54.043090</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:39:54.043093</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:54.043124</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:39:54.044319</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:39:54.044469</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:39:54.044650</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:54.044639</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:39:54.044644</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:39:54.044647</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:54.044679</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'compute'}
<i>2024-12-17 17:39:54.044702</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_memory_info :Collect information for Numa Memory</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:39:54.151454</td>
    <td>0.19</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:54.151441</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:39:54.151448</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:39:54.151451</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:54.151507</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/memory/memory_info_collector.sh : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/memory/memory_info_collector.sh
<i>2024-12-17 17:39:54.151512</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/memory/memory_info_collector.sh/shell_artifacts/memory/memory_info_collector.sh
<i>2024-12-17 17:39:54.151516</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/memory/memory_info_collector.sh
<i>2024-12-17 17:39:54.337880</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Total Memory of the Node ##############</b>

MemTotal:           768379       MB
<b>############ Total Memory of each Numa Node ##############</b>

Node  0  MemTotal:         191915      MB
Node  1  MemTotal:         193506      MB
Node  2  MemTotal:         193528      MB
Node  3  MemTotal:         189430      MB


<b>############ Free Memory of the Node ##############</b>

MemFree:            662073       MB

<b>############ Free Memory of each Numa Node ##############</b>

Node  0  MemFree:          157160      MB
Node  1  MemFree:          175619      MB
Node  2  MemFree:          172298      MB
Node  3  MemFree:          156997      MB


<b>############ Used Memory of the Node ##############</b>

MemUsed:            106306  MB

<b>############ Used Memory of each Numa Node ##############</b>

Node  0  MemUsed:          34754       MB
Node  1  MemUsed:          17886.8     MB
Node  2  MemUsed:          21230.4     MB
Node  3  MemUsed:          32431.8     MB

'
<i>2024-12-17 17:39:54.338062</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_verify_memory_info :verify if the freememory for compute node is less than the baseline memory of Gen1/Gen2/Gen3</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:39:54.338261</td>
    <td>0.11</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:54.338250</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:39:54.338256</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:39:54.338258</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:54.338330</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/memory/memory_data.yml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/memory/memory_data.yml
<i>2024-12-17 17:39:54.341892</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /sys/class/dmi/id/board_vendor
<i>2024-12-17 17:39:54.344252</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Supermicro
'
<i>2024-12-17 17:39:54.344304</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - lspci |grep -i net |egrep -vi 'Virtual|VF'| grep 'AMD Pensando'
<i>2024-12-17 17:39:54.447061</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:39:54.447100</i> <b style="color:rgb(0 133 115);">[INFO]</b> This is a Gen2 node
<i>2024-12-17 17:39:54.447108</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /proc/meminfo | column -t | grep MemFree
<i>2024-12-17 17:39:54.450255</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'MemFree:            677969508    kB
'
<i>2024-12-17 17:39:54.450320</i> <b style="color:rgb(0 133 115);">[INFO]</b> Free Memory in Node (GB):647
<i>2024-12-17 17:39:54.450330</i> <b style="color:rgb(0 133 115);">[INFO]</b> Baseline Memory (GB):656
<i>2024-12-17 17:39:54.450425</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown
<i>2024-12-17 17:39:54.450891</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/memory_info_collection/test_memory_info_collector.py", line 61, in test_verify_memory_info
    self.assertLessEqual(baseline_memory,memory_in_gb, msg="Memory Not sufficient! Free Memory in node is less than or equal to BaselineMemory")
AssertionError: 656 not less than or equal to 647 : Memory Not sufficient! Free Memory in node is less than or equal to BaselineMemory
</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc001_create_ubuntu_vsi :Verify if an Ubuntu vm can be created on hostos hypervisor</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:40:16.211203</td>
    <td>53.48</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:40:16.211182</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:40:16.211189</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:40:16.211192</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:40:16.211266</i> <b style="color:rgb(0 133 115);">[INFO]</b> Running test for VM: ubuntu_bionic
<i>2024-12-17 17:40:16.211407</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg
<i>2024-12-17 17:40:16.211417</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/network_config_debian.cfg : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_debian.cfg
<i>2024-12-17 17:40:16.213822</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_debian.cfg /home/hostos-validate/network_config_hostos_vsi_ubuntu_bionic_vuqgcn.cfg
<i>2024-12-17 17:40:16.216196</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:16.216230</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/INTERFACE/ens4/g' /home/hostos-validate/network_config_hostos_vsi_ubuntu_bionic_vuqgcn.cfg
<i>2024-12-17 17:40:16.218585</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:16.218613</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/IP_ADDRESS/192.167.128.48/g' /home/hostos-validate/network_config_hostos_vsi_ubuntu_bionic_vuqgcn.cfg
<i>2024-12-17 17:40:16.221056</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:16.221089</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cloud-localds -v --network-config=/home/hostos-validate/network_config_hostos_vsi_ubuntu_bionic_vuqgcn.cfg /home/hostos-validate/cld-init-hostos_vsi_ubuntu_bionic_vuqgcn /home/hostos-validate/cloud_config_hostos_vsi_ubuntu_bionic_vuqgcn.cfg
<i>2024-12-17 17:40:16.234927</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'wrote /home/hostos-validate/cld-init-hostos_vsi_ubuntu_bionic_vuqgcn with filesystem=iso9660 and diskformat=raw
'
<i>2024-12-17 17:40:16.234979</i> <b style="color:rgb(0 133 115);">[INFO]</b> cloud-init image: cld-init-hostos_vsi_ubuntu_bionic_vuqgcn created successfully
<i>2024-12-17 17:40:16.235027</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/generic_vsi.xml /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.xml
<i>2024-12-17 17:40:16.237542</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:16.237588</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /tmp/hostos_images/ubuntu-bionic-amd64-20220607.qcow2 /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.qcow2
<i>2024-12-17 17:40:16.420993</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:16.421030</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_ubuntu_bionic_vuqgcn/' /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.xml
<i>2024-12-17 17:40:16.423222</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:16.423271</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CLOUDINIT_IMAGE_PATH/\/home\/hostos-validate\/cld-init-hostos_vsi_ubuntu_bionic_vuqgcn/' /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.xml
<i>2024-12-17 17:40:16.425820</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:16.425862</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh capabilities | grep model | head -1
<i>2024-12-17 17:40:16.502220</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'      <model>Cascadelake-Server-noTSX</model>
'
<i>2024-12-17 17:40:16.502313</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CPU_MODEL/Cascadelake-Server-noTSX/' /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.xml
<i>2024-12-17 17:40:16.505341</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:16.505400</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.qcow2+'  /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.xml
<i>2024-12-17 17:40:16.508453</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:16.508488</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating VSI : hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:40:16.508495</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh define /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.xml
<i>2024-12-17 17:40:16.555273</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_ubuntu_bionic_vuqgcn defined from /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.xml

'
<i>2024-12-17 17:40:16.555312</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:40:17.405436</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_ubuntu_bionic_vuqgcn started

'
<i>2024-12-17 17:40:17.405697</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list | grep hostos_vsi_ubuntu_bionic_vuqgcn | awk '{print $3}'
<i>2024-12-17 17:40:17.426838</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'running
'
<i>2024-12-17 17:40:17.427054</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","uname"], "capture-output": true}}'
<i>2024-12-17 17:40:17.446403</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1284}}

'
<i>2024-12-17 17:40:17.446538</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1284}}'
<i>2024-12-17 17:40:17.461473</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:40:17.461527</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:17.461623</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:40:17.461632</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:40:25.469771</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1284}}'
<i>2024-12-17 17:40:25.486161</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguNDggcG9ydCAyMjogTm8gcm91dGUgdG8gaG9zdA0K","exited":true}}

'
<i>2024-12-17 17:40:25.486204</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:25.486296</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:40:25.486308</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:40:45.506435</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","uname"], "capture-output": true}}'
<i>2024-12-17 17:40:45.530556</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1375}}

'
<i>2024-12-17 17:40:45.530661</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1375}}'
<i>2024-12-17 17:40:45.547391</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:40:45.547423</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:45.547480</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:40:45.547490</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:40:53.552185</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1375}}'
<i>2024-12-17 17:40:53.569067</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"err-data":"V2FybmluZzogUGVybWFuZW50bHkgYWRkZWQgJzE5Mi4xNjcuMTI4LjQ4JyAoRUNEU0EpIHRvIHRoZSBsaXN0IG9mIGtub3duIGhvc3RzLg0K","out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:40:53.569120</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:53.569209</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:40:53.569218</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:40:53.569239</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","uname -srmpoi"], "capture-output": true}}'
<i>2024-12-17 17:40:53.591824</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1379}}

'
<i>2024-12-17 17:40:53.591934</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1379}}'
<i>2024-12-17 17:40:53.606468</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:40:53.606497</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:53.606549</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:40:53.606558</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:01.613452</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1379}}'
<i>2024-12-17 17:41:01.628849</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXggNS40LjAtMTAyMy1pYm0geDg2XzY0IHg4Nl82NCB4ODZfNjQgR05VL0xpbnV4Cg==","exited":true}}

'
<i>2024-12-17 17:41:01.628900</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:01.629020</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:01.629179</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","cat /etc/os-release | grep PRETTY_NAME"], "capture-output": true}}'
<i>2024-12-17 17:41:01.650873</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1380}}

'
<i>2024-12-17 17:41:01.651024</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1380}}'
<i>2024-12-17 17:41:01.665613</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:01.665650</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:01.665728</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:01.665737</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:09.672254</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1380}}'
<i>2024-12-17 17:41:09.687778</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"UFJFVFRZX05BTUU9IlVidW50dSAxOC4wNC42IExUUyIK","exited":true}}

'
<i>2024-12-17 17:41:09.687811</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:09.687902</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:09.688062</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc002_create_rhel_vsi :Verify if an Redhat vm can be created on hostos hypervisor</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:41:09.688373</td>
    <td>53.56</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:41:09.688358</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:41:09.688365</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:41:09.688368</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:41:09.688413</i> <b style="color:rgb(0 133 115);">[INFO]</b> Running test for VM: rhel_8_6
<i>2024-12-17 17:41:09.688544</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg
<i>2024-12-17 17:41:09.688555</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/network_config_rhel.cfg : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_rhel.cfg
<i>2024-12-17 17:41:09.690893</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_rhel.cfg /home/hostos-validate/network_config_hostos_vsi_rhel_8_6_v6exki.cfg
<i>2024-12-17 17:41:09.693003</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:09.693039</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/INTERFACE/ens4/g' /home/hostos-validate/network_config_hostos_vsi_rhel_8_6_v6exki.cfg
<i>2024-12-17 17:41:09.695659</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:09.695712</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/IP_ADDRESS/192.167.128.210/g' /home/hostos-validate/network_config_hostos_vsi_rhel_8_6_v6exki.cfg
<i>2024-12-17 17:41:09.698063</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:09.698098</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cloud-localds -v --network-config=/home/hostos-validate/network_config_hostos_vsi_rhel_8_6_v6exki.cfg /home/hostos-validate/cld-init-hostos_vsi_rhel_8_6_v6exki /home/hostos-validate/cloud_config_hostos_vsi_rhel_8_6_v6exki.cfg
<i>2024-12-17 17:41:09.711067</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'wrote /home/hostos-validate/cld-init-hostos_vsi_rhel_8_6_v6exki with filesystem=iso9660 and diskformat=raw
'
<i>2024-12-17 17:41:09.711103</i> <b style="color:rgb(0 133 115);">[INFO]</b> cloud-init image: cld-init-hostos_vsi_rhel_8_6_v6exki created successfully
<i>2024-12-17 17:41:09.711151</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/generic_vsi.xml /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.xml
<i>2024-12-17 17:41:09.713253</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:09.713305</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /tmp/hostos_images/rhel-8.6-x86_64-11052022.qcow2 /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.qcow2
<i>2024-12-17 17:41:09.989343</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:09.989405</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_rhel_8_6_v6exki/' /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.xml
<i>2024-12-17 17:41:09.992353</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:09.992403</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CLOUDINIT_IMAGE_PATH/\/home\/hostos-validate\/cld-init-hostos_vsi_rhel_8_6_v6exki/' /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.xml
<i>2024-12-17 17:41:09.995530</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:09.995575</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh capabilities | grep model | head -1
<i>2024-12-17 17:41:10.070241</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'      <model>Cascadelake-Server-noTSX</model>
'
<i>2024-12-17 17:41:10.070321</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CPU_MODEL/Cascadelake-Server-noTSX/' /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.xml
<i>2024-12-17 17:41:10.073218</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:10.073267</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.qcow2+'  /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.xml
<i>2024-12-17 17:41:10.075990</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:10.076027</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating VSI : hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:41:10.076034</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh define /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.xml
<i>2024-12-17 17:41:10.111728</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_rhel_8_6_v6exki defined from /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.xml

'
<i>2024-12-17 17:41:10.111766</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:41:10.993378</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_rhel_8_6_v6exki started

'
<i>2024-12-17 17:41:10.993572</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list | grep hostos_vsi_rhel_8_6_v6exki | awk '{print $3}'
<i>2024-12-17 17:41:11.015982</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'running
'
<i>2024-12-17 17:41:11.016180</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.210","uname"], "capture-output": true}}'
<i>2024-12-17 17:41:11.038208</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1381}}

'
<i>2024-12-17 17:41:11.038324</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1381}}'
<i>2024-12-17 17:41:11.054719</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:11.054757</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:11.054822</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:11.054832</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:19.060190</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1381}}'
<i>2024-12-17 17:41:19.079570</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMjEwIHBvcnQgMjI6IE5vIHJvdXRlIHRvIGhvc3QNCg==","exited":true}}

'
<i>2024-12-17 17:41:19.079624</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:19.079736</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:19.079750</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:41:39.088478</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.210","uname"], "capture-output": true}}'
<i>2024-12-17 17:41:39.110266</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1521}}

'
<i>2024-12-17 17:41:39.110366</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1521}}'
<i>2024-12-17 17:41:39.126523</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:39.126552</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:39.126606</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:39.126615</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:47.127864</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1521}}'
<i>2024-12-17 17:41:47.144876</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"err-data":"V2FybmluZzogUGVybWFuZW50bHkgYWRkZWQgJzE5Mi4xNjcuMTI4LjIxMCcgKEVDRFNBKSB0byB0aGUgbGlzdCBvZiBrbm93biBob3N0cy4NCg==","out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:41:47.144920</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:47.145010</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:47.145021</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:41:47.145041</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.210","uname -srmpoi"], "capture-output": true}}'
<i>2024-12-17 17:41:47.159774</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1530}}

'
<i>2024-12-17 17:41:47.159845</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1530}}'
<i>2024-12-17 17:41:47.174163</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:47.174192</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:47.174237</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:47.174244</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:55.176298</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1530}}'
<i>2024-12-17 17:41:55.192722</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXggNC4xOC4wLTM3Mi45LjEuZWw4Lng4Nl82NCB4ODZfNjQgeDg2XzY0IHg4Nl82NCBHTlUvTGludXgK","exited":true}}

'
<i>2024-12-17 17:41:55.192755</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:55.192834</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:55.192945</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.210","cat /etc/os-release | grep PRETTY_NAME"], "capture-output": true}}'
<i>2024-12-17 17:41:55.209605</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1539}}

'
<i>2024-12-17 17:41:55.209712</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1539}}'
<i>2024-12-17 17:41:55.223563</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:55.223596</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:55.223647</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:55.223655</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:42:03.228241</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1539}}'
<i>2024-12-17 17:42:03.243901</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"UFJFVFRZX05BTUU9IlJlZCBIYXQgRW50ZXJwcmlzZSBMaW51eCA4LjYgKE9vdHBhKSIK","exited":true}}

'
<i>2024-12-17 17:42:03.243937</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:03.244025</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:42:03.244189</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc003_create_centos_vsi :Verify if a Centos vm can be created on hostos hypervisor</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:42:03.244487</td>
    <td>53.43</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:42:03.244473</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:42:03.244481</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:42:03.244483</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:42:03.244530</i> <b style="color:rgb(0 133 115);">[INFO]</b> Running test for VM: centos_7_9
<i>2024-12-17 17:42:03.244669</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg
<i>2024-12-17 17:42:03.244680</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/network_config_centos.cfg : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_centos.cfg
<i>2024-12-17 17:42:03.247072</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_centos.cfg /home/hostos-validate/network_config_hostos_vsi_centos_7_9_nh85ru.cfg
<i>2024-12-17 17:42:03.249186</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:03.249218</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/INTERFACE/ens4/g' /home/hostos-validate/network_config_hostos_vsi_centos_7_9_nh85ru.cfg
<i>2024-12-17 17:42:03.251419</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:03.251450</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/IP_ADDRESS/192.167.128.151/g' /home/hostos-validate/network_config_hostos_vsi_centos_7_9_nh85ru.cfg
<i>2024-12-17 17:42:03.254167</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:03.254221</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cloud-localds -v --network-config=/home/hostos-validate/network_config_hostos_vsi_centos_7_9_nh85ru.cfg /home/hostos-validate/cld-init-hostos_vsi_centos_7_9_nh85ru /home/hostos-validate/cloud_config_hostos_vsi_centos_7_9_nh85ru.cfg
<i>2024-12-17 17:42:03.266693</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'wrote /home/hostos-validate/cld-init-hostos_vsi_centos_7_9_nh85ru with filesystem=iso9660 and diskformat=raw
'
<i>2024-12-17 17:42:03.266722</i> <b style="color:rgb(0 133 115);">[INFO]</b> cloud-init image: cld-init-hostos_vsi_centos_7_9_nh85ru created successfully
<i>2024-12-17 17:42:03.266768</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/generic_vsi.xml /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.xml
<i>2024-12-17 17:42:03.268442</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:03.268488</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /tmp/hostos_images/centos-7.9-x86_64_sparsified.qcow2 /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.qcow2
<i>2024-12-17 17:42:03.478419</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:03.478479</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_centos_7_9_nh85ru/' /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.xml
<i>2024-12-17 17:42:03.482034</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:03.482093</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CLOUDINIT_IMAGE_PATH/\/home\/hostos-validate\/cld-init-hostos_vsi_centos_7_9_nh85ru/' /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.xml
<i>2024-12-17 17:42:03.485076</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:03.485128</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh capabilities | grep model | head -1
<i>2024-12-17 17:42:03.537806</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'      <model>Cascadelake-Server-noTSX</model>
'
<i>2024-12-17 17:42:03.537892</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CPU_MODEL/Cascadelake-Server-noTSX/' /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.xml
<i>2024-12-17 17:42:03.540527</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:03.540563</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.qcow2+'  /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.xml
<i>2024-12-17 17:42:03.542534</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:03.542561</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating VSI : hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:42:03.542567</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh define /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.xml
<i>2024-12-17 17:42:03.588720</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_centos_7_9_nh85ru defined from /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.xml

'
<i>2024-12-17 17:42:03.588755</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:42:04.428793</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_centos_7_9_nh85ru started

'
<i>2024-12-17 17:42:04.428998</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list | grep hostos_vsi_centos_7_9_nh85ru | awk '{print $3}'
<i>2024-12-17 17:42:04.447837</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'running
'
<i>2024-12-17 17:42:04.448036</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.151","uname"], "capture-output": true}}'
<i>2024-12-17 17:42:04.467091</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1540}}

'
<i>2024-12-17 17:42:04.467180</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1540}}'
<i>2024-12-17 17:42:04.483564</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:42:04.483606</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:04.483680</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:42:04.483691</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:42:12.491857</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1540}}'
<i>2024-12-17 17:42:12.509522</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMTUxIHBvcnQgMjI6IE5vIHJvdXRlIHRvIGhvc3QNCg==","exited":true}}

'
<i>2024-12-17 17:42:12.509583</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:12.509685</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:42:12.509696</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:42:32.520313</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.151","uname"], "capture-output": true}}'
<i>2024-12-17 17:42:32.539164</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1541}}

'
<i>2024-12-17 17:42:32.539259</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1541}}'
<i>2024-12-17 17:42:32.553904</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:42:32.553938</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:32.553995</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:42:32.554004</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:42:40.559545</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1541}}'
<i>2024-12-17 17:42:40.576719</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"err-data":"V2FybmluZzogUGVybWFuZW50bHkgYWRkZWQgJzE5Mi4xNjcuMTI4LjE1MScgKEVDRFNBKSB0byB0aGUgbGlzdCBvZiBrbm93biBob3N0cy4NCg==","out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:42:40.576749</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:40.576827</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:42:40.576836</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:42:40.576854</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.151","uname -srmpoi"], "capture-output": true}}'
<i>2024-12-17 17:42:40.592004</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1542}}

'
<i>2024-12-17 17:42:40.592070</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1542}}'
<i>2024-12-17 17:42:40.606215</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:42:40.606244</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:40.606287</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:42:40.606294</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:42:48.610236</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1542}}'
<i>2024-12-17 17:42:48.626741</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXggMy4xMC4wLTExNjAuNzEuMS5lbDcueDg2XzY0IHg4Nl82NCB4ODZfNjQgeDg2XzY0IEdOVS9MaW51eAo=","exited":true}}

'
<i>2024-12-17 17:42:48.626772</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:48.626849</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:42:48.626946</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.151","cat /etc/os-release | grep PRETTY_NAME"], "capture-output": true}}'
<i>2024-12-17 17:42:48.642881</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1543}}

'
<i>2024-12-17 17:42:48.642948</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1543}}'
<i>2024-12-17 17:42:48.658899</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:42:48.658927</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:48.658970</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:42:48.658977</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:42:56.662544</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1543}}'
<i>2024-12-17 17:42:56.678525</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"UFJFVFRZX05BTUU9IkNlbnRPUyBMaW51eCA3IChDb3JlKSIK","exited":true}}

'
<i>2024-12-17 17:42:56.678576</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:56.678678</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:42:56.678856</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc004_create_windows_vsi :Verify if a Windows vm can be created on hostos hypervisor</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:42:56.679155</td>
    <td>496.89</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:42:56.679140</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:42:56.679148</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:42:56.679151</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:42:56.679196</i> <b style="color:rgb(0 133 115);">[INFO]</b> Running test for VM: windows_10
<i>2024-12-17 17:42:56.679345</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudbaseinit_templates/meta_data.json : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudbaseinit_templates/meta_data.json
<i>2024-12-17 17:42:56.679356</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudbaseinit_templates/user_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudbaseinit_templates/user_data
<i>2024-12-17 17:42:56.679362</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mkdir -pv /home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2/openstack/latest
<i>2024-12-17 17:42:56.681967</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"mkdir: created directory '/home/hostos-validate/hostos_vsi_windows_10_l7n9ar'
mkdir: created directory '/home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2'
mkdir: created directory '/home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2/openstack'
mkdir: created directory '/home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2/openstack/latest'
"
<i>2024-12-17 17:42:56.682013</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudbaseinit_templates/meta_data.json /home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2/openstack/latest/meta_data.json
<i>2024-12-17 17:42:56.684833</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:56.684875</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_windows_10_l7n9ar/g' /home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2/openstack/latest/meta_data.json
<i>2024-12-17 17:42:56.687369</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:56.687424</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/PASSWORD/7JUZCEyCQUcdUQCQ9cQB/g' /home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2/openstack/latest/meta_data.json
<i>2024-12-17 17:42:56.689797</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:56.689829</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudbaseinit_templates/user_data /home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2/openstack/latest/user_data
<i>2024-12-17 17:42:56.692032</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:56.692067</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/IP_ADDRESS/192.167.128.129/g' /home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2/openstack/latest/user_data
<i>2024-12-17 17:42:56.694811</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:56.694851</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/INTERFACE_NAME/Ethernet/g' /home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2/openstack/latest/user_data
<i>2024-12-17 17:42:56.697294</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:56.697327</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - genisoimage -input-charset utf-8 -joliet -rock -volid config-2 -output /home/hostos-validate/cld-init-hostos_vsi_windows_10_l7n9ar /home/hostos-validate/hostos_vsi_windows_10_l7n9ar/config-2
<i>2024-12-17 17:42:56.702453</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Total translation table size: 0
Total rockridge attributes bytes: 763
Total directory bytes: 4096
Path table size(bytes): 40
Max brk space used 22000
187 extents written (0 MB)
'
<i>2024-12-17 17:42:56.702488</i> <b style="color:rgb(0 133 115);">[INFO]</b> cloudbase-init image: cld-init-hostos_vsi_windows_10_l7n9ar created successfully
<i>2024-12-17 17:42:56.702506</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/generic_vsi.xml /home/hostos-validate/hostos_vsi_windows_10_l7n9ar.xml
<i>2024-12-17 17:42:56.704875</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:56.704926</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /tmp/hostos_images/win-2k19-std-040822.qcow2 /home/hostos-validate/hostos_vsi_windows_10_l7n9ar.qcow2
<i>2024-12-17 17:43:03.594229</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:43:03.594289</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_windows_10_l7n9ar/' /home/hostos-validate/hostos_vsi_windows_10_l7n9ar.xml
<i>2024-12-17 17:43:03.597619</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:43:03.597677</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CLOUDINIT_IMAGE_PATH/\/home\/hostos-validate\/cld-init-hostos_vsi_windows_10_l7n9ar/' /home/hostos-validate/hostos_vsi_windows_10_l7n9ar.xml
<i>2024-12-17 17:43:03.600570</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:43:03.600623</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh capabilities | grep model | head -1
<i>2024-12-17 17:43:03.655632</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'      <model>Cascadelake-Server-noTSX</model>
'
<i>2024-12-17 17:43:03.655717</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CPU_MODEL/Cascadelake-Server-noTSX/' /home/hostos-validate/hostos_vsi_windows_10_l7n9ar.xml
<i>2024-12-17 17:43:03.658173</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:43:03.658207</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_windows_10_l7n9ar.qcow2+'  /home/hostos-validate/hostos_vsi_windows_10_l7n9ar.xml
<i>2024-12-17 17:43:03.661082</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:43:03.661123</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating VSI : hostos_vsi_windows_10_l7n9ar
<i>2024-12-17 17:43:03.661130</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh define /home/hostos-validate/hostos_vsi_windows_10_l7n9ar.xml
<i>2024-12-17 17:43:03.707412</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_windows_10_l7n9ar defined from /home/hostos-validate/hostos_vsi_windows_10_l7n9ar.xml

'
<i>2024-12-17 17:43:03.707453</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_windows_10_l7n9ar
<i>2024-12-17 17:43:04.572104</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_windows_10_l7n9ar started

'
<i>2024-12-17 17:43:04.572344</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list | grep hostos_vsi_windows_10_l7n9ar | awk '{print $3}'
<i>2024-12-17 17:43:04.590374</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'running
'
<i>2024-12-17 17:43:04.590541</i> <b style="color:rgb(0 133 115);">[INFO]</b> Waiting for VSI network connectivity...
<i>2024-12-17 17:43:04.590569</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:43:04.611664</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1544}}

'
<i>2024-12-17 17:43:04.611772</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1544}}'
<i>2024-12-17 17:43:04.627967</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:43:04.628004</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:43:04.628062</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:43:04.628072</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:43:12.636228</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1544}}'
<i>2024-12-17 17:43:12.656393</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:43:12.656431</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:43:12.656536</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:43:12.656547</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:43:52.663615</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:43:52.694147</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1548}}

'
<i>2024-12-17 17:43:52.694254</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1548}}'
<i>2024-12-17 17:43:52.710296</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:43:52.710334</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:43:52.710398</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:43:52.710407</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:44:00.710490</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1548}}'
<i>2024-12-17 17:44:00.727262</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:44:00.727313</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:44:00.727405</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:44:00.727416</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:44:40.767535</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:44:40.786147</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1549}}

'
<i>2024-12-17 17:44:40.786271</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1549}}'
<i>2024-12-17 17:44:40.800335</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:44:40.800375</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:44:40.800438</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:44:40.800446</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:44:48.808603</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1549}}'
<i>2024-12-17 17:44:48.825008</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:44:48.825062</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:44:48.825164</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:44:48.825174</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:45:28.864267</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:45:28.882629</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1551}}

'
<i>2024-12-17 17:45:28.882716</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1551}}'
<i>2024-12-17 17:45:28.898073</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:45:28.898127</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:45:28.898200</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:45:28.898209</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:45:36.906346</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1551}}'
<i>2024-12-17 17:45:36.923000</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:45:36.923051</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:45:36.923150</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:45:36.923160</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:46:16.933893</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:46:16.951873</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1553}}

'
<i>2024-12-17 17:46:16.951959</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1553}}'
<i>2024-12-17 17:46:16.966964</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:46:16.967013</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:46:16.967082</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:46:16.967090</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:46:24.975248</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1553}}'
<i>2024-12-17 17:46:24.992243</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:46:24.992278</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:46:24.992359</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:46:24.992368</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:47:05.020190</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:47:05.040098</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1554}}

'
<i>2024-12-17 17:47:05.040262</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1554}}'
<i>2024-12-17 17:47:05.054034</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:47:05.054066</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:47:05.054113</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:47:05.054121</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:47:13.060263</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1554}}'
<i>2024-12-17 17:47:13.077668</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:47:13.077702</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:47:13.077790</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:47:13.077799</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:47:53.082636</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:47:53.112040</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1555}}

'
<i>2024-12-17 17:47:53.112136</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1555}}'
<i>2024-12-17 17:47:53.127768</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:47:53.127797</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:47:53.127841</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:47:53.127849</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:48:01.128173</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1555}}'
<i>2024-12-17 17:48:01.144350</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:48:01.144387</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:48:01.144486</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:48:01.144497</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:48:41.184264</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:48:41.203938</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1556}}

'
<i>2024-12-17 17:48:41.204047</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1556}}'
<i>2024-12-17 17:48:41.220977</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:48:41.221020</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:48:41.221090</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:48:41.221100</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:48:49.228198</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1556}}'
<i>2024-12-17 17:48:49.245687</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:48:49.245737</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:48:49.245837</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:48:49.245849</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:49:29.285659</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:49:29.301685</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1557}}

'
<i>2024-12-17 17:49:29.301795</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1557}}'
<i>2024-12-17 17:49:29.317022</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:49:29.317052</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:49:29.317101</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:49:29.317110</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:49:37.325178</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1557}}'
<i>2024-12-17 17:49:37.341354</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:49:37.341394</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:49:37.341487</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:49:37.341498</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:50:17.379704</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:50:17.399791</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1558}}

'
<i>2024-12-17 17:50:17.399888</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1558}}'
<i>2024-12-17 17:50:17.414409</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:50:17.414447</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:50:17.414508</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:50:17.414516</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:50:25.422677</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1558}}'
<i>2024-12-17 17:50:25.438521</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguMjA0IGljbXBfc2VxPTEgRGVzdGluYXRpb24gSG9zdCBVbnJlYWNoYWJsZQoKLS0tIDE5Mi4xNjcuMTI4LjEyOSBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMCByZWNlaXZlZCwgKzEgZXJyb3JzLCAxMDAlIHBhY2tldCBsb3NzLCB0aW1lIDBtcwoK","exited":true}}

'
<i>2024-12-17 17:50:25.438558</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:50:25.438652</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:50:25.438662</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:51:05.476253</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:51:05.495022</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1560}}

'
<i>2024-12-17 17:51:05.495126</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1560}}'
<i>2024-12-17 17:51:05.511180</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMjkgKDE5Mi4xNjcuMTI4LjEyOSkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCjY0IGJ5dGVzIGZyb20gMTkyLjE2Ny4xMjguMTI5OiBpY21wX3NlcT0xIHR0bD0xMjggdGltZT0xLjExIG1zCgotLS0gMTkyLjE2Ny4xMjguMTI5IHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAxIHJlY2VpdmVkLCAwJSBwYWNrZXQgbG9zcywgdGltZSAwbXMKcnR0IG1pbi9hdmcvbWF4L21kZXYgPSAxLjExNy8xLjExNy8xLjExNy8wLjAwMCBtcwo=","exited":true}}

'
<i>2024-12-17 17:51:05.511223</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:05.511319</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:51:05.511328</i> <b style="color:rgb(0 133 115);">[INFO]</b> Network connectivity successful!
<i>2024-12-17 17:51:05.511335</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking Remote Desktop connectivity...
<i>2024-12-17 17:51:05.511350</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "xfreerdp", "arg": ["/cert-ignore", "+auth-only", "/u:Administrator" , "/p:7JUZCEyCQUcdUQCQ9cQB", "/v:192.167.128.129"], "capture-output": true}}'
<i>2024-12-17 17:51:05.530798</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1561}}

'
<i>2024-12-17 17:51:05.530904</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1561}}'
<i>2024-12-17 17:51:05.546064</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:51:05.546108</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:05.546170</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:51:05.546179</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:51:13.554316</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1561}}'
<i>2024-12-17 17:51:13.570411</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"err-data":"L2J1aWxkL2ZyZWVyZHAtS0I2RW90L2ZyZWVyZHAtMS4xLjB+Z2l0MjAxNDA5MjEuMS40NDA5MTZlK2Rmc2cxL2NsaWVudC9YMTEveGZfY2xpZW50LmM6NjkyOiBBdXRoZW50aWNhdGlvbiBvbmx5LiBEb24ndCBjb25uZWN0IHRvIFguCmNvbm5lY3RlZCB0byAxOTIuMTY3LjEyOC4xMjk6MzM4OQpjcmVhdGluZyBkaXJlY3RvcnkgL3RtcC8uY29uZmlnL2ZyZWVyZHAKY3JlYXRpbmcgZGlyZWN0b3J5IC90bXAvLmNvbmZpZy9mcmVlcmRwL2NlcnRzCmNyZWF0aW5nIGRpcmVjdG9yeSAvdG1wLy5jb25maWcvZnJlZXJkcC9zZXJ2ZXIKY2VydGlmaWNhdGVfc3RvcmVfb3BlbjogZXJyb3Igb3BlbmluZyBbL3RtcC8uY29uZmlnL2ZyZWVyZHAva25vd25faG9zdHNdIGZvciB3cml0aW5nClVuYWJsZSB0byBmaW5kIGEgbWF0Y2ggZm9yIHVuaXggdGltZXpvbmU6IEV0Yy9VVEMKL2J1aWxkL2ZyZWVyZHAtS0I2RW90L2ZyZWVyZHAtMS4xLjB+Z2l0MjAxNDA5MjEuMS40NDA5MTZlK2Rmc2cxL2xpYmZyZWVyZHAvY29yZS9mcmVlcmRwLmM6OTU6IEF1dGhlbnRpY2F0aW9uIG9ubHksIGV4aXQgc3RhdHVzIDAKL2J1aWxkL2ZyZWVyZHAtS0I2RW90L2ZyZWVyZHAtMS4xLjB+Z2l0MjAxNDA5MjEuMS40NDA5MTZlK2Rmc2cxL2NsaWVudC9YMTEveGZfY2xpZW50LmM6MTI3ODogQXV0aGVudGljYXRpb24gb25seSwgZXhpdCBzdGF0dXMgMAo=","exited":true}}

'
<i>2024-12-17 17:51:13.570444</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:13.570546</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:51:13.570557</i> <b style="color:rgb(0 133 115);">[INFO]</b> RDP connection message: /build/freerdp-KB6Eot/freerdp-1.1.0~git20140921.1.440916e+dfsg1/client/X11/xf_client.c:692: Authentication only. Don't connect to X.
connected to 192.167.128.129:3389
creating directory /tmp/.config/freerdp
creating directory /tmp/.config/freerdp/certs
creating directory /tmp/.config/freerdp/server
certificate_store_open: error opening [/tmp/.config/freerdp/known_hosts] for writing
Unable to find a match for unix timezone: Etc/UTC
/build/freerdp-KB6Eot/freerdp-1.1.0~git20140921.1.440916e+dfsg1/libfreerdp/core/freerdp.c:95: Authentication only, exit status 0
/build/freerdp-KB6Eot/freerdp-1.1.0~git20140921.1.440916e+dfsg1/client/X11/xf_client.c:1278: Authentication only, exit status 0
<i>2024-12-17 17:51:13.570653</i> <b style="color:rgb(0 133 115);">[INFO]</b> Remote Desktop authentication is successful
<i>2024-12-17 17:51:13.570700</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc005_get_qemusupported_machines :Verify if the list of supported machines of hostos hypervisor matches the base file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:51:13.570942</td>
    <td>0.02</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:51:13.570931</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:51:13.570936</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:51:13.570939</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:51:13.570982</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - qemu-system-x86_64 --machine help | sort
<i>2024-12-17 17:51:13.588474</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Supported machines are:
isapc                ISA-only PC
none                 empty machine
pc                   Standard PC (i440FX + PIIX, 1996) (alias of pc-i440fx-4.2)
pc-0.12              Standard PC (i440FX + PIIX, 1996) (deprecated)
pc-0.13              Standard PC (i440FX + PIIX, 1996) (deprecated)
pc-0.14              Standard PC (i440FX + PIIX, 1996) (deprecated)
pc-0.15              Standard PC (i440FX + PIIX, 1996) (deprecated)
pc-1.0               Standard PC (i440FX + PIIX, 1996)
pc-1.1               Standard PC (i440FX + PIIX, 1996)
pc-1.2               Standard PC (i440FX + PIIX, 1996)
pc-1.3               Standard PC (i440FX + PIIX, 1996)
pc-i440fx-1.4        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-1.5        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-1.6        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-1.7        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.0        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.1        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.10       Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.11       Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.12       Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.2        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.3        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.4        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.5        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.6        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.7        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.8        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.9        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-3.0        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-3.1        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-4.0        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-4.1        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-4.2        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-artful     Ubuntu 17.10 PC (i440FX + PIIX, 1996)
pc-i440fx-bionic     Ubuntu 18.04 PC (i440FX + PIIX, 1996)
pc-i440fx-bionic-hpb Ubuntu 18.04 PC (i440FX + PIIX, +host-phys-bits=true, 1996)
pc-i440fx-cosmic     Ubuntu 18.10 PC (i440FX + PIIX, 1996)
pc-i440fx-cosmic-hpb Ubuntu 18.10 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-disco      Ubuntu 19.04 PC (i440FX + PIIX, 1996)
pc-i440fx-disco-hpb  Ubuntu 19.04 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-eoan       Ubuntu 19.10 PC (i440FX + PIIX, 1996)
pc-i440fx-eoan-hpb   Ubuntu 19.10 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-focal      Ubuntu 20.04 PC (i440FX + PIIX, 1996) (default)
pc-i440fx-focal-hpb  Ubuntu 20.04 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-trusty     Ubuntu 14.04 PC (i440FX + PIIX, 1996)
pc-i440fx-wily       Ubuntu 15.04 PC (i440FX + PIIX, 1996)
pc-i440fx-xenial     Ubuntu 16.04 PC (i440FX + PIIX, 1996)
pc-i440fx-yakkety    Ubuntu 16.10 PC (i440FX + PIIX, 1996)
pc-i440fx-zesty      Ubuntu 17.04 PC (i440FX + PIIX, 1996)
pc-q35-2.10          Standard PC (Q35 + ICH9, 2009)
pc-q35-2.11          Standard PC (Q35 + ICH9, 2009)
pc-q35-2.12          Standard PC (Q35 + ICH9, 2009)
pc-q35-2.4           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.5           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.6           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.7           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.8           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.9           Standard PC (Q35 + ICH9, 2009)
pc-q35-3.0           Standard PC (Q35 + ICH9, 2009)
pc-q35-3.1           Standard PC (Q35 + ICH9, 2009)
pc-q35-4.0           Standard PC (Q35 + ICH9, 2009)
pc-q35-4.0.1         Standard PC (Q35 + ICH9, 2009)
pc-q35-4.1           Standard PC (Q35 + ICH9, 2009)
pc-q35-4.2           Standard PC (Q35 + ICH9, 2009)
pc-q35-artful        Ubuntu 17.10 PC (Q35 + ICH9, 2009)
pc-q35-bionic        Ubuntu 18.04 PC (Q35 + ICH9, 2009)
pc-q35-bionic-hpb    Ubuntu 18.04 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-cosmic        Ubuntu 18.10 PC (Q35 + ICH9, 2009)
pc-q35-cosmic-hpb    Ubuntu 18.10 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-disco         Ubuntu 19.04 PC (Q35 + ICH9, 2009)
pc-q35-disco-hpb     Ubuntu 19.04 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-eoan          Ubuntu 19.10 PC (Q35 + ICH9, 2009)
pc-q35-eoan-hpb      Ubuntu 19.10 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-focal         Ubuntu 20.04 PC (Q35 + ICH9, 2009)
pc-q35-focal-hpb     Ubuntu 20.04 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-xenial        Ubuntu 16.04 PC (Q35 + ICH9, 2009)
pc-q35-yakkety       Ubuntu 16.10 PC (Q35 + ICH9, 2009)
pc-q35-zesty         Ubuntu 17.04 PC (Q35 + ICH9, 2009)
q35                  Standard PC (Q35 + ICH9, 2009) (alias of pc-q35-4.2)
ubuntu               Ubuntu 20.04 PC (i440FX + PIIX, 1996) (alias of pc-i440fx-focal)
ubuntu-q35           Ubuntu 20.04 PC (Q35 + ICH9, 2009) (alias of pc-q35-focal)
'
<i>2024-12-17 17:51:13.588568</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/supported_machines_release_5.txt : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/supported_machines_release_5.txt
<i>2024-12-17 17:51:13.588607</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/supported_machines_release_generic.txt : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/supported_machines_release_generic.txt
<i>2024-12-17 17:51:13.588704</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -y --suppress-common-lines -EZbwB /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/supported_machines_release_generic.txt /home/hostos-validate/result.txt
<i>2024-12-17 17:51:13.590588</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:51:13.590736</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc006_libvirt_protocol_support :Verify ssl/tls protocol versions supported by libvirt for remote connections</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:51:13.590937</td>
    <td>0.13</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:51:13.590925</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:51:13.590931</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:51:13.590933</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:51:13.591156</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using compute node dal1-qz2-sr2-rk203-s14 for checking remote virsh connection
<i>2024-12-17 17:51:13.591166</i> <b style="color:rgb(0 133 115);">[INFO]</b> Starting virsh remote shell -> virsh -c qemu+tls://dal1-qz2-sr2-rk203-s14/system?tls_priority=NORMAL:-VERS-ALL:+VERS-TLS1.2
<i>2024-12-17 17:51:13.642053</i> <b style="color:rgb(0 133 115);">[INFO]</b> Connectivity is successful, output as follows:
Welcome to virsh, the virtualization interactive terminal.

Type:  'help' for help with commands
       'quit' to quit

virsh # 
virsh #                             hostname
dal1-qz2-sr2-rk203-s14

virsh #                             quit


<i>2024-12-17 17:51:13.642070</i> <b style="color:rgb(0 133 115);">[INFO]</b> TLS1.2 is enabled for virsh remote connections
<i>2024-12-17 17:51:13.642080</i> <b style="color:rgb(0 133 115);">[INFO]</b> Starting virsh remote shell -> virsh -c qemu+tls://dal1-qz2-sr2-rk203-s14/system?tls_priority=NORMAL:-VERS-ALL:+VERS-SSL3.0
<i>2024-12-17 17:51:13.668152</i> <b style="color:rgb(0 133 115);">[INFO]</b> Connectivity failed as expected, error as follows:
error: failed to connect to the hypervisor
error: authentication failed: TLS handshake failed The TLS connection was non-properly terminated.

<i>2024-12-17 17:51:13.668170</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSL3.0 is disabled for virsh remote connections
<i>2024-12-17 17:51:13.668176</i> <b style="color:rgb(0 133 115);">[INFO]</b> Starting virsh remote shell -> virsh -c qemu+tls://dal1-qz2-sr2-rk203-s14/system?tls_priority=NORMAL:-VERS-ALL:+VERS-TLS1.0
<i>2024-12-17 17:51:13.692476</i> <b style="color:rgb(0 133 115);">[INFO]</b> Connectivity failed as expected, error as follows:
error: failed to connect to the hypervisor
error: authentication failed: TLS handshake failed The TLS connection was non-properly terminated.

<i>2024-12-17 17:51:13.692502</i> <b style="color:rgb(0 133 115);">[INFO]</b> TLS1.0 is disabled for virsh remote connections
<i>2024-12-17 17:51:13.692510</i> <b style="color:rgb(0 133 115);">[INFO]</b> Starting virsh remote shell -> virsh -c qemu+tls://dal1-qz2-sr2-rk203-s14/system?tls_priority=NORMAL:-VERS-ALL:+VERS-TLS1.1
<i>2024-12-17 17:51:13.716039</i> <b style="color:rgb(0 133 115);">[INFO]</b> Connectivity failed as expected, error as follows:
error: failed to connect to the hypervisor
error: authentication failed: TLS handshake failed The TLS connection was non-properly terminated.

<i>2024-12-17 17:51:13.716057</i> <b style="color:rgb(0 133 115);">[INFO]</b> TLS1.1 is disabled for virsh remote connections
<i>2024-12-17 17:51:13.716201</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc007_process_monitoring :Validate the process monitoring output with the manifest created from last release deployed</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:51:13.716356</td>
    <td>1.92</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:51:13.716345</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:51:13.716351</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:51:13.716354</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:51:13.716386</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - hostos-monitoring -n process-monitoring --verbose
<i>2024-12-17 17:51:14.690715</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'hostos-process-monitoring[128801]: process-monitoring: skipped: 4363, excluded: 0, compliant: 73, non-compliant: [{"/bin/bash": {"checks": [{"owner": {"loginuid": {"expected": 4294967295, "found": 0}, "groups": {"expected": [], "found": [0]}}}], "cmdline": ["bash", "-c", "stdbuf -oL cat /sys/kernel/debug/tracing/trace_pipe | egrep --line-buffered -v bpf_trace_printk >> /var/log/kernel-rpc-traces.txt"], "pid": 38878}}, {"/usr/bin/python3.6": {"checks": [{"apparmor": {"profile_name": {"expected": "/etc/hostos-monitoring/plugins.d/process-monitoring", "found": ""}, "confinement": {"expected": "enforce", "found": "unconfined"}}}, {"cmdline": {"expected": ["/usr/bin/python3", "/usr/bin/ceph-crash"], "found": ["python3", "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}, {"cmdline": {"expected": ["/usr/bin/python3", "/usr/bin/keylime_agent"], "found": ["python3", "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}, {"cmdline": {"expected": ["/usr/bin/python3", "/usr/bin/rclone-configurator"], "found": ["python3", "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}], "cmdline": ["python3", "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"], "pid": 101285}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5900]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_driver_w86z7q,debug-threads=on", "-S", "-object", "secret,id=masterKey0,format=raw,file=/var/lib/libvirt/qemu/domain-153-hostos_vsi_driver_w8/master-key.aes", "-machine", "pc-i440fx-4.2,accel=kvm,usb=off,dump-guest-core=off", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "6dd01884-bc7a-462c-97c9-4e971a1b64e1", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=40,server,nowait", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_driver_w86z7q.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_driver_w86z7q","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=42,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:ca:de:a3,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=43,server,nowait", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-vnc", "0.0.0.0:0", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 101414}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5901]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_ubuntu_bionic_vuqgcn,debug-threads=on", "-S", "-object", "secret,id=masterKey0,format=raw,file=/var/lib/libvirt/qemu/domain-154-hostos_vsi_ubuntu_bi/master-key.aes", "-machine", "pc-i440fx-4.2,accel=kvm,usb=off,dump-guest-core=off", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "6aad8148-db1d-4463-afa2-232533f03f63", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=42,server,nowait", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_ubuntu_bionic_vuqgcn","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=44,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:44:17:c8,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=45,server,nowait", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-vnc", "0.0.0.0:1", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 102233}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5902]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_rhel_8_6_v6exki,debug-threads=on", "-S", "-object", "secret,id=masterKey0,format=raw,file=/var/lib/libvirt/qemu/domain-155-hostos_vsi_rhel_8_6_/master-key.aes", "-machine", "pc-i440fx-4.2,accel=kvm,usb=off,dump-guest-core=off", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "38eedffe-cb06-4d7d-a515-6f59beff7832", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=43,server,nowait", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_rhel_8_6_v6exki","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=45,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:ec:48:7e,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=46,server,nowait", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-vnc", "0.0.0.0:2", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 105594}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5903]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_centos_7_9_nh85ru,debug-threads=on", "-S", "-object", "secret,id=masterKey0,format=raw,file=/var/lib/libvirt/qemu/domain-156-hostos_vsi_centos_7_/master-key.aes", "-machine", "pc-i440fx-4.2,accel=kvm,usb=off,dump-guest-core=off", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "201902c3-e3a6-48af-99a4-489c0beed1c6", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=45,server,nowait", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_centos_7_9_nh85ru","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=47,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:68:ba:9e,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=48,server,nowait", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-vnc", "0.0.0.0:3", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 112020}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5904]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_windows_10_l7n9ar,debug-threads=on", "-S", "-object", "secret,id=masterKey0,format=raw,file=/var/lib/libvirt/qemu/domain-157-hostos_vsi_windows_1/master-key.aes", "-machine", "pc-i440fx-4.2,accel=kvm,usb=off,dump-guest-core=off", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "24f81a6b-64a9-4c2a-906d-73534a2d2381", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=47,server,nowait", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_windows_10_l7n9ar.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_windows_10_l7n9ar","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,scsi=off,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=49,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:95:b5:c8,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=50,server,nowait", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-vnc", "0.0.0.0:4", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 113779}}], unknown: [{"/opt/Tanium/TaniumClient/TaniumClient": {"pid": 182368, "owner": {"uid": 0, "gid": 0, "loginuid": 4294967295, "groups": []}, "apparmor": {"profile_name": "", "confinement": "unconfined"}, "network": {"listen": {"tcp": [], "udp": [], "tcp_src": [], "udp_src": [], "tcp_dest": [], "udp_dest": []}}, "cmdline": ["/opt/Tanium/TaniumClient/TaniumClient", "-d"]}}], zombies: 0, vanished: 0
'
<i>2024-12-17 17:51:14.690780</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - hostos-monitoring -n process-monitoring --verbose --exclude "/usr/bin/qemu-system-x86_64"| awk -F'non-compliant:' '{print $2}' 
<i>2024-12-17 17:51:15.627382</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b' [{"/bin/bash": {"checks": [{"owner": {"loginuid": {"expected": 4294967295, "found": 0}, "groups": {"expected": [], "found": [0]}}}], "cmdline": ["bash", "-c", "stdbuf -oL cat /sys/kernel/debug/tracing/trace_pipe | egrep --line-buffered -v bpf_trace_printk >> /var/log/kernel-rpc-traces.txt"], "pid": 38878}}, {"/usr/bin/python3.6": {"checks": [{"apparmor": {"profile_name": {"expected": "/etc/hostos-monitoring/plugins.d/process-monitoring", "found": ""}, "confinement": {"expected": "enforce", "found": "unconfined"}}}, {"cmdline": {"expected": ["/usr/bin/python3", "/usr/bin/ceph-crash"], "found": ["python3", "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}, {"cmdline": {"expected": ["/usr/bin/python3", "/usr/bin/keylime_agent"], "found": ["python3", "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}, {"cmdline": {"expected": ["/usr/bin/python3", "/usr/bin/rclone-configurator"], "found": ["python3", "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}], "cmdline": ["python3", "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"], "pid": 101285}}], unknown: [{"/opt/Tanium/TaniumClient/TaniumClient": {"pid": 182368, "owner": {"uid": 0, "gid": 0, "loginuid": 4294967295, "groups": []}, "apparmor": {"profile_name": "", "confinement": "unconfined"}, "network": {"listen": {"tcp": [], "udp": [], "tcp_src": [], "udp_src": [], "tcp_dest": [], "udp_dest": []}}, "cmdline": ["/opt/Tanium/TaniumClient/TaniumClient", "-d"]}}], zombies: 0, vanished: 0
'
<i>2024-12-17 17:51:15.627902</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -e '/"-cpu"/,+1d' //home/hostos-validate/actual.json > /home/hostos-validate/tempfile.json
<i>2024-12-17 17:51:15.630546</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:51:15.631358</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/process_monitoring/process_monitoring_data_5.json : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/process_monitoring/process_monitoring_data_5.json
<i>2024-12-17 17:51:15.631400</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/process_monitoring/process_monitoring_data_generic.json : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/process_monitoring/process_monitoring_data_generic.json
<i>2024-12-17 17:51:15.631410</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -e '/"-cpu"/,+1d' /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/process_monitoring/process_monitoring_data_generic.json > /home/hostos-validate/tempfile.json
<i>2024-12-17 17:51:15.634023</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:51:15.634689</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -y --ignore-matching-lines='[0-9]' --ignore-matching-lines='hostos_vsi.*'                      --ignore-matching-lines='cld-init-hostos_vsi.*' --suppress-common-lines //home/hostos-validate/expected.json //home/hostos-validate/actual.json
<i>2024-12-17 17:51:15.636865</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'                  "complain"				      |	                  "unconfined"
                  "/opt/Tanium/TaniumClient/TaniumClient"     |	                  ""
'
<i>2024-12-17 17:51:15.637059</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown
<i>2024-12-17 17:51:15.637661</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py", line 461, in test_vpc007_process_monitoring
    self.assertEqual(exit_code, 0, "Base File comparison Failed!")
  File "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 226, in assertEqual
    raise e
  File "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
AssertionError: 1 != 0 : Base File comparison Failed!
</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc008_create_storagepool :Verify if a storage pool can be created on the host and verify its state</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:51:15.637847</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:51:15.637835</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:51:15.637840</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:51:15.637843</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:51:15.637873</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating storage pool
<i>2024-12-17 17:51:15.637883</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-define-as guest_vsi_disk dir --target /home/hostos-validate
<i>2024-12-17 17:51:15.652332</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk defined

'
<i>2024-12-17 17:51:15.652366</i> <b style="color:rgb(0 133 115);">[INFO]</b> b'Pool guest_vsi_disk defined

'
<i>2024-12-17 17:51:15.652382</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-build guest_vsi_disk
<i>2024-12-17 17:51:15.667539</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk built

'
<i>2024-12-17 17:51:15.667574</i> <b style="color:rgb(0 133 115);">[INFO]</b> b'Pool guest_vsi_disk built

'
<i>2024-12-17 17:51:15.667589</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-start guest_vsi_disk
<i>2024-12-17 17:51:15.680456</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk started

'
<i>2024-12-17 17:51:15.680488</i> <b style="color:rgb(0 133 115);">[INFO]</b> b'Pool guest_vsi_disk started

'
<i>2024-12-17 17:51:15.680495</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking Storage pool status
<i>2024-12-17 17:51:15.680508</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-info guest_vsi_disk | grep State | sed 's/ //g'
<i>2024-12-17 17:51:15.694601</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'State:running
'
<i>2024-12-17 17:51:15.694761</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc009_attach_volume_ubuntu :Verify if a storage volume is created and is attached to Ubuntu vsi</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:51:15.694949</td>
    <td>8.61</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:51:15.694936</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:51:15.694942</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:51:15.694946</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:51:15.694995</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-create-as --pool guest_vsi_disk --name vol_ubuntu_bionic_vuqgcn --capacity 5GiB --format raw
<i>2024-12-17 17:51:16.084498</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_ubuntu_bionic_vuqgcn created

'
<i>2024-12-17 17:51:16.084548</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating and attaching volume vdc on hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:51:16.084554</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-disk hostos_vsi_ubuntu_bionic_vuqgcn /home/hostos-validate/vol_ubuntu_bionic_vuqgcn vdc
<i>2024-12-17 17:51:16.243873</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk attached successfully

'
<i>2024-12-17 17:51:16.243931</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","lsblk -po NAME,SIZE,TYPE | grep vdc"], "capture-output": true}}'
<i>2024-12-17 17:51:16.268457</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1564}}

'
<i>2024-12-17 17:51:16.268569</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1564}}'
<i>2024-12-17 17:51:16.282994</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:51:16.283043</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:16.283115</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:51:16.283125</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:51:24.291259</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1564}}'
<i>2024-12-17 17:51:24.307507</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"L2Rldi92ZGMgICAgICAgIDVHIGRpc2sK","exited":true}}

'
<i>2024-12-17 17:51:24.307561</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:24.307656</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:51:24.307826</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc010_attach_volume_rhel :Verify if a storage volume is created and is attached to Redhat vsi</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:51:24.308035</td>
    <td>8.62</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:51:24.308024</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:51:24.308030</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:51:24.308033</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:51:24.308082</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-create-as --pool guest_vsi_disk --name vol_rhel_8_6_v6exki --capacity 5GiB --format raw
<i>2024-12-17 17:51:24.698731</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_rhel_8_6_v6exki created

'
<i>2024-12-17 17:51:24.698774</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating and attaching volume vdc on hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:51:24.698779</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-disk hostos_vsi_rhel_8_6_v6exki /home/hostos-validate/vol_rhel_8_6_v6exki vdc
<i>2024-12-17 17:51:24.858099</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk attached successfully

'
<i>2024-12-17 17:51:24.858149</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.210","lsblk -po NAME,SIZE,TYPE | grep vdc"], "capture-output": true}}'
<i>2024-12-17 17:51:24.891732</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1565}}

'
<i>2024-12-17 17:51:24.891840</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1565}}'
<i>2024-12-17 17:51:24.906154</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:51:24.906186</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:24.906234</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:51:24.906242</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:51:32.908290</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1565}}'
<i>2024-12-17 17:51:32.923367</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"L2Rldi92ZGMgICAgICAgNUcgZGlzawo=","exited":true}}

'
<i>2024-12-17 17:51:32.923422</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:32.923520</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:51:32.923696</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc011_attach_volume_centos :Verify if a storage volume is created and is attached to Centos vsi</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:51:32.923909</td>
    <td>8.6</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:51:32.923895</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:51:32.923904</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:51:32.923907</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:51:32.923957</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-create-as --pool guest_vsi_disk --name vol_centos_7_9_nh85ru --capacity 5GiB --format raw
<i>2024-12-17 17:51:33.313009</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_centos_7_9_nh85ru created

'
<i>2024-12-17 17:51:33.313068</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating and attaching volume vdc on hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:51:33.313074</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-disk hostos_vsi_centos_7_9_nh85ru /home/hostos-validate/vol_centos_7_9_nh85ru vdc
<i>2024-12-17 17:51:33.454543</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk attached successfully

'
<i>2024-12-17 17:51:33.454607</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.151","lsblk -po NAME,SIZE,TYPE | grep vdc"], "capture-output": true}}'
<i>2024-12-17 17:51:33.482111</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1566}}

'
<i>2024-12-17 17:51:33.482211</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1566}}'
<i>2024-12-17 17:51:33.496669</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:51:33.496699</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:33.496749</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:51:33.496758</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:51:41.504903</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1566}}'
<i>2024-12-17 17:51:41.522658</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"L2Rldi92ZGMgICAgICAgICAgICAgICAgICAgICAgICAgICA1RyBkaXNrCg==","exited":true}}

'
<i>2024-12-17 17:51:41.522694</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:41.522779</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:51:41.522932</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc012_create_revert_ubuntu_snap :Verify if a snapshot is created, reverted and verified for ubuntu VSI</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:51:41.523114</td>
    <td>70.54</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:51:41.523104</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:51:41.523109</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:51:41.523112</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:51:41.523156</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_ubuntu_bionic_vuqgcn | awk -F" " '{print $1}' | tail -n+3
<i>2024-12-17 17:51:41.539227</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'vda
vdb
vdc

'
<i>2024-12-17 17:51:41.539271</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-create-as hostos_vsi_ubuntu_bionic_vuqgcn  --name snap1 --disk-only --diskspec vda,snapshot=external,file=/home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.snap1 diskspec vdb,snapshot=no vdc,snapshot=no
<i>2024-12-17 17:51:41.693350</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 created
'
<i>2024-12-17 17:51:41.693415</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_ubuntu_bionic_vuqgcn | grep snap1 | wc -l
<i>2024-12-17 17:51:41.708217</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'1
'
<i>2024-12-17 17:51:41.708370</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_ubuntu_bionic_vuqgcn | grep vda | grep snap1 | awk -F" " '{print $2}'
<i>2024-12-17 17:51:41.722124</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.snap1
'
<i>2024-12-17 17:51:41.722307</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","pwd > sample.txt"], "capture-output": true}}'
<i>2024-12-17 17:51:41.749787</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1567}}

'
<i>2024-12-17 17:51:41.749871</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1567}}'
<i>2024-12-17 17:51:41.765933</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:51:41.765968</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:41.766025</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:51:41.766035</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:51:49.772266</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1567}}'
<i>2024-12-17 17:51:49.788108</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"exited":true}}

'
<i>2024-12-17 17:51:49.788152</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:49.788237</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> No stderr or stdout found !!
<i>2024-12-17 17:51:49.788258</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:51:49.788284</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:51:49.805802</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1568}}

'
<i>2024-12-17 17:51:49.805917</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1568}}'
<i>2024-12-17 17:51:49.821877</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:51:49.821915</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:49.821973</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:51:49.821982</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:51:57.830056</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1568}}'
<i>2024-12-17 17:51:57.847152</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MQo=","exited":true}}

'
<i>2024-12-17 17:51:57.847200</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:57.847290</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:51:57.847468</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/disk_info.xml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml
<i>2024-12-17 17:51:57.847475</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn_diskinfo.xml
<i>2024-12-17 17:51:57.850157</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:51:57.850203</i> <b style="color:rgb(0 133 115);">[INFO]</b> created a source diskinfo xml for hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:51:57.850212</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.qcow2+' /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn_diskinfo.xml
<i>2024-12-17 17:51:57.853263</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:51:57.853310</i> <b style="color:rgb(0 133 115);">[INFO]</b> qcow2 diskinfo xml for hostos_vsi_ubuntu_bionic_vuqgcn created!
<i>2024-12-17 17:51:57.853333</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh detach-disk --persistent hostos_vsi_ubuntu_bionic_vuqgcn vda
<i>2024-12-17 17:51:58.124295</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk detached successfully

'
<i>2024-12-17 17:51:58.124338</i> <b style="color:rgb(0 133 115);">[INFO]</b> detached the snapshot from vsi hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:51:58.124348</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-device --persistent hostos_vsi_ubuntu_bionic_vuqgcn /home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn_diskinfo.xml
<i>2024-12-17 17:51:58.307684</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Device attached successfully

'
<i>2024-12-17 17:51:58.307736</i> <b style="color:rgb(0 133 115);">[INFO]</b> attached the qcow2 diskinfo to vsi hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:51:58.307745</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh destroy hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:51:58.752468</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_ubuntu_bionic_vuqgcn destroyed

'
<i>2024-12-17 17:51:58.752524</i> <b style="color:rgb(0 133 115);">[INFO]</b> VSI hostos_vsi_ubuntu_bionic_vuqgcn shutdown successful
<i>2024-12-17 17:51:58.752533</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:51:59.816148</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_ubuntu_bionic_vuqgcn started

'
<i>2024-12-17 17:51:59.816215</i> <b style="color:rgb(0 133 115);">[INFO]</b> hostos_vsi_ubuntu_bionic_vuqgcn restart successful
<i>2024-12-17 17:51:59.816256</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","uname"], "capture-output": true}}'
<i>2024-12-17 17:51:59.839361</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1569}}

'
<i>2024-12-17 17:51:59.839477</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1569}}'
<i>2024-12-17 17:51:59.855829</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:51:59.855868</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:59.855924</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:51:59.855935</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:52:07.863499</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1569}}'
<i>2024-12-17 17:52:07.881496</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:52:07.881558</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:07.881639</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:52:07.881653</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:52:15.884273</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1569}}'
<i>2024-12-17 17:52:15.903303</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguNDggcG9ydCAyMjogQ29ubmVjdGlvbiByZWZ1c2VkDQo=","exited":true}}

'
<i>2024-12-17 17:52:15.903356</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:15.903454</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:52:15.903466</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:52:35.907254</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","uname"], "capture-output": true}}'
<i>2024-12-17 17:52:35.923142</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1570}}

'
<i>2024-12-17 17:52:35.923249</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1570}}'
<i>2024-12-17 17:52:35.939634</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:52:35.939666</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:35.939714</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:52:35.939723</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:52:43.947880</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1570}}'
<i>2024-12-17 17:52:43.965319</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:52:43.965375</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:43.965496</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:52:43.965507</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:52:43.965519</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_ubuntu_bionic_vuqgcn | grep vda| grep "qcow2" | awk                     -F" " '{print $2}'
<i>2024-12-17 17:52:43.982262</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_ubuntu_bionic_vuqgcn.qcow2
'
<i>2024-12-17 17:52:43.982432</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.48","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:52:43.997193</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1571}}

'
<i>2024-12-17 17:52:43.997282</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1571}}'
<i>2024-12-17 17:52:44.011780</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:52:44.011813</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:44.011861</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:52:44.011870</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:52:52.020035</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1571}}'
<i>2024-12-17 17:52:52.036645</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MAo=","exited":true}}

'
<i>2024-12-17 17:52:52.036692</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:52.036777</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:52:52.036905</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-delete --metadata hostos_vsi_ubuntu_bionic_vuqgcn snap1
<i>2024-12-17 17:52:52.052576</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 deleted

'
<i>2024-12-17 17:52:52.052625</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-list hostos_vsi_ubuntu_bionic_vuqgcn | grep snap1 | wc -l
<i>2024-12-17 17:52:52.066545</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:52:52.066714</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc013_create_revert_rhel_snap :Verify if a snapshot is created, reverted and verified for rhel VSI</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:52:52.066964</td>
    <td>58.29</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:52:52.066948</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:52:52.066956</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:52:52.066960</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:52:52.067006</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_rhel_8_6_v6exki | awk -F" " '{print $1}' | tail -n+3
<i>2024-12-17 17:52:52.081340</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'vda
vdb
vdc

'
<i>2024-12-17 17:52:52.081384</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-create-as hostos_vsi_rhel_8_6_v6exki  --name snap1 --disk-only --diskspec vda,snapshot=external,file=/home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.snap1 diskspec vdb,snapshot=no vdc,snapshot=no
<i>2024-12-17 17:52:52.231516</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 created
'
<i>2024-12-17 17:52:52.231563</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_rhel_8_6_v6exki | grep snap1 | wc -l
<i>2024-12-17 17:52:52.246975</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'1
'
<i>2024-12-17 17:52:52.247149</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_rhel_8_6_v6exki | grep vda | grep snap1 | awk -F" " '{print $2}'
<i>2024-12-17 17:52:52.261837</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.snap1
'
<i>2024-12-17 17:52:52.262003</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.210","pwd > sample.txt"], "capture-output": true}}'
<i>2024-12-17 17:52:52.276382</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1572}}

'
<i>2024-12-17 17:52:52.276461</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1572}}'
<i>2024-12-17 17:52:52.291493</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:52:52.291523</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:52.291571</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:52:52.291580</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:53:00.298554</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1572}}'
<i>2024-12-17 17:53:00.315272</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"exited":true}}

'
<i>2024-12-17 17:53:00.315310</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:00.315384</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> No stderr or stdout found !!
<i>2024-12-17 17:53:00.315403</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:53:00.315429</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.210","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:53:00.330651</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1573}}

'
<i>2024-12-17 17:53:00.330722</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1573}}'
<i>2024-12-17 17:53:00.344888</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:53:00.344921</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:00.344967</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:53:00.344975</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:53:08.348302</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1573}}'
<i>2024-12-17 17:53:08.365429</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MQo=","exited":true}}

'
<i>2024-12-17 17:53:08.365472</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:08.365554</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:53:08.365709</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/disk_info.xml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml
<i>2024-12-17 17:53:08.365717</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki_diskinfo.xml
<i>2024-12-17 17:53:08.368493</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:53:08.368533</i> <b style="color:rgb(0 133 115);">[INFO]</b> created a source diskinfo xml for hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:53:08.368542</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.qcow2+' /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki_diskinfo.xml
<i>2024-12-17 17:53:08.370999</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:53:08.371034</i> <b style="color:rgb(0 133 115);">[INFO]</b> qcow2 diskinfo xml for hostos_vsi_rhel_8_6_v6exki created!
<i>2024-12-17 17:53:08.371049</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh detach-disk --persistent hostos_vsi_rhel_8_6_v6exki vda
<i>2024-12-17 17:53:08.621331</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk detached successfully

'
<i>2024-12-17 17:53:08.621385</i> <b style="color:rgb(0 133 115);">[INFO]</b> detached the snapshot from vsi hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:53:08.621394</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-device --persistent hostos_vsi_rhel_8_6_v6exki /home/hostos-validate/hostos_vsi_rhel_8_6_v6exki_diskinfo.xml
<i>2024-12-17 17:53:08.799758</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Device attached successfully

'
<i>2024-12-17 17:53:08.799808</i> <b style="color:rgb(0 133 115);">[INFO]</b> attached the qcow2 diskinfo to vsi hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:53:08.799816</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh destroy hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:53:09.210824</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_rhel_8_6_v6exki destroyed

'
<i>2024-12-17 17:53:09.210885</i> <b style="color:rgb(0 133 115);">[INFO]</b> VSI hostos_vsi_rhel_8_6_v6exki shutdown successful
<i>2024-12-17 17:53:09.210896</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:53:10.136331</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_rhel_8_6_v6exki started

'
<i>2024-12-17 17:53:10.136401</i> <b style="color:rgb(0 133 115);">[INFO]</b> hostos_vsi_rhel_8_6_v6exki restart successful
<i>2024-12-17 17:53:10.136457</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.210","uname"], "capture-output": true}}'
<i>2024-12-17 17:53:10.155992</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1574}}

'
<i>2024-12-17 17:53:10.156108</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1574}}'
<i>2024-12-17 17:53:10.173940</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:53:10.173976</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:10.174030</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:53:10.174039</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:53:18.174251</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1574}}'
<i>2024-12-17 17:53:18.192279</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:53:18.192331</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:18.192405</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:53:18.192416</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:53:26.200177</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1574}}'
<i>2024-12-17 17:53:26.215631</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:53:26.215668</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:26.215727</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:53:26.215735</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:53:34.219308</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1574}}'
<i>2024-12-17 17:53:34.234343</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:53:34.234391</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:34.234460</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:53:34.234468</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:53:42.242543</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1574}}'
<i>2024-12-17 17:53:42.258618</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:53:42.258667</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:42.258754</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:53:42.258762</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:53:42.258773</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_rhel_8_6_v6exki | grep vda| grep "qcow2" | awk                     -F" " '{print $2}'
<i>2024-12-17 17:53:42.273661</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_rhel_8_6_v6exki.qcow2
'
<i>2024-12-17 17:53:42.273832</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.210","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:53:42.289209</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1575}}

'
<i>2024-12-17 17:53:42.289289</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1575}}'
<i>2024-12-17 17:53:42.304897</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:53:42.304928</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:42.304977</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:53:42.304985</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:53:50.306509</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1575}}'
<i>2024-12-17 17:53:50.322150</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MAo=","exited":true}}

'
<i>2024-12-17 17:53:50.322187</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:50.322270</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:53:50.322393</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-delete --metadata hostos_vsi_rhel_8_6_v6exki snap1
<i>2024-12-17 17:53:50.337796</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 deleted

'
<i>2024-12-17 17:53:50.337835</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-list hostos_vsi_rhel_8_6_v6exki | grep snap1 | wc -l
<i>2024-12-17 17:53:50.354386</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:53:50.354618</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc014_create_revert_centos_snap :Verify if a snapshot is created, reverted and verified for CentOS VSI</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:53:50.354871</td>
    <td>42.24</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:53:50.354857</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:53:50.354864</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:53:50.354868</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:53:50.354921</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_centos_7_9_nh85ru | awk -F" " '{print $1}' | tail -n+3
<i>2024-12-17 17:53:50.370044</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'vda
vdb
vdc

'
<i>2024-12-17 17:53:50.370098</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-create-as hostos_vsi_centos_7_9_nh85ru  --name snap1 --disk-only --diskspec vda,snapshot=external,file=/home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.snap1 diskspec vdb,snapshot=no vdc,snapshot=no
<i>2024-12-17 17:53:50.517279</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 created
'
<i>2024-12-17 17:53:50.517352</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_centos_7_9_nh85ru | grep snap1 | wc -l
<i>2024-12-17 17:53:50.531783</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'1
'
<i>2024-12-17 17:53:50.531922</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_centos_7_9_nh85ru | grep vda | grep snap1 | awk -F" " '{print $2}'
<i>2024-12-17 17:53:50.547438</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.snap1
'
<i>2024-12-17 17:53:50.547608</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.151","pwd > sample.txt"], "capture-output": true}}'
<i>2024-12-17 17:53:50.562038</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1576}}

'
<i>2024-12-17 17:53:50.562116</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1576}}'
<i>2024-12-17 17:53:50.576693</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:53:50.576729</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:50.576790</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:53:50.576801</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:53:58.582600</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1576}}'
<i>2024-12-17 17:53:58.598799</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"exited":true}}

'
<i>2024-12-17 17:53:58.598845</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:58.598914</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> No stderr or stdout found !!
<i>2024-12-17 17:53:58.598935</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:53:58.598957</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.151","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:53:58.614163</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1577}}

'
<i>2024-12-17 17:53:58.614259</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1577}}'
<i>2024-12-17 17:53:58.629184</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:53:58.629214</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:58.629261</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:53:58.629269</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:54:06.636201</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1577}}'
<i>2024-12-17 17:54:06.652970</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MQo=","exited":true}}

'
<i>2024-12-17 17:54:06.653018</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:06.653102</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:54:06.653262</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/disk_info.xml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml
<i>2024-12-17 17:54:06.653270</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru_diskinfo.xml
<i>2024-12-17 17:54:06.655623</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:06.655663</i> <b style="color:rgb(0 133 115);">[INFO]</b> created a source diskinfo xml for hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:54:06.655672</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.qcow2+' /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru_diskinfo.xml
<i>2024-12-17 17:54:06.657939</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:06.657970</i> <b style="color:rgb(0 133 115);">[INFO]</b> qcow2 diskinfo xml for hostos_vsi_centos_7_9_nh85ru created!
<i>2024-12-17 17:54:06.657985</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh detach-disk --persistent hostos_vsi_centos_7_9_nh85ru vda
<i>2024-12-17 17:54:06.894429</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk detached successfully

'
<i>2024-12-17 17:54:06.894466</i> <b style="color:rgb(0 133 115);">[INFO]</b> detached the snapshot from vsi hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:54:06.894475</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-device --persistent hostos_vsi_centos_7_9_nh85ru /home/hostos-validate/hostos_vsi_centos_7_9_nh85ru_diskinfo.xml
<i>2024-12-17 17:54:07.076216</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Device attached successfully

'
<i>2024-12-17 17:54:07.076287</i> <b style="color:rgb(0 133 115);">[INFO]</b> attached the qcow2 diskinfo to vsi hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:54:07.076296</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh destroy hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:54:07.493664</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_centos_7_9_nh85ru destroyed

'
<i>2024-12-17 17:54:07.493712</i> <b style="color:rgb(0 133 115);">[INFO]</b> VSI hostos_vsi_centos_7_9_nh85ru shutdown successful
<i>2024-12-17 17:54:07.493721</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:54:08.410524</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_centos_7_9_nh85ru started

'
<i>2024-12-17 17:54:08.410584</i> <b style="color:rgb(0 133 115);">[INFO]</b> hostos_vsi_centos_7_9_nh85ru restart successful
<i>2024-12-17 17:54:08.410625</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.151","uname"], "capture-output": true}}'
<i>2024-12-17 17:54:08.432639</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1578}}

'
<i>2024-12-17 17:54:08.432763</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1578}}'
<i>2024-12-17 17:54:08.452817</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:54:08.452867</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:08.452935</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:54:08.452945</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:54:16.458576</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1578}}'
<i>2024-12-17 17:54:16.476803</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:54:16.476858</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:16.476935</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:54:16.476946</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:54:24.484201</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1578}}'
<i>2024-12-17 17:54:24.501203</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:54:24.501240</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:24.501322</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:54:24.501331</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:54:24.501341</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_centos_7_9_nh85ru | grep vda| grep "qcow2" | awk                     -F" " '{print $2}'
<i>2024-12-17 17:54:24.517442</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_centos_7_9_nh85ru.qcow2
'
<i>2024-12-17 17:54:24.517616</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.151","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:54:24.532895</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1579}}

'
<i>2024-12-17 17:54:24.532976</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1579}}'
<i>2024-12-17 17:54:24.547678</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:54:24.547728</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:24.547794</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:54:24.547803</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:54:32.550895</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_w86z7q '{"execute": "guest-exec-status", "arguments": { "pid" :1579}}'
<i>2024-12-17 17:54:32.567789</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MAo=","exited":true}}

'
<i>2024-12-17 17:54:32.567834</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:32.567921</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:54:32.568043</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-delete --metadata hostos_vsi_centos_7_9_nh85ru snap1
<i>2024-12-17 17:54:32.584160</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 deleted

'
<i>2024-12-17 17:54:32.584202</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-list hostos_vsi_centos_7_9_nh85ru | grep snap1 | wc -l
<i>2024-12-17 17:54:32.596746</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:54:32.596880</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc015_volume_cleanup :Verify if the storage volumes are deleted</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:32.597069</td>
    <td>0.83</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:32.597057</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:32.597063</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:32.597066</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:32.597101</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying storage volumes
<i>2024-12-17 17:54:32.597113</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-list guest_vsi_disk | grep vol | awk -F" " '{print $1}'
<i>2024-12-17 17:54:32.615156</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'vol_centos_7_9_nh85ru
vol_rhel_8_6_v6exki
vol_ubuntu_bionic_vuqgcn
'
<i>2024-12-17 17:54:32.615199</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-delete vol_centos_7_9_nh85ru --pool guest_vsi_disk
<i>2024-12-17 17:54:32.874446</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_centos_7_9_nh85ru deleted

'
<i>2024-12-17 17:54:32.874495</i> <b style="color:rgb(0 133 115);">[INFO]</b> Volume vol_centos_7_9_nh85ru deleted
<i>2024-12-17 17:54:32.874509</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-delete vol_rhel_8_6_v6exki --pool guest_vsi_disk
<i>2024-12-17 17:54:33.143881</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_rhel_8_6_v6exki deleted

'
<i>2024-12-17 17:54:33.143939</i> <b style="color:rgb(0 133 115);">[INFO]</b> Volume vol_rhel_8_6_v6exki deleted
<i>2024-12-17 17:54:33.143960</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-delete vol_ubuntu_bionic_vuqgcn --pool guest_vsi_disk
<i>2024-12-17 17:54:33.405985</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_ubuntu_bionic_vuqgcn deleted

'
<i>2024-12-17 17:54:33.406021</i> <b style="color:rgb(0 133 115);">[INFO]</b> Volume vol_ubuntu_bionic_vuqgcn deleted
<i>2024-12-17 17:54:33.406036</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-list guest_vsi_disk | grep vol | wc -l
<i>2024-12-17 17:54:33.422434</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:54:33.422633</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc016_vhost_pinning :Validate if the vhost processes were correctly pinned acc to the emulatorpin setting of libvirtd</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:33.422823</td>
    <td>1.33</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:33.422811</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:33.422817</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:33.422820</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:33.422893</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/test_pin.sh : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/test_pin.sh
<i>2024-12-17 17:54:33.422899</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/test_pin.sh && echo match || echo mismatch
<i>2024-12-17 17:54:34.754632</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'match
'
<i>2024-12-17 17:54:34.754833</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc017_vsi_cleanup :Verify if the VSIs created are deleted</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:34.755018</td>
    <td>2.35</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:34.755006</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:34.755013</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:34.755016</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:34.755059</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all |awk -F" " '{print $2}'
<i>2024-12-17 17:54:34.769933</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Name

k8s_d9bcdd4212ff4637a6efc1d48d8a802b_2114_8ba3f1f9-ae76-46b5-a6c1-527c3ee378f9
k8s_a75f2a54c5114ce5b4055016f250e8e5_2114_60973d9f-dc2d-4cd1-833d-fa4bae9a67c5
k8s_a75f2a54c5114ce5b4055016f250e8e5_2114_96f3a64c-4002-4029-b777-a44021c28925
k8s_a75f2a54c5114ce5b4055016f250e8e5_2114_531d1985-3a4b-46e5-9857-3562f93537ea
hostos_vsi_driver_w86z7q
hostos_vsi_windows_10_l7n9ar
hostos_vsi_ubuntu_bionic_vuqgcn
hostos_vsi_rhel_8_6_v6exki
hostos_vsi_centos_7_9_nh85ru

'
<i>2024-12-17 17:54:34.770006</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_driver_w86z7q
<i>2024-12-17 17:54:34.770019</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_driver_w86z7q; virsh destroy hostos_vsi_driver_w86z7q
<i>2024-12-17 17:54:35.211749</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_driver_w86z7q has been undefined

Domain hostos_vsi_driver_w86z7q destroyed

'
<i>2024-12-17 17:54:35.211822</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_driver_w86z7q | wc -l
<i>2024-12-17 17:54:35.229512</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:54:35.229674</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:54:35.229686</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_ubuntu_bionic_vuqgcn; virsh destroy hostos_vsi_ubuntu_bionic_vuqgcn
<i>2024-12-17 17:54:35.660927</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_ubuntu_bionic_vuqgcn has been undefined

Domain hostos_vsi_ubuntu_bionic_vuqgcn destroyed

'
<i>2024-12-17 17:54:35.660991</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_ubuntu_bionic_vuqgcn | wc -l
<i>2024-12-17 17:54:35.677980</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:54:35.678146</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:54:35.678159</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_rhel_8_6_v6exki; virsh destroy hostos_vsi_rhel_8_6_v6exki
<i>2024-12-17 17:54:36.121440</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_rhel_8_6_v6exki has been undefined

Domain hostos_vsi_rhel_8_6_v6exki destroyed

'
<i>2024-12-17 17:54:36.121559</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_rhel_8_6_v6exki | wc -l
<i>2024-12-17 17:54:36.143210</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:54:36.143444</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:54:36.143464</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_centos_7_9_nh85ru; virsh destroy hostos_vsi_centos_7_9_nh85ru
<i>2024-12-17 17:54:36.596856</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_centos_7_9_nh85ru has been undefined

Domain hostos_vsi_centos_7_9_nh85ru destroyed

'
<i>2024-12-17 17:54:36.596904</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_centos_7_9_nh85ru | wc -l
<i>2024-12-17 17:54:36.615082</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:54:36.615264</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_windows_10_l7n9ar
<i>2024-12-17 17:54:36.615278</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_windows_10_l7n9ar; virsh destroy hostos_vsi_windows_10_l7n9ar
<i>2024-12-17 17:54:37.084317</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain hostos_vsi_windows_10_l7n9ar has been undefined

Domain hostos_vsi_windows_10_l7n9ar destroyed

'
<i>2024-12-17 17:54:37.084383</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_windows_10_l7n9ar | wc -l
<i>2024-12-17 17:54:37.100800</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:54:37.101017</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc018_storagepool_cleanup :Verify if the storage pool is deleted</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:37.101274</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:37.101250</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:37.101261</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:37.101268</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:37.101318</i> <b style="color:rgb(0 133 115);">[INFO]</b> destroying the pool guest_vsi_disk
<i>2024-12-17 17:54:37.101335</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-destroy guest_vsi_disk
<i>2024-12-17 17:54:37.118651</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk destroyed

'
<i>2024-12-17 17:54:37.118690</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-undefine guest_vsi_disk
<i>2024-12-17 17:54:37.134091</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk has been undefined

'
<i>2024-12-17 17:54:37.134140</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-list --all | grep guest_vsi_disk| wc -l
<i>2024-12-17 17:54:37.154359</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:54:37.154575</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:54:38.943491</td>
    <td>0.34</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:38.943474</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:38.943484</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:38.943487</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:38.943527</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:54:38.943562</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:54:38.943587</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:54:38.943591</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:54:38.991561</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:54:38.991753</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:54:39.270809</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/block-agent-server": [
            {
                "pid": "179901",
                "status": "enforce"
            }
        ],
        "/sbin/coalesce-agent": [
            {
                "pid": "89589",
                "status": "enforce"
            }
        ],
        "/sbin/coalesce-agent-nr": [
            {
                "pid": "169190",
                "status": "enforce"
            }
        ],
        "/sbin/computeproxy": [
            {
                "pid": "169034",
                "status": "enforce"
            }
        ],
        "/sbin/consolemultiplexer": [
            {
                "pid": "169094",
                "status": "enforce"
            }
        ],
        "/sbin/cos-transfer-agent": [
            {
                "pid": "89795",
                "status": "enforce"
            }
        ],
        "/sbin/cos-transfer-agent-nr": [
            {
                "pid": "169251",
                "status": "enforce"
            }
        ],
        "/sbin/dhclient": [
            {
                "pid": "40501",
                "status": "enforce"
            }
        ],
        "/sbin/guestproxysvc": [
            {
                "pid": "88337",
                "status": "enforce"
            }
        ],
        "/sbin/metadataagent": [
            {
                "pid": "179344",
                "status": "enforce"
            },
            {
                "pid": "179754",
                "status": "enforce"
            },
            {
                "pid": "180778",
                "status": "enforce"
            },
            {
                "pid": "180811",
                "status": "enforce"
            }
        ],
        "/sbin/threadbare": [
            {
                "pid": "88447",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "172097",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "196568",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "196576",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "196546",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "196563",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "13635",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "174086",
                "status": "complain"
            },
            {
                "pid": "175260",
                "status": "complain"
            },
            {
                "pid": "175269",
                "status": "complain"
            },
            {
                "pid": "175276",
                "status": "complain"
            },
            {
                "pid": "175290",
                "status": "complain"
            },
            {
                "pid": "175302",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "72950",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "70847",
                "status": "complain"
            },
            {
                "pid": "70903",
                "status": "complain"
            },
            {
                "pid": "70978",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "74175",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "181226",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "92743",
                "status": "enforce"
            },
            {
                "pid": "92764",
                "status": "enforce"
            },
            {
                "pid": "182487",
                "status": "enforce"
            },
            {
                "pid": "182499",
                "status": "enforce"
            }
        ],
        "/{,usr/}sbin/net-block-agent": [
            {
                "pid": "89958",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "141883",
                "status": "enforce"
            },
            {
                "pid": "141907",
                "status": "enforce"
            },
            {
                "pid": "141994",
                "status": "enforce"
            },
            {
                "pid": "170895",
                "status": "enforce"
            },
            {
                "pid": "171043",
                "status": "enforce"
            },
            {
                "pid": "172113",
                "status": "enforce"
            },
            {
                "pid": "172139",
                "status": "enforce"
            },
            {
                "pid": "172312",
                "status": "enforce"
            },
            {
                "pid": "172352",
                "status": "enforce"
            },
            {
                "pid": "172424",
                "status": "enforce"
            },
            {
                "pid": "172473",
                "status": "enforce"
            },
            {
                "pid": "172474",
                "status": "enforce"
            },
            {
                "pid": "173234",
                "status": "enforce"
            },
            {
                "pid": "173255",
                "status": "enforce"
            },
            {
                "pid": "173305",
                "status": "enforce"
            },
            {
                "pid": "173484",
                "status": "enforce"
            },
            {
                "pid": "173556",
                "status": "enforce"
            },
            {
                "pid": "176349",
                "status": "enforce"
            },
            {
                "pid": "177510",
                "status": "enforce"
            }
        ],
        "libvirt-531d1985-3a4b-46e5-9857-3562f93537ea": [
            {
                "pid": "181092",
                "status": "enforce"
            }
        ],
        "libvirt-60973d9f-dc2d-4cd1-833d-fa4bae9a67c5": [
            {
                "pid": "179850",
                "status": "enforce"
            }
        ],
        "libvirt-8ba3f1f9-ae76-46b5-a6c1-527c3ee378f9": [
            {
                "pid": "179485",
                "status": "enforce"
            }
        ],
        "libvirt-96f3a64c-4002-4029-b777-a44021c28925": [
            {
                "pid": "180901",
                "status": "enforce"
            }
        ],
        "libvirtd": [
            {
                "pid": "168952",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/process-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/block-agent-server": "enforce",
        "/sbin/capause": "enforce",
        "/sbin/coalesce-agent": "enforce",
        "/sbin/coalesce-agent-nr": "enforce",
        "/sbin/computeproxy": "enforce",
        "/sbin/consolemultiplexer": "enforce",
        "/sbin/cos-transfer-agent": "enforce",
        "/sbin/cos-transfer-agent-nr": "enforce",
        "/sbin/dhclient": "enforce",
        "/sbin/guestproxysvc": "enforce",
        "/sbin/launch_rmds_agent": "enforce",
        "/sbin/metadataagent": "enforce",
        "/sbin/threadbare": "enforce",
        "/usr/bin/autofs_rclone": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/bin/rclone-agent": "enforce",
        "/usr/bin/rclone-configurator": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/bin/grep": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/bin/mkdir": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/bin/rm": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/find": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/gawk": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/install": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/jq": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/kubectl": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/base64": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/jq": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/wc": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "/{,usr/}sbin/net-block-agent": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "libvirt-531d1985-3a4b-46e5-9857-3562f93537ea": "enforce",
        "libvirt-60973d9f-dc2d-4cd1-833d-fa4bae9a67c5": "enforce",
        "libvirt-8ba3f1f9-ae76-46b5-a6c1-527c3ee378f9": "enforce",
        "libvirt-96f3a64c-4002-4029-b777-a44021c28925": "enforce",
        "libvirtd": "enforce",
        "libvirtd//qemu_bridge_helper": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce",
        "virt-aa-helper": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:54:39.281643</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[399 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[2320 chars]e"}}' != '{"pr[399 chars]", "/sbin/block-agent-server": "enforce", "/sb[2267 chars]e"}}'
Diff is 5961 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:54:39.281797</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:54:39.281986</td>
    <td>1.0</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:39.281974</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:39.281980</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:39.281983</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:39.282012</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:54:39.947579</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:39.947639</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:54:39.947654</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:54:39.947755</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:54:39.947804</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:54:39.947811</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:54:39.992955</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:54:39.993020</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:54:40.274670</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/block-agent-server": [
            {
                "pid": "179901",
                "status": "enforce"
            }
        ],
        "/sbin/coalesce-agent": [
            {
                "pid": "89589",
                "status": "enforce"
            }
        ],
        "/sbin/coalesce-agent-nr": [
            {
                "pid": "169190",
                "status": "enforce"
            }
        ],
        "/sbin/computeproxy": [
            {
                "pid": "169034",
                "status": "enforce"
            }
        ],
        "/sbin/consolemultiplexer": [
            {
                "pid": "169094",
                "status": "enforce"
            }
        ],
        "/sbin/cos-transfer-agent": [
            {
                "pid": "89795",
                "status": "enforce"
            }
        ],
        "/sbin/cos-transfer-agent-nr": [
            {
                "pid": "169251",
                "status": "enforce"
            }
        ],
        "/sbin/dhclient": [
            {
                "pid": "40501",
                "status": "enforce"
            }
        ],
        "/sbin/guestproxysvc": [
            {
                "pid": "88337",
                "status": "enforce"
            }
        ],
        "/sbin/metadataagent": [
            {
                "pid": "179344",
                "status": "enforce"
            },
            {
                "pid": "179754",
                "status": "enforce"
            },
            {
                "pid": "180778",
                "status": "enforce"
            },
            {
                "pid": "180811",
                "status": "enforce"
            }
        ],
        "/sbin/threadbare": [
            {
                "pid": "88447",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "172097",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "196568",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "196576",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "196546",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "196563",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "13635",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "174086",
                "status": "complain"
            },
            {
                "pid": "175260",
                "status": "complain"
            },
            {
                "pid": "175269",
                "status": "complain"
            },
            {
                "pid": "175276",
                "status": "complain"
            },
            {
                "pid": "175290",
                "status": "complain"
            },
            {
                "pid": "175302",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "72950",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "70847",
                "status": "complain"
            },
            {
                "pid": "70903",
                "status": "complain"
            },
            {
                "pid": "70978",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "74175",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "181226",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "92743",
                "status": "enforce"
            },
            {
                "pid": "92764",
                "status": "enforce"
            },
            {
                "pid": "182487",
                "status": "enforce"
            },
            {
                "pid": "182499",
                "status": "enforce"
            }
        ],
        "/{,usr/}sbin/net-block-agent": [
            {
                "pid": "89958",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "141883",
                "status": "enforce"
            },
            {
                "pid": "141907",
                "status": "enforce"
            },
            {
                "pid": "141994",
                "status": "enforce"
            },
            {
                "pid": "170895",
                "status": "enforce"
            },
            {
                "pid": "171043",
                "status": "enforce"
            },
            {
                "pid": "172113",
                "status": "enforce"
            },
            {
                "pid": "172139",
                "status": "enforce"
            },
            {
                "pid": "172312",
                "status": "enforce"
            },
            {
                "pid": "172352",
                "status": "enforce"
            },
            {
                "pid": "172424",
                "status": "enforce"
            },
            {
                "pid": "172473",
                "status": "enforce"
            },
            {
                "pid": "172474",
                "status": "enforce"
            },
            {
                "pid": "173234",
                "status": "enforce"
            },
            {
                "pid": "173255",
                "status": "enforce"
            },
            {
                "pid": "173305",
                "status": "enforce"
            },
            {
                "pid": "173484",
                "status": "enforce"
            },
            {
                "pid": "173556",
                "status": "enforce"
            },
            {
                "pid": "176349",
                "status": "enforce"
            },
            {
                "pid": "177510",
                "status": "enforce"
            }
        ],
        "libvirt-531d1985-3a4b-46e5-9857-3562f93537ea": [
            {
                "pid": "181092",
                "status": "enforce"
            }
        ],
        "libvirt-60973d9f-dc2d-4cd1-833d-fa4bae9a67c5": [
            {
                "pid": "179850",
                "status": "enforce"
            }
        ],
        "libvirt-8ba3f1f9-ae76-46b5-a6c1-527c3ee378f9": [
            {
                "pid": "179485",
                "status": "enforce"
            }
        ],
        "libvirt-96f3a64c-4002-4029-b777-a44021c28925": [
            {
                "pid": "180901",
                "status": "enforce"
            }
        ],
        "libvirtd": [
            {
                "pid": "168952",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/process-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/block-agent-server": "enforce",
        "/sbin/capause": "enforce",
        "/sbin/coalesce-agent": "enforce",
        "/sbin/coalesce-agent-nr": "enforce",
        "/sbin/computeproxy": "enforce",
        "/sbin/consolemultiplexer": "enforce",
        "/sbin/cos-transfer-agent": "enforce",
        "/sbin/cos-transfer-agent-nr": "enforce",
        "/sbin/dhclient": "enforce",
        "/sbin/guestproxysvc": "enforce",
        "/sbin/launch_rmds_agent": "enforce",
        "/sbin/metadataagent": "enforce",
        "/sbin/threadbare": "enforce",
        "/usr/bin/autofs_rclone": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/bin/rclone-agent": "enforce",
        "/usr/bin/rclone-configurator": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/bin/grep": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/bin/mkdir": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/bin/rm": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/find": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/gawk": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/install": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/jq": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/kubectl": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/base64": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/jq": "complain",
        "/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/wc": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "/{,usr/}sbin/net-block-agent": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "libvirt-531d1985-3a4b-46e5-9857-3562f93537ea": "enforce",
        "libvirt-60973d9f-dc2d-4cd1-833d-fa4bae9a67c5": "enforce",
        "libvirt-8ba3f1f9-ae76-46b5-a6c1-527c3ee378f9": "enforce",
        "libvirt-96f3a64c-4002-4029-b777-a44021c28925": "enforce",
        "libvirtd": "enforce",
        "libvirtd//qemu_bridge_helper": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce",
        "virt-aa-helper": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:54:40.284399</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[399 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[2320 chars]e"}}' != '{"pr[399 chars]", "/sbin/block-agent-server": "enforce", "/sb[2267 chars]e"}}'
Diff is 5961 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:54:40.284564</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:40.412296</td>
    <td>0.07</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:40.412276</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:40.412287</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:40.412291</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:40.412358</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:54:40.412389</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:54:40.475737</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:54:40.479271</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
lxd
input
crontab
messagebus
ssh
admin
netdev
uuidd
syslog
sysop
rdma
ceph
nslcd
_lldpd
kvm
libvirt
libvirt-qemu
libvirt-dnsmasq
docker
ssl-cert
postfix
postdrop
tss
frrvty
frr
vault
rmds
consolemux
prometheus
systemd-timesync
sugroup
sysgt
no_user
'
<i>2024-12-17 17:54:40.479551</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:40.479780</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:40.479765</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:40.479774</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:40.479777</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:40.479857</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:54:40.479891</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:54:40.538733</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:54:40.541370</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd::/var/lib/lxd/:/bin/false
messagebus::/nonexistent:/usr/sbin/nologin
sshd::/run/sshd:/usr/sbin/nologin
uuidd::/run/uuidd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
ceph:Ceph storage service:/var/lib/ceph:/usr/sbin/nologin
nslcd:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd::/var/run/lldpd:/usr/sbin/nologin
strongswan::/var/lib/strongswan:/usr/sbin/nologin
libvirt-qemu:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
libvirt-dnsmasq:Libvirt Dnsmasq,,,:/var/lib/libvirt/dnsmasq:/usr/sbin/nologin
postfix::/var/spool/postfix:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
rmds:VPC Metadata Services:/home/rmds:/usr/sbin/nologin
consolemux:VSI Console Multiplexer account:/home/consolemux:/usr/sbin/nologin
genctl:GenCTL User,,,:/home/genctl:/usr/sbin/nologin
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:54:40.541727</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:40.659587</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:40.659570</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:40.659579</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:40.659584</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:40.659684</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.659717</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.659735</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:54:40.659799</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.659814</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:54:40.660357</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.660375</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:54:40.660423</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.660437</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.660450</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:54:40.660509</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.660523</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.660535</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:54:40.661356</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.661373</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:54:40.661556</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:54:40.661572</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release5 : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release5
<i>2024-12-17 17:54:40.682479</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:54:40.684488</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root   0 Dec 17 17:54 cron.allow
drwxr-x--- 2 root root  80 Dec 17 17:54 cron.d
drwxr-x--- 2 root root 340 Dec 17 17:54 cron.daily
drwxr-x--- 2 root root 200 Dec 17 17:54 cron.hourly
drwxr-x--- 2 root root  40 Dec 17 17:54 cron.monthly
drwxr-x--- 2 root root  40 Dec 17 17:54 cron.weekly
-rw-r----- 1 root root 815 Dec 17 17:54 crontab
'
<i>2024-12-17 17:54:40.684526</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:54:40.687456</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:40.687506</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:54:40.687555</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:54:40.687783</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:40.687768</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:40.687775</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:40.687779</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:40.687809</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:54:40.689758</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'*/15 * * * * /usr/bin/rclone_cache_monitor.sh -r 10 -i 10 | /usr/bin/logger -t rclone_cache_monitor
0 0 * * * /usr/bin/nfs-mount-details.sh
0 0 * * * /usr/bin/nfsiostat-collect.sh
* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
'
<i>2024-12-17 17:54:40.689795</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:54:40.691793</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:40.691872</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release5/compute : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/compute
<i>2024-12-17 17:54:40.691899</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release5/compute : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/compute
<i>2024-12-17 17:54:40.691906</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -y --suppress-common-lines -EZbwB /tmp/crontab_data /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/compute
<i>2024-12-17 17:54:40.693837</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger	      <
'
<i>2024-12-17 17:54:40.694028</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown
<i>2024-12-17 17:54:40.694480</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/cronjob_info/test_crontasks.py", line 140, in test_crontab_diff
    self.assertEqual(exit_code, 0, "Diffs in crontab tasks found!")
  File "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 226, in assertEqual
    raise e
  File "/home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
AssertionError: 1 != 0 : Diffs in crontab tasks found!
</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:40.694632</td>
    <td>25.73</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:40.694619</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:54:40.694626</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:54:40.694629</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:40.694653</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:54:40.696773</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:40.696821</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:54:40.698390</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:40.698435</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:54:42.712839</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:42.712911</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:54:42.713002</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:54:42.713011</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:54:42.713019</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:55:04.404670</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
.......
good
'
<i>2024-12-17 17:55:04.404711</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:55:04.404721</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:55:04.407848</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:55:04.407913</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:55:06.421795</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:55:06.422026</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:55:06.532864</td>
    <td>0.13</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:55:06.532847</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:55:06.532857</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:55:06.532861</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:55:06.532916</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:55:06.532921</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:55:06.532925</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:55:06.664789</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

Linked to: nmnode2-05-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:55:06.664983</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:55:06.761983</td>
    <td>0.04</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:55:06.761968</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:55:06.761976</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:55:06.761980</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:55:06.762026</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:55:06.762031</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:55:06.762034</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:55:06.796828</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:55:06.796981</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:55:06.797149</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:55:06.797138</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:55:06.797144</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:55:06.797147</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:55:06.797208</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:55:06.797213</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:55:06.797217</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:55:06.830892</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:55:06.831027</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:55:06.933621</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:55:06.933605</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:55:06.933615</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:55:06.933618</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:55:06.933667</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:55:06.933671</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:55:06.933675</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:55:06.938811</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:55:06.938921</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:55:06.939052</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:55:06.939041</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:55:06.939047</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:55:06.939050</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:55:06.939094</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:55:06.939099</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:55:06.939102</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:55:06.944274</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:55:06.944383</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:55:06.944511</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:55:06.944500</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:55:06.944506</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:55:06.944508</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:55:06.944552</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:55:06.944558</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:55:06.944561</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014282_5962/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:55:06.949800</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:55:06.949940</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:55:07.048537</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s12 (compute)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:55:07.048521</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:55:07.048529</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:04 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:31 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:18:11 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:42 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:55:07.048533</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:55:07.048567</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:55:07.051045</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.E1lVkTMNtWstj9E
'
<i>2024-12-17 17:55:07.051081</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.E1lVkTMNtWstj9E | grep "publickey ssh-rsa"
<i>2024-12-17 17:55:07.052811</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:55:07.052923</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:39:50.691565</td>
    <td>1.43</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:50.691547</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:39:50.691556</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:39:50.691560</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:50.691609</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:39:50.691614</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:39:50.691618</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:39:52.121028</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 4 packets, 478 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     834K  107M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      31M  109G KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3     834K  107M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4      31M  109G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5      31M  109G HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 9592 packets, 576K bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     133K 8105K KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2     133K 8105K KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3      29M  541G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4      29M  541G HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    3020K  334M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      11M 4047M KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3    3008K  333M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4    3008K  333M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5        0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
6    3008K  333M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 62 packets, 4464 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      680  346K KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      618  341K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      680  346K KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      618  341K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5      709  360K HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      791 55184 KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4      800 55688 HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2     1200 69888 KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     1200 69888 HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION
# am-utils.service                     not-found inactive dead    am-utils.service
# apache2.service                      not-found inactive dead    apache2.service
  apparmor.service                     loaded    active   exited  Load AppArmor profiles
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities
# apt-daily.service                    masked    inactive dead    apt-daily.service
# atd.service                          not-found inactive dead    atd.service
  auditd.service                       loaded    active   running Security Auditing Service
  auth-rpcgss-module.service           loaded    inactive dead    Kernel Module supporting RPCSEC_GSS
  autofs.service                       loaded    active   running Automounts filesystems on demand
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats
  blk-availability.service             loaded    active   exited  Availability of block devices
# citadel.service                      not-found inactive dead    citadel.service
  cld-blockagent-server.service        loaded    active   running Genesis block-agent Service
  cld-coalesce-agent-nr.service        loaded    active   running Genesis coalesce-agent-nr Service
  cld-coalesce-agent.service           loaded    active   running Genesis coalesce-agent Service
  cld-computeproxy.service             loaded    active   running Genesis computeproxy Service
  cld-consolemultiplexer.service       loaded    active   running Console Multiplexer Service
  cld-cos-transfer-agent-nr.service    loaded    active   running Genesis cos-transfer-agent-nr Service
  cld-cos-transfer-agent.service       loaded    active   running Genesis cos-transfer-agent Service
  cld-guest-proxy.service              loaded    active   running Instance Metadata Service
  cld-net-block-agent.service          loaded    active   running Genesis net-block-agent Service
  cld-threadbare.service               loaded    active   running threadbare sets CPU process pin policy via sched_setaffinity for compute nodes
  cloud-config.service                 loaded    inactive dead    Cloud-init: Config Stage
  cloud-final.service                  loaded    active   exited  Cloud-init: Final Stage
  cloud-init-hotplugd.service          loaded    inactive dead    Cloud-init: Hotplug Hook
  cloud-init-local.service             loaded    active   exited  Cloud-init: Local Stage (pre-network)
  cloud-init.service                   loaded    active   exited  Cloud-init: Network Stage
  cloudnet-gobgp.service               loaded    inactive dead    gobgpd service
# connman.service                      not-found inactive dead    connman.service
  containerd.service                   loaded    active   running containerd container runtime
# courier-ldap.service                 not-found inactive dead    courier-ldap.service
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service
# courier-mta.service                  not-found inactive dead    courier-mta.service
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service
# courier-pop.service                  not-found inactive dead    courier-pop.service
  cron.service                         loaded    active   running Regular background program processing daemon
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service
  dbus.service                         loaded    active   running D-Bus System Message Bus
# display-manager.service              not-found inactive dead    display-manager.service
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon
  dmesg.service                        loaded    inactive dead    Save initial kernel messages after boot
# dovecot.service                      not-found inactive dead    dovecot.service
  dpkg-db-backup.service               loaded    inactive dead    Daily dpkg database backup service
  e2scrub_all.service                  loaded    inactive dead    Online ext4 Metadata Check for All Filesystems
  e2scrub_reap.service                 loaded    inactive dead    Remove Stale Online ext4 Metadata Check Snapshots
  emergency.service                    loaded    inactive dead    Emergency Shell
# exim4.service                        not-found inactive dead    exim4.service
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor
# fcoe.service                         not-found inactive dead    fcoe.service
  finalrd.service                      loaded    active   exited  Create final runtime dir for shutdown pivot root
# firewalld.service                    not-found inactive dead    firewalld.service
  fluent-bit-ops-logs.service          loaded    inactive dead    Fluent Bit agent forwarding ops logs to remote.
  fluent-bit-qradar.service            loaded    inactive dead    Fluent Bit agent forwarding audit logs to QRadar.
  frr.service                          loaded    active   running FRRouting
  fstrim.service                       loaded    inactive dead    Discard unused blocks on filesystems from /etc/fstab
# gdm3.service                         not-found inactive dead    gdm3.service
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available
  getty@tty1.service                   loaded    active   running Getty on tty1
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes
# gssproxy.service                     not-found inactive dead    gssproxy.service
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service
# hv_kvp_daemon.service                not-found inactive dead    hv_kvp_daemon.service
  ifupdown-pre.service                 loaded    inactive dead    Helper to synchronize boot up for ifupdown
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device
# ip6tables.service                    not-found inactive dead    ip6tables.service
# iptables.service                     not-found inactive dead    iptables.service
  irqbalance.service                   loaded    active   running irqbalance daemon
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service
  iscsid.service                       loaded    inactive dead    iSCSI initiator daemon (iscsid)
# kdm.service                          not-found inactive dead    kdm.service
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system
  kmod-static-nodes.service            loaded    active   exited  Create List of Static Device Nodes
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent
  libvirt-guests.service               loaded    active   exited  Suspend/Resume Running libvirt Guests
  libvirtd.service                     loaded    active   running Virtualization daemon
  lldpd.service                        loaded    active   running LLDP daemon
# logrotate.service                    loaded    failed   failed  Rotate log files
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service
# masqmail.service                     not-found inactive dead    masqmail.service
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.
  modprobe@configfs.service            loaded    inactive dead    Load Kernel Module configfs
  modprobe@drm.service                 loaded    inactive dead    Load Kernel Module drm
  modprobe@efi_pstore.service          loaded    inactive dead    Load Kernel Module efi_pstore
  modprobe@fuse.service                loaded    inactive dead    Load Kernel Module fuse
  motd-news.service                    loaded    inactive dead    Message of the Day
  mst.service                          loaded    active   exited  LSB: mst
  nessusagent.service                  loaded    active   running The Nessus Client Agent
  netplan-ovs-cleanup.service          loaded    inactive dead    OpenVSwitch configuration for cleanup
# network.service                      not-found inactive dead    network.service
  networking.service                   loaded    inactive dead    Raise network interfaces
# NetworkManager.service               not-found inactive dead    NetworkManager.service
# nfs-server.service                   not-found inactive dead    nfs-server.service
  nfs-utils.service                    loaded    inactive dead    NFS server and client services
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon
# nullmailer.service                   not-found inactive dead    nullmailer.service
  nvmefc-boot-connections.service      loaded    inactive dead    Auto-connect to subsystems on FC-NVME devices found during boot
  nvmf-autoconnect.service             loaded    inactive dead    Connect NVMe-oF subsystems automatically during boot
  open-iscsi.service                   loaded    inactive dead    Login to default iSCSI targets
  osqueryd.service                     loaded    active   running The osquery Daemon
# ovsdb-server.service                 not-found inactive dead    ovsdb-server.service
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service
# plymouth-start.service               not-found inactive dead    plymouth-start.service
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics
  qemu-kvm.service                     loaded    active   exited  QEMU KVM preparation - module, ksm, hugepages
# rbdmap.service                       not-found inactive dead    rbdmap.service
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility
  rclone-agent@rclone-agent.service    loaded    inactive dead    rclone wrapper agent service
  rclone-validate.service              loaded    inactive dead    Rclone config validator service
  rescue.service                       loaded    inactive dead    Rescue Shell
  rpc-gssd.service                     loaded    active   running RPC security service for NFS client and server
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.
  rpc-svcgssd.service                  loaded    inactive dead    RPC security service for NFS server
  rpcbind.service                      loaded    active   running RPC bind portmap service
  rsyslog.service                      loaded    active   running System Logging Service
  secureboot-db.service                loaded    inactive dead    Secure Boot updates for DB and DBX
# sendmail.service                     not-found inactive dead    sendmail.service
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1
# set-hostname.service                 not-found inactive dead    set-hostname.service
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service
  skydive.service                      loaded    active   running Skydive
# slapd.service                        not-found inactive dead    slapd.service
# slim.service                         not-found inactive dead    slim.service
# snapd.seeded.service                 not-found inactive dead    snapd.seeded.service
  ssh.service                          loaded    active   running OpenBSD Secure Shell server
# sshd-keygen.service                  not-found inactive dead    sshd-keygen.service
# sssd.service                         not-found inactive dead    sssd.service
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall
  systemd-binfmt.service               loaded    active   exited  Set Up Additional Binary Formats
  systemd-boot-system-token.service    loaded    inactive dead    Store a System Token in an EFI Variable
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status
# systemd-hwdb-update.service          not-found inactive dead    systemd-hwdb-update.service
  systemd-initctl.service              loaded    inactive dead    initctl Compatibility Daemon
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage
  systemd-journald.service             loaded    active   running Journal Service
  systemd-logind.service               loaded    active   running User Login Management
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk
  systemd-machined.service             loaded    active   running Virtual Machine and Container Registration Service
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules
  systemd-networkd-wait-online.service loaded    inactive dead    Wait for Network to be Configured
# systemd-networkd.service             masked    inactive dead    systemd-networkd.service
# systemd-oomd.service                 not-found inactive dead    systemd-oomd.service
  systemd-pstore.service               loaded    inactive dead    Platform Persistent Storage Archival
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems
  systemd-resolved.service             loaded    active   running Network Name Resolution
  systemd-rfkill.service               loaded    inactive dead    Load/Save RF Kill Switch Status
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables
  systemd-sysusers.service             loaded    active   exited  Create System Users
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories
  systemd-udev-trigger.service         loaded    active   exited  Coldplug All udev Devices
  systemd-udevd.service                loaded    active   running Rule-based Manager for Device Events and Files
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service
  systemd-update-utmp-runlevel.service loaded    inactive dead    Record Runlevel Change in UTMP
  systemd-update-utmp.service          loaded    active   exited  Record System Boot/Shutdown in UTMP
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service
  taniumclient.service                 loaded    active   running Tanium Client
  user-runtime-dir@1001.service        loaded    active   exited  User Runtime Directory /run/user/1001
  user@1001.service                    loaded    active   running User Manager for UID 1001
  uuidd.service                        loaded    inactive dead    Daemon for generating UUIDs
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent
  vagentx.service                      loaded    active   running service wrapper around vault agent
  virtlockd.service                    loaded    inactive dead    Virtual machine lock manager
  virtlogd.service                     loaded    active   running Virtual machine log manager
# wdm.service                          not-found inactive dead    wdm.service
# xdm.service                          not-found inactive dead    xdm.service
# xencommons.service                   not-found inactive dead    xencommons.service
# xendomains.service                   not-found inactive dead    xendomains.service
# ypbind.service                       not-found inactive dead    ypbind.service

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.
188 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State  Recv-Q Send-Q      Local Address:Port  Peer Address:PortProcess                                                       
udp   UNCONN 0      0           127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=1096647,fd=13))                
udp   UNCONN 0      0                 0.0.0.0:111        0.0.0.0:*    users:(("rpcbind",pid=1387401,fd=5),("systemd",pid=1,fd=79)) 
udp   UNCONN 0      0               127.0.0.1:682        0.0.0.0:*    users:(("rpc.statd",pid=1187282,fd=5))                       
udp   UNCONN 0      0                 0.0.0.0:4789       0.0.0.0:*                                                                 
udp   UNCONN 0      0             11.50.206.2:50052      0.0.0.0:*    users:(("fabcon_server",pid=1195941,fd=14))                  
udp   UNCONN 0      0                 0.0.0.0:57221      0.0.0.0:*    users:(("rpc.statd",pid=1187282,fd=8))                       
udp   UNCONN 0      0                    [::]:111           [::]:*    users:(("rpcbind",pid=1387401,fd=7),("systemd",pid=1,fd=88)) 
udp   UNCONN 0      0                    [::]:24091         [::]:*    users:(("rpc.statd",pid=1187282,fd=10))                      
tcp   LISTEN 0      16384         169.254.2.0:18067      0.0.0.0:*    users:(("metadataagent",pid=1389029,fd=9))                   
tcp   LISTEN 0      16384         169.254.2.0:18066      0.0.0.0:*    users:(("metadataagent",pid=1387983,fd=9))                   
tcp   LISTEN 0      16384         169.254.2.0:18065      0.0.0.0:*    users:(("metadataagent",pid=1387518,fd=9))                   
tcp   LISTEN 0      1024            127.0.0.1:17473      0.0.0.0:*    users:(("TaniumClient",pid=424633,fd=68))                    
tcp   LISTEN 0      16384           127.0.0.1:27519      0.0.0.0:*    users:(("containerd",pid=1324387,fd=13))                     
tcp   LISTEN 0      128               0.0.0.0:22         0.0.0.0:*    users:(("sshd",pid=1202126,fd=3))                            
tcp   LISTEN 0      4096              0.0.0.0:111        0.0.0.0:*    users:(("rpcbind",pid=1387401,fd=4),("systemd",pid=1,fd=78)) 
tcp   LISTEN 0      4096              0.0.0.0:179        0.0.0.0:*    users:(("bgpd",pid=89225,fd=22))                             
tcp   LISTEN 0      3               127.0.0.1:2616       0.0.0.0:*    users:(("staticd",pid=89232,fd=11))                          
tcp   LISTEN 0      3               127.0.0.1:2605       0.0.0.0:*    users:(("bgpd",pid=89225,fd=18))                             
tcp   LISTEN 0      3               127.0.0.1:2601       0.0.0.0:*    users:(("zebra",pid=89219,fd=27))                            
tcp   LISTEN 0      4096        127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=1096647,fd=14))                
tcp   LISTEN 0      16384           127.0.0.1:9100       0.0.0.0:*    users:(("prometheus-node",pid=1193805,fd=3))                 
tcp   LISTEN 0      16384           127.0.0.1:10249      0.0.0.0:*    users:(("kube-proxy",pid=1333486,fd=9))                      
tcp   LISTEN 0      16384           127.0.0.1:10248      0.0.0.0:*    users:(("kubelet",pid=1348556,fd=20))                        
tcp   LISTEN 0      4096              0.0.0.0:52351      0.0.0.0:*    users:(("rpc.statd",pid=1187282,fd=9))                       
tcp   LISTEN 0      16384         169.254.2.2:18193      0.0.0.0:*    users:(("metadataagent",pid=1387699,fd=9))                   
tcp   LISTEN 0      16384         169.254.2.2:18195      0.0.0.0:*    users:(("metadataagent",pid=1389463,fd=9))                   
tcp   LISTEN 0      16384         169.254.2.2:18194      0.0.0.0:*    users:(("metadataagent",pid=1389008,fd=9))                   
tcp   LISTEN 0      16384           127.0.0.1:50059      0.0.0.0:*    users:(("fabcon_server",pid=1195941,fd=19))                  
tcp   LISTEN 0      16384           127.0.0.1:50055      0.0.0.0:*    users:(("fabcon_server",pid=1195941,fd=17))                  
tcp   LISTEN 0      1024          11.50.206.2:17472      0.0.0.0:*    users:(("TaniumClient",pid=424633,fd=65))                    
tcp   LISTEN 0      1000                    *:16514            *:*    users:(("libvirtd",pid=1190891,fd=6),("systemd",pid=1,fd=54))
tcp   LISTEN 0      128                  [::]:22            [::]:*    users:(("sshd",pid=1202126,fd=4))                            
tcp   LISTEN 0      4096                 [::]:111           [::]:*    users:(("rpcbind",pid=1387401,fd=6),("systemd",pid=1,fd=87)) 
tcp   LISTEN 0      4096                 [::]:179           [::]:*    users:(("bgpd",pid=89225,fd=23))                             
tcp   LISTEN 0      16384                   *:10256            *:*    users:(("kube-proxy",pid=1333486,fd=8))                      
tcp   LISTEN 0      16384                   *:10250            *:*    users:(("kubelet",pid=1348556,fd=24))                        
tcp   LISTEN 0      4096   [::ffff:127.0.0.1]:10514            *:*    users:(("iobricksd",pid=340797,fd=56))                       
tcp   LISTEN 0      16384                   *:50057            *:*    users:(("fabcon_server",pid=1195941,fd=18))                  
tcp   LISTEN 0      16384                   *:50051            *:*    users:(("fabcon_server",pid=1195941,fd=21))                  
tcp   LISTEN 0      4096                    *:51010            *:*    users:(("guestproxysvc",pid=1073846,fd=9))                   
tcp   LISTEN 0      4096                 [::]:34913         [::]:*    users:(("rpc.statd",pid=1187282,fd=11))                      

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

Include /etc/ssh/sshd_config.d/*.conf

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)
KbdInteractiveAuthentication no

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# be allowed through the KbdInteractiveAuthentication and
# PasswordAuthentication.  Depending on your PAM configuration,
# PAM authentication via KbdInteractiveAuthentication may bypass
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
# and KbdInteractiveAuthentication to \'no\'.
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#Compression delayed
#UseDNS no
#PidFile /run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
PubkeyAuthentication yes
PubkeyAcceptedKeyTypes=+ssh-rsa
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Defaults	use_pty

# This preserves proxy settings from user environments of root
# equivalent users (group sudo)
#Defaults:%sudo env_keep += "http_proxy https_proxy ftp_proxy all_proxy no_proxy"

# This allows running arbitrary commands, but so does ALL, and it means
# different sudoers have their choice of editor respected.
#Defaults:%sudo env_keep += "EDITOR"

# Completely harmless preservation of a user preference.
#Defaults:%sudo env_keep += "GREP_COLOR"

# While you shouldn\'t normally run git as root, you need to with etckeeper
#Defaults:%sudo env_keep += "GIT_AUTHOR_* GIT_COMMITTER_*"

# Per-user preferences; root won\'t have sensible values for them.
#Defaults:%sudo env_keep += "EMAIL DEBEMAIL DEBFULLNAME"

# "sudo scp" or "sudo rsync" should be able to use your SSH agent.
#Defaults:%sudo env_keep += "SSH_AGENT_PID SSH_AUTH_SOCK"

# Ditto for GPG agent
#Defaults:%sudo env_keep += "GPG_AGENT_INFO"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "@include" directives:

@includedir /etc/sudoers.d
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:consolemux
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
messagebus:x:104:
systemd-timesync:x:105:
input:x:106:
sgx:x:107:
kvm:x:108:consolemux
render:x:109:
lxd:x:110:
tss:x:111:
_ssh:x:112:
fwupd-refresh:x:113:
admin:x:115:
netdev:x:116:
syslog:x:114:
sysop:x:1001:
crontab:x:117:
nslcd:x:118:
tcpdump:x:119:
_lldpd:x:120:
uuidd:x:121:
rdma:x:122:
libvirt:x:200:consolemux
libvirt-qemu:x:64055:libvirt-qemu
libvirt-dnsmasq:x:124:
swtpm:x:125:
ssl-cert:x:126:
postfix:x:127:
postdrop:x:128:
frrvty:x:129:frr
frr:x:130:
vault:x:999:
rmds:x:998:
consolemux:x:60102:genctl
host-logging:x:60202:
prometheus:x:62700:
docker:x:1002:
sugroup:x:1003:
sysgt:x:1004:
no_user:x:997:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_faillock.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth required                  pam_faillock.so preauth
auth  [success=4 default=ignore] pam_unix.so nullok_secure
auth  [success=3 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth [default=die]              pam_faillock.so authfail
auth sufficient                 pam_faillock.so authsucc
auth required                   pam_deny.so
auth required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so
password [success=2 default=ignore] pam_unix.so obscure remember=5 use_authtok try_first_pass 
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
# pam_selinux.so changes the SELinux context of the used TTY and configures
# SELinux in order to transition to the user context with the next execve()
# call.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/polkit-1 <==
#%PAM-1.0

@include common-auth
@include common-account
@include common-password
session       required   pam_env.so readenv=1 user_readenv=0
session       required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-session-noninteractive

==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_14_55_42 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group wheel
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "wheel" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/su-l <==
#%PAM-1.0
auth		include		su
account		include		su
password	include		su
session		optional	pam_keyinit.so force revoke
session		include		su

==> /etc/pam.d/sudo <==
#%PAM-1.0

# Set up user limits from /etc/security/limits.conf.
session    required   pam_limits.so

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0

@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/sudo-i <==
#%PAM-1.0

# Set up user limits from /etc/security/limits.conf.
session    required   pam_limits.so

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0

@include common-auth
@include common-account
@include common-session

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin
messagebus:x:103:104::/nonexistent:/usr/sbin/nologin
systemd-timesync:x:104:105:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin
tss:x:105:111:TPM software stack,,,:/var/lib/tpm:/bin/false
sshd:x:107:65534::/run/sshd:/usr/sbin/nologin
fwupd-refresh:x:108:113:fwupd-refresh user,,,:/run/systemd:/usr/sbin/nologin
syslog:x:106:114::/home/syslog:/usr/sbin/nologin
sysop:x:1001:1001::/home/sysop:/bin/bash
nslcd:x:109:118:nslcd name service LDAP connection daemon,,,:/run/nslcd:/usr/sbin/nologin
tcpdump:x:110:119::/nonexistent:/usr/sbin/nologin
_lldpd:x:111:120::/run/lldpd:/usr/sbin/nologin
uuidd:x:112:121::/run/uuidd:/usr/sbin/nologin
libvirt-qemu:x:64055:108:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
libvirt-dnsmasq:x:113:124:Libvirt Dnsmasq,,,:/var/lib/libvirt/dnsmasq:/usr/sbin/nologin
swtpm:x:114:125:virtual TPM software stack,,,:/var/lib/swtpm:/bin/false
postfix:x:115:127::/var/spool/postfix:/usr/sbin/nologin
_rpc:x:116:65534::/run/rpcbind:/usr/sbin/nologin
statd:x:117:65534::/var/lib/nfs:/usr/sbin/nologin
frr:x:118:130:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:999::/home/vault:/bin/false
rmds:x:998:998:VPC Metadata Services:/home/rmds:/usr/sbin/nologin
genctl:x:60000:200:GenCTL User,,,:/home/genctl:/usr/sbin/nologin
consolemux:x:60101:60102:VSI Console Multiplexer account:/home/consolemux:/usr/sbin/nologin
host-logging:x:60201:60202:Logging account:/home/host-logging:/usr/sbin/nologin
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
sysgt:x:1002:1004::/home/sysgt:/bin/bash
no_user:x:65535:997:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.49.14604.0
aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        compute-agent-bfb9d                                               3/3     Running     3 (25h ago)   25h     11.50.206.5    dal1-qz2-sr2-rk203-s14   <none>           <none>
genctl        fabcon-manager-msrr4                                              2/2     Running     3 (25h ago)   25h     11.50.206.4    dal1-qz2-sr2-rk203-s14   <none>           <none>
genctl        fluentbit-logs-xqzgm                                              4/4     Running     0             25h     11.50.206.6    dal1-qz2-sr2-rk203-s14   <none>           <none>
genctl        fluentd-qradar-ds-fv55x                                           1/1     Running     0             25h     11.50.206.3    dal1-qz2-sr2-rk203-s14   <none>           <none>
genctl        storage-agent-k4wvc                                               2/2     Running     0             8h      11.50.206.9    dal1-qz2-sr2-rk203-s14   <none>           <none>
kube-system   kube-proxy-fs684                                                  1/1     Running     0             25h     10.22.64.55    dal1-qz2-sr2-rk203-s14   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
83 profiles are loaded.
53 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/process-monitoring
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /sbin/block-agent-server
   /sbin/capause
   /sbin/coalesce-agent
   /sbin/coalesce-agent-nr
   /sbin/computeproxy
   /sbin/consolemultiplexer
   /sbin/cos-transfer-agent
   /sbin/cos-transfer-agent-nr
   /sbin/guestproxysvc
   /sbin/launch_rmds_agent
   /sbin/metadataagent
   /sbin/threadbare
   /usr/bin/autofs_rclone
   /usr/bin/prometheus-node-exporter
   /usr/bin/rclone-agent
   /usr/bin/rclone-configurator
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /{,usr/}sbin/dhclient
   /{,usr/}sbin/net-block-agent
   cri-containerd.apparmor.d
   fluent-bit-logs
   fluentbit-logs
   genctl-ingress-controller
   libvirt-1a2f4cef-208b-4bdf-9b54-7b4248bd29e7
   libvirt-33f22359-a64a-4e96-b914-d2914e5a6d84
   libvirt-524536fa-a847-412c-8b6f-22a438924884
   libvirt-5b5f0fb5-3efb-4a95-8032-7140f5096d81
   libvirt-c8dd410c-781e-46fa-855c-d867ed5c63ec
   libvirt-e513a8fa-5e06-454d-bd2b-ec7f3caf0eb0
   libvirtd
   libvirtd//qemu_bridge_helper
   lsb_release
   nvidia_modprobe
   nvidia_modprobe//kmod
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
   tcpdump
   virt-aa-helper
30 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/find
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/gawk
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/grep
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/install
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/jq
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/kubectl
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/mkdir
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/rm
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/base64
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/jq
   /usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/wc
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
0 profiles are in kill mode.
0 profiles are in unconfined mode.
56 processes have profiles defined.
47 processes are in enforce mode.
   /usr/sbin/block-agent-server (1200850) /sbin/block-agent-server
   /usr/sbin/coalesce-agent (1074750) /sbin/coalesce-agent
   /usr/sbin/coalesce-agent-nr (1191074) /sbin/coalesce-agent-nr
   /usr/sbin/computeproxy (1190973) /sbin/computeproxy
   /usr/sbin/consolemultiplexer (1191018) /sbin/consolemultiplexer
   /usr/sbin/cos-transfer-agent (1076383) /sbin/cos-transfer-agent
   /usr/sbin/cos-transfer-agent-nr (1191113) /sbin/cos-transfer-agent-nr
   /usr/sbin/guestproxysvc (1073846) /sbin/guestproxysvc
   /usr/sbin/metadataagent (1387518) /sbin/metadataagent
   /usr/sbin/metadataagent (1387699) /sbin/metadataagent
   /usr/sbin/metadataagent (1387983) /sbin/metadataagent
   /usr/sbin/metadataagent (1389008) /sbin/metadataagent
   /usr/sbin/metadataagent (1389029) /sbin/metadataagent
   /usr/sbin/metadataagent (1389463) /sbin/metadataagent
   /usr/sbin/threadbare (1073712) /sbin/threadbare
   /usr/bin/prometheus-node-exporter (1193805) 
   /usr/sbin/sshd (1202126) 
   /usr/sbin/sshd (880206) /usr/sbin/sshd//sysop
   /usr/sbin/sshd (880218) /usr/sbin/sshd//sysop
   /usr/sbin/dhclient (3495553) /{,usr/}sbin/dhclient
   /usr/sbin/net-block-agent (1076587) /{,usr/}sbin/net-block-agent
   /usr/bin/ruby (1379168) cri-containerd.apparmor.d
   /usr/bin/ruby (1379199) cri-containerd.apparmor.d
   /usr/bin/dash (1380830) cri-containerd.apparmor.d
   /usr/bin/vault (1380860) cri-containerd.apparmor.d
   /usr/bin/dash (1381166) cri-containerd.apparmor.d
   /usr/bin/vault (1381182) cri-containerd.apparmor.d
   /usr/bin/bash (1381344) cri-containerd.apparmor.d
   /usr/bin/stunnel (1381365) cri-containerd.apparmor.d
   /home/genctl/stunnelserver (1381366) cri-containerd.apparmor.d
   /usr/bin/dash (1382245) cri-containerd.apparmor.d
   /usr/bin/vault (1382260) cri-containerd.apparmor.d
   /bin/ssf-validator-fluentbit (1382291) cri-containerd.apparmor.d
   /fluent-bit/bin/fluent-bit (1382361) cri-containerd.apparmor.d
   /synthetics/datagen (1382421) cri-containerd.apparmor.d
   /fabcon-manager (1385658) cri-containerd.apparmor.d
   /compute-agent (1386258) cri-containerd.apparmor.d
   /usr/bin/dash (3920317) cri-containerd.apparmor.d
   /usr/bin/vault (3920331) cri-containerd.apparmor.d
   /storage-agent (3920388) cri-containerd.apparmor.d
   /usr/bin/qemu-system-x86_64 (1387793) libvirt-1a2f4cef-208b-4bdf-9b54-7b4248bd29e7
   /usr/bin/qemu-system-x86_64 (1389089) libvirt-33f22359-a64a-4e96-b914-d2914e5a6d84
   /usr/bin/qemu-system-x86_64 (1389313) libvirt-524536fa-a847-412c-8b6f-22a438924884
   /usr/bin/qemu-system-x86_64 (1387709) libvirt-5b5f0fb5-3efb-4a95-8032-7140f5096d81
   /usr/bin/qemu-system-x86_64 (1388049) libvirt-c8dd410c-781e-46fa-855c-d867ed5c63ec
   /usr/bin/qemu-system-x86_64 (1389541) libvirt-e513a8fa-5e06-454d-bd2b-ec7f3caf0eb0
   /usr/sbin/libvirtd (1190891) libvirtd
9 processes are in complain mode.
   /usr/lib/frr/bgpd (89225) 
   /usr/lib/frr/staticd (89232) 
   /usr/lib/frr/watchfrr (89205) 
   /usr/lib/frr/zebra (89219) 
   /usr/local/fabcon/fabcon_server (1195941) 
   /usr/local/iobricks/iobricksd (340797) 
   /usr/local/skydive/skydive (339190) 
   /usr/local/skydive/skydive (339221) 
   /usr/local/skydive/skydive (339331) 
0 processes are unconfined but have a profile defined.
0 processes are in mixed mode.
0 processes are in kill mode.
'
<i>2024-12-17 17:39:52.121205</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:39:52.239333</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:52.239319</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:39:52.239327</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:39:52.239330</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:52.239351</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:39:52.239974</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:39:52.240015</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:39:52.240092</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:52.240083</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:39:52.240087</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:39:52.240089</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:52.240108</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'compute'}
<i>2024-12-17 17:39:52.240130</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_memory_info :Collect information for Numa Memory</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:39:52.362665</td>
    <td>0.25</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:52.362653</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:39:52.362659</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:39:52.362662</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:52.362693</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/memory/memory_info_collector.sh : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/memory/memory_info_collector.sh
<i>2024-12-17 17:39:52.362696</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/memory/memory_info_collector.sh/shell_artifacts/memory/memory_info_collector.sh
<i>2024-12-17 17:39:52.362699</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/memory/memory_info_collector.sh
<i>2024-12-17 17:39:52.610878</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Total Memory of the Node ##############</b>

MemTotal:           766477       MB
<b>############ Total Memory of each Numa Node ##############</b>

Node  0  MemTotal:         192102      MB
Node  1  MemTotal:         193477      MB
Node  2  MemTotal:         193524      MB
Node  3  MemTotal:         187374      MB


<b>############ Free Memory of the Node ##############</b>

MemFree:            651469       MB

<b>############ Free Memory of each Numa Node ##############</b>

Node  0  MemFree:          138781      MB
Node  1  MemFree:          181567      MB
Node  2  MemFree:          162410      MB
Node  3  MemFree:          168710      MB


<b>############ Used Memory of the Node ##############</b>

MemUsed:            115007  MB

<b>############ Used Memory of each Numa Node ##############</b>

Node  0  MemUsed:          53320.9     MB
Node  1  MemUsed:          11909.5     MB
Node  2  MemUsed:          31114.1     MB
Node  3  MemUsed:          18663.7     MB

'
<i>2024-12-17 17:39:52.610988</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_verify_memory_info :verify if the freememory for compute node is less than the baseline memory of Gen1/Gen2/Gen3</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:39:52.611118</td>
    <td>0.13</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:39:52.611108</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:39:52.611113</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:39:52.611116</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:39:52.611163</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/memory/memory_data.yml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/memory/memory_data.yml
<i>2024-12-17 17:39:52.614405</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /sys/class/dmi/id/board_vendor
<i>2024-12-17 17:39:52.615970</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Supermicro
'
<i>2024-12-17 17:39:52.615996</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - lspci |grep -i net |egrep -vi 'Virtual|VF'| grep 'AMD Pensando'
<i>2024-12-17 17:39:52.741741</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:39:52.741762</i> <b style="color:rgb(0 133 115);">[INFO]</b> This is a Gen2 node
<i>2024-12-17 17:39:52.741767</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /proc/meminfo | column -t | grep MemFree
<i>2024-12-17 17:39:52.743970</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'MemFree:            667103564    kB
'
<i>2024-12-17 17:39:52.743996</i> <b style="color:rgb(0 133 115);">[INFO]</b> Free Memory in Node (GB):636
<i>2024-12-17 17:39:52.744004</i> <b style="color:rgb(0 133 115);">[INFO]</b> Baseline Memory (GB):638
<i>2024-12-17 17:39:52.744057</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown
<i>2024-12-17 17:39:52.744356</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/memory_info_collection/test_memory_info_collector.py", line 61, in test_verify_memory_info
    self.assertLessEqual(baseline_memory,memory_in_gb, msg="Memory Not sufficient! Free Memory in node is less than or equal to BaselineMemory")
AssertionError: 638 not less than or equal to 636 : Memory Not sufficient! Free Memory in node is less than or equal to BaselineMemory
</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc001_create_ubuntu_vsi :Verify if an Ubuntu vm can be created on hostos hypervisor</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:40:14.888521</td>
    <td>53.54</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:40:14.888503</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:40:14.888509</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:40:14.888512</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:40:14.888561</i> <b style="color:rgb(0 133 115);">[INFO]</b> Running test for VM: ubuntu_bionic
<i>2024-12-17 17:40:14.888685</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg
<i>2024-12-17 17:40:14.888699</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/network_config_debian.cfg : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_debian.cfg
<i>2024-12-17 17:40:14.891339</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_debian.cfg /home/hostos-validate/network_config_hostos_vsi_ubuntu_bionic_ebnpya.cfg
<i>2024-12-17 17:40:14.893240</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:14.893258</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/INTERFACE/ens4/g' /home/hostos-validate/network_config_hostos_vsi_ubuntu_bionic_ebnpya.cfg
<i>2024-12-17 17:40:14.895755</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:14.895763</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/IP_ADDRESS/192.167.128.107/g' /home/hostos-validate/network_config_hostos_vsi_ubuntu_bionic_ebnpya.cfg
<i>2024-12-17 17:40:14.897681</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:14.897697</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cloud-localds -v --network-config=/home/hostos-validate/network_config_hostos_vsi_ubuntu_bionic_ebnpya.cfg /home/hostos-validate/cld-init-hostos_vsi_ubuntu_bionic_ebnpya /home/hostos-validate/cloud_config_hostos_vsi_ubuntu_bionic_ebnpya.cfg
<i>2024-12-17 17:40:14.910312</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'wrote /home/hostos-validate/cld-init-hostos_vsi_ubuntu_bionic_ebnpya with filesystem=iso9660 and diskformat=raw
'
<i>2024-12-17 17:40:14.910326</i> <b style="color:rgb(0 133 115);">[INFO]</b> cloud-init image: cld-init-hostos_vsi_ubuntu_bionic_ebnpya created successfully
<i>2024-12-17 17:40:14.910342</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/generic_vsi.xml /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.xml
<i>2024-12-17 17:40:14.911952</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:14.911972</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /tmp/hostos_images/ubuntu-bionic-amd64-20220607.qcow2 /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.qcow2
<i>2024-12-17 17:40:15.120944</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:15.120991</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_ubuntu_bionic_ebnpya/' /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.xml
<i>2024-12-17 17:40:15.123326</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:15.123357</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CLOUDINIT_IMAGE_PATH/\/home\/hostos-validate\/cld-init-hostos_vsi_ubuntu_bionic_ebnpya/' /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.xml
<i>2024-12-17 17:40:15.125026</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:15.125042</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh capabilities | grep model | head -1
<i>2024-12-17 17:40:15.202853</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'      <model>Cascadelake-Server-noTSX</model>
'
<i>2024-12-17 17:40:15.202896</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CPU_MODEL/Cascadelake-Server-noTSX/' /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.xml
<i>2024-12-17 17:40:15.204555</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:15.204569</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.qcow2+'  /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.xml
<i>2024-12-17 17:40:15.206147</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:40:15.206160</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating VSI : hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:40:15.206164</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh define /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.xml
<i>2024-12-17 17:40:15.239325</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_ubuntu_bionic_ebnpya' defined from /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.xml

"
<i>2024-12-17 17:40:15.239339</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:40:16.189118</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_ubuntu_bionic_ebnpya' started

"
<i>2024-12-17 17:40:16.189253</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list | grep hostos_vsi_ubuntu_bionic_ebnpya | awk '{print $3}'
<i>2024-12-17 17:40:16.204361</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'running
'
<i>2024-12-17 17:40:16.204481</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","uname"], "capture-output": true}}'
<i>2024-12-17 17:40:16.218130</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1303}}

'
<i>2024-12-17 17:40:16.218185</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1303}}'
<i>2024-12-17 17:40:16.229879</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:40:16.229898</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:16.229931</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:40:16.229937</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:40:24.238103</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1303}}'
<i>2024-12-17 17:40:24.252602</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMTA3IHBvcnQgMjI6IE5vIHJvdXRlIHRvIGhvc3QNCg==","exited":true}}

'
<i>2024-12-17 17:40:24.252665</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:24.252731</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:40:24.252740</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:40:44.272701</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","uname"], "capture-output": true}}'
<i>2024-12-17 17:40:44.293784</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1388}}

'
<i>2024-12-17 17:40:44.293856</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1388}}'
<i>2024-12-17 17:40:44.310928</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:40:44.310956</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:44.311008</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:40:44.311016</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:40:52.319181</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1388}}'
<i>2024-12-17 17:40:52.333943</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"err-data":"V2FybmluZzogUGVybWFuZW50bHkgYWRkZWQgJzE5Mi4xNjcuMTI4LjEwNycgKEVDRFNBKSB0byB0aGUgbGlzdCBvZiBrbm93biBob3N0cy4NCg==","out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:40:52.333970</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:52.334037</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:40:52.334042</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:40:52.334059</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","uname -srmpoi"], "capture-output": true}}'
<i>2024-12-17 17:40:52.346107</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1390}}

'
<i>2024-12-17 17:40:52.346147</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1390}}'
<i>2024-12-17 17:40:52.356978</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:40:52.356992</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:40:52.357017</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:40:52.357023</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:00.364762</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1390}}'
<i>2024-12-17 17:41:00.379408</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXggNS40LjAtMTAyMy1pYm0geDg2XzY0IHg4Nl82NCB4ODZfNjQgR05VL0xpbnV4Cg==","exited":true}}

'
<i>2024-12-17 17:41:00.379446</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:00.379519</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:00.379603</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","cat /etc/os-release | grep PRETTY_NAME"], "capture-output": true}}'
<i>2024-12-17 17:41:00.393768</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1391}}

'
<i>2024-12-17 17:41:00.393834</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1391}}'
<i>2024-12-17 17:41:00.406443</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:00.406470</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:00.406508</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:00.406517</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:08.412775</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1391}}'
<i>2024-12-17 17:41:08.428329</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"UFJFVFRZX05BTUU9IlVidW50dSAxOC4wNC42IExUUyIK","exited":true}}

'
<i>2024-12-17 17:41:08.428359</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:08.428425</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:08.428534</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc002_create_rhel_vsi :Verify if an Redhat vm can be created on hostos hypervisor</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:41:08.428721</td>
    <td>53.79</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:41:08.428708</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:41:08.428715</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:41:08.428718</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:41:08.428753</i> <b style="color:rgb(0 133 115);">[INFO]</b> Running test for VM: rhel_8_6
<i>2024-12-17 17:41:08.428863</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg
<i>2024-12-17 17:41:08.428872</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/network_config_rhel.cfg : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_rhel.cfg
<i>2024-12-17 17:41:08.430992</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_rhel.cfg /home/hostos-validate/network_config_hostos_vsi_rhel_8_6_zk54hz.cfg
<i>2024-12-17 17:41:08.433004</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:08.433023</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/INTERFACE/ens4/g' /home/hostos-validate/network_config_hostos_vsi_rhel_8_6_zk54hz.cfg
<i>2024-12-17 17:41:08.434691</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:08.434705</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/IP_ADDRESS/192.167.128.97/g' /home/hostos-validate/network_config_hostos_vsi_rhel_8_6_zk54hz.cfg
<i>2024-12-17 17:41:08.436354</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:08.436368</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cloud-localds -v --network-config=/home/hostos-validate/network_config_hostos_vsi_rhel_8_6_zk54hz.cfg /home/hostos-validate/cld-init-hostos_vsi_rhel_8_6_zk54hz /home/hostos-validate/cloud_config_hostos_vsi_rhel_8_6_zk54hz.cfg
<i>2024-12-17 17:41:08.449029</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'wrote /home/hostos-validate/cld-init-hostos_vsi_rhel_8_6_zk54hz with filesystem=iso9660 and diskformat=raw
'
<i>2024-12-17 17:41:08.449043</i> <b style="color:rgb(0 133 115);">[INFO]</b> cloud-init image: cld-init-hostos_vsi_rhel_8_6_zk54hz created successfully
<i>2024-12-17 17:41:08.449062</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/generic_vsi.xml /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.xml
<i>2024-12-17 17:41:08.450726</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:08.450746</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /tmp/hostos_images/rhel-8.6-x86_64-11052022.qcow2 /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.qcow2
<i>2024-12-17 17:41:08.755875</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:08.755925</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_rhel_8_6_zk54hz/' /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.xml
<i>2024-12-17 17:41:08.758364</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:08.758402</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CLOUDINIT_IMAGE_PATH/\/home\/hostos-validate\/cld-init-hostos_vsi_rhel_8_6_zk54hz/' /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.xml
<i>2024-12-17 17:41:08.760192</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:08.760216</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh capabilities | grep model | head -1
<i>2024-12-17 17:41:08.859178</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'      <model>Cascadelake-Server-noTSX</model>
'
<i>2024-12-17 17:41:08.859230</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CPU_MODEL/Cascadelake-Server-noTSX/' /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.xml
<i>2024-12-17 17:41:08.860902</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:08.860918</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.qcow2+'  /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.xml
<i>2024-12-17 17:41:08.862457</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:41:08.862471</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating VSI : hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:41:08.862475</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh define /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.xml
<i>2024-12-17 17:41:08.959208</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_rhel_8_6_zk54hz' defined from /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.xml

"
<i>2024-12-17 17:41:08.959245</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:41:09.953256</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_rhel_8_6_zk54hz' started

"
<i>2024-12-17 17:41:09.953485</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list | grep hostos_vsi_rhel_8_6_zk54hz | awk '{print $3}'
<i>2024-12-17 17:41:09.969655</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'running
'
<i>2024-12-17 17:41:09.969777</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.97","uname"], "capture-output": true}}'
<i>2024-12-17 17:41:09.987623</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1395}}

'
<i>2024-12-17 17:41:09.987692</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1395}}'
<i>2024-12-17 17:41:09.999854</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:09.999879</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:09.999933</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:09.999940</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:18.005755</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1395}}'
<i>2024-12-17 17:41:18.023418</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguOTcgcG9ydCAyMjogTm8gcm91dGUgdG8gaG9zdA0K","exited":true}}

'
<i>2024-12-17 17:41:18.023444</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:18.023511</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:18.023518</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:41:38.040955</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.97","uname"], "capture-output": true}}'
<i>2024-12-17 17:41:38.063305</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1515}}

'
<i>2024-12-17 17:41:38.063364</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1515}}'
<i>2024-12-17 17:41:38.074739</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:38.074761</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:38.074797</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:38.074803</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:46.081001</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1515}}'
<i>2024-12-17 17:41:46.096278</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"err-data":"V2FybmluZzogUGVybWFuZW50bHkgYWRkZWQgJzE5Mi4xNjcuMTI4Ljk3JyAoRUNEU0EpIHRvIHRoZSBsaXN0IG9mIGtub3duIGhvc3RzLg0K","out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:41:46.096311</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:46.096376</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:46.096382</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:41:46.096396</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.97","uname -srmpoi"], "capture-output": true}}'
<i>2024-12-17 17:41:46.112393</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1531}}

'
<i>2024-12-17 17:41:46.112442</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1531}}'
<i>2024-12-17 17:41:46.126333</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:46.126351</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:46.126382</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:46.126388</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:41:54.130352</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1531}}'
<i>2024-12-17 17:41:54.145867</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXggNC4xOC4wLTM3Mi45LjEuZWw4Lng4Nl82NCB4ODZfNjQgeDg2XzY0IHg4Nl82NCBHTlUvTGludXgK","exited":true}}

'
<i>2024-12-17 17:41:54.145896</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:54.145964</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:41:54.146041</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.97","cat /etc/os-release | grep PRETTY_NAME"], "capture-output": true}}'
<i>2024-12-17 17:41:54.177153</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1532}}

'
<i>2024-12-17 17:41:54.177208</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1532}}'
<i>2024-12-17 17:41:54.187968</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:41:54.187986</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:41:54.188013</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:41:54.188020</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:42:02.196157</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1532}}'
<i>2024-12-17 17:42:02.215475</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"UFJFVFRZX05BTUU9IlJlZCBIYXQgRW50ZXJwcmlzZSBMaW51eCA4LjYgKE9vdHBhKSIK","exited":true}}

'
<i>2024-12-17 17:42:02.215505</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:02.215572</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:42:02.215676</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc003_create_centos_vsi :Verify if a Centos vm can be created on hostos hypervisor</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:42:02.215824</td>
    <td>255.65</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:42:02.215813</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:42:02.215819</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:42:02.215821</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:42:02.215850</i> <b style="color:rgb(0 133 115);">[INFO]</b> Running test for VM: centos_7_9
<i>2024-12-17 17:42:02.215946</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg
<i>2024-12-17 17:42:02.215955</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/network_config_centos.cfg : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_centos.cfg
<i>2024-12-17 17:42:02.218092</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_centos.cfg /home/hostos-validate/network_config_hostos_vsi_centos_7_9_jx2r45.cfg
<i>2024-12-17 17:42:02.221864</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:02.221879</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/INTERFACE/ens4/g' /home/hostos-validate/network_config_hostos_vsi_centos_7_9_jx2r45.cfg
<i>2024-12-17 17:42:02.224823</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:02.224837</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/IP_ADDRESS/192.167.128.0/g' /home/hostos-validate/network_config_hostos_vsi_centos_7_9_jx2r45.cfg
<i>2024-12-17 17:42:02.227450</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:02.227464</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cloud-localds -v --network-config=/home/hostos-validate/network_config_hostos_vsi_centos_7_9_jx2r45.cfg /home/hostos-validate/cld-init-hostos_vsi_centos_7_9_jx2r45 /home/hostos-validate/cloud_config_hostos_vsi_centos_7_9_jx2r45.cfg
<i>2024-12-17 17:42:02.246177</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'wrote /home/hostos-validate/cld-init-hostos_vsi_centos_7_9_jx2r45 with filesystem=iso9660 and diskformat=raw
'
<i>2024-12-17 17:42:02.246190</i> <b style="color:rgb(0 133 115);">[INFO]</b> cloud-init image: cld-init-hostos_vsi_centos_7_9_jx2r45 created successfully
<i>2024-12-17 17:42:02.246205</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/generic_vsi.xml /home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.xml
<i>2024-12-17 17:42:02.248709</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:02.248727</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /tmp/hostos_images/centos-7.9-x86_64_sparsified.qcow2 /home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.qcow2
<i>2024-12-17 17:42:02.495023</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:02.495068</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_centos_7_9_jx2r45/' /home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.xml
<i>2024-12-17 17:42:02.498490</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:02.498523</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CLOUDINIT_IMAGE_PATH/\/home\/hostos-validate\/cld-init-hostos_vsi_centos_7_9_jx2r45/' /home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.xml
<i>2024-12-17 17:42:02.501087</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:02.501104</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh capabilities | grep model | head -1
<i>2024-12-17 17:42:02.610263</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'      <model>Cascadelake-Server-noTSX</model>
'
<i>2024-12-17 17:42:02.610333</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CPU_MODEL/Cascadelake-Server-noTSX/' /home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.xml
<i>2024-12-17 17:42:02.612171</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:02.612192</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.qcow2+'  /home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.xml
<i>2024-12-17 17:42:02.614114</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:42:02.614129</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating VSI : hostos_vsi_centos_7_9_jx2r45
<i>2024-12-17 17:42:02.614134</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh define /home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.xml
<i>2024-12-17 17:42:02.666656</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_centos_7_9_jx2r45' defined from /home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.xml

"
<i>2024-12-17 17:42:02.666670</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_centos_7_9_jx2r45
<i>2024-12-17 17:42:03.659656</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_centos_7_9_jx2r45' started

"
<i>2024-12-17 17:42:03.659787</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list | grep hostos_vsi_centos_7_9_jx2r45 | awk '{print $3}'
<i>2024-12-17 17:42:03.673704</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'running
'
<i>2024-12-17 17:42:03.673813</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:42:03.689582</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1533}}

'
<i>2024-12-17 17:42:03.689635</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1533}}'
<i>2024-12-17 17:42:03.700125</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:42:03.700145</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:03.700199</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:42:03.700205</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:42:23.716702</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:42:23.735404</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1534}}

'
<i>2024-12-17 17:42:23.735494</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1534}}'
<i>2024-12-17 17:42:23.750920</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:42:23.750937</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:23.750978</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:42:23.750985</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:42:43.770312</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:42:43.787159</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1535}}

'
<i>2024-12-17 17:42:43.787213</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1535}}'
<i>2024-12-17 17:42:43.800199</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:42:43.800220</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:42:43.800267</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:42:43.800277</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:43:03.820416</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:43:03.837666</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1536}}

'
<i>2024-12-17 17:43:03.837716</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1536}}'
<i>2024-12-17 17:43:03.853372</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:43:03.853403</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:43:03.853459</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:43:03.853468</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:43:23.873645</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:43:23.889051</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1537}}

'
<i>2024-12-17 17:43:23.889109</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1537}}'
<i>2024-12-17 17:43:23.900949</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:43:23.900965</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:43:23.901009</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:43:23.901016</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:43:43.920742</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:43:43.936038</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1538}}

'
<i>2024-12-17 17:43:43.936092</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1538}}'
<i>2024-12-17 17:43:43.947788</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:43:43.947806</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:43:43.947853</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:43:43.947861</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:44:03.964816</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:44:03.981068</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1539}}

'
<i>2024-12-17 17:44:03.981123</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1539}}'
<i>2024-12-17 17:44:03.992622</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:44:03.992639</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:44:03.992683</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:44:03.992690</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:44:24.012782</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:44:24.029899</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1540}}

'
<i>2024-12-17 17:44:24.029961</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1540}}'
<i>2024-12-17 17:44:24.042021</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:44:24.042038</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:44:24.042084</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:44:24.042090</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:44:44.060690</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:44:44.077656</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1541}}

'
<i>2024-12-17 17:44:44.077741</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1541}}'
<i>2024-12-17 17:44:44.090681</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:44:44.090704</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:44:44.090756</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:44:44.090763</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:45:04.094766</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:45:04.110406</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1543}}

'
<i>2024-12-17 17:45:04.110467</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1543}}'
<i>2024-12-17 17:45:04.122105</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:45:04.122125</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:45:04.122174</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:45:04.122182</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:45:24.140791</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.0","uname"], "capture-output": true}}'
<i>2024-12-17 17:45:24.156471</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1544}}

'
<i>2024-12-17 17:45:24.156532</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1544}}'
<i>2024-12-17 17:45:24.168516</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMCBwb3J0IDIyOiBOZXR3b3JrIGlzIHVucmVhY2hhYmxlDQo=","exited":true}}

'
<i>2024-12-17 17:45:24.168537</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:45:24.168589</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:45:24.168603</i> <b style="color:rgb(0 133 115);">[INFO]</b> Retrying attempt: 1
<i>2024-12-17 17:45:24.168718</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/cloud_config_generic.cfg
<i>2024-12-17 17:45:24.168729</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudinit_templates/network_config_centos.cfg : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_centos.cfg
<i>2024-12-17 17:45:24.170727</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudinit_templates/network_config_centos.cfg /home/hostos-validate/network_config_hostos_vsi_centos_7_9_jmulsc.cfg
<i>2024-12-17 17:45:24.172478</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:45:24.172498</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/INTERFACE/ens4/g' /home/hostos-validate/network_config_hostos_vsi_centos_7_9_jmulsc.cfg
<i>2024-12-17 17:45:24.174162</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:45:24.174178</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/IP_ADDRESS/192.167.128.193/g' /home/hostos-validate/network_config_hostos_vsi_centos_7_9_jmulsc.cfg
<i>2024-12-17 17:45:24.175697</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:45:24.175711</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cloud-localds -v --network-config=/home/hostos-validate/network_config_hostos_vsi_centos_7_9_jmulsc.cfg /home/hostos-validate/cld-init-hostos_vsi_centos_7_9_jmulsc /home/hostos-validate/cloud_config_hostos_vsi_centos_7_9_jmulsc.cfg
<i>2024-12-17 17:45:24.190208</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'wrote /home/hostos-validate/cld-init-hostos_vsi_centos_7_9_jmulsc with filesystem=iso9660 and diskformat=raw
'
<i>2024-12-17 17:45:24.190242</i> <b style="color:rgb(0 133 115);">[INFO]</b> cloud-init image: cld-init-hostos_vsi_centos_7_9_jmulsc created successfully
<i>2024-12-17 17:45:24.190268</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/generic_vsi.xml /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.xml
<i>2024-12-17 17:45:24.192020</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:45:24.192041</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /tmp/hostos_images/centos-7.9-x86_64_sparsified.qcow2 /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.qcow2
<i>2024-12-17 17:45:24.472296</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:45:24.472331</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_centos_7_9_jmulsc/' /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.xml
<i>2024-12-17 17:45:24.475901</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:45:24.475918</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CLOUDINIT_IMAGE_PATH/\/home\/hostos-validate\/cld-init-hostos_vsi_centos_7_9_jmulsc/' /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.xml
<i>2024-12-17 17:45:24.478638</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:45:24.478654</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh capabilities | grep model | head -1
<i>2024-12-17 17:45:24.583141</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'      <model>Cascadelake-Server-noTSX</model>
'
<i>2024-12-17 17:45:24.583178</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CPU_MODEL/Cascadelake-Server-noTSX/' /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.xml
<i>2024-12-17 17:45:24.584921</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:45:24.584933</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.qcow2+'  /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.xml
<i>2024-12-17 17:45:24.586439</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:45:24.586451</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating VSI : hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:45:24.586455</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh define /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.xml
<i>2024-12-17 17:45:24.638559</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_centos_7_9_jmulsc' defined from /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.xml

"
<i>2024-12-17 17:45:24.638571</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:45:25.637914</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_centos_7_9_jmulsc' started

"
<i>2024-12-17 17:45:25.638063</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list | grep hostos_vsi_centos_7_9_jmulsc | awk '{print $3}'
<i>2024-12-17 17:45:25.652835</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'running
'
<i>2024-12-17 17:45:25.652930</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.193","uname"], "capture-output": true}}'
<i>2024-12-17 17:45:25.665480</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1545}}

'
<i>2024-12-17 17:45:25.665526</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1545}}'
<i>2024-12-17 17:45:25.675993</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:45:25.676007</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:45:25.676034</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:45:25.676039</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:45:33.683502</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1545}}'
<i>2024-12-17 17:45:33.698652</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMTkzIHBvcnQgMjI6IE5vIHJvdXRlIHRvIGhvc3QNCg==","exited":true}}

'
<i>2024-12-17 17:45:33.698676</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:45:33.698736</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:45:33.698745</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:45:53.708759</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.193","uname"], "capture-output": true}}'
<i>2024-12-17 17:45:53.727654</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1546}}

'
<i>2024-12-17 17:45:53.727711</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1546}}'
<i>2024-12-17 17:45:53.739392</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:45:53.739409</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:45:53.739459</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:45:53.739467</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:46:01.744708</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1546}}'
<i>2024-12-17 17:46:01.762878</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"err-data":"V2FybmluZzogUGVybWFuZW50bHkgYWRkZWQgJzE5Mi4xNjcuMTI4LjE5MycgKEVDRFNBKSB0byB0aGUgbGlzdCBvZiBrbm93biBob3N0cy4NCg==","out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:46:01.762901</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:46:01.762960</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:46:01.762966</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:46:01.762979</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.193","uname -srmpoi"], "capture-output": true}}'
<i>2024-12-17 17:46:01.778948</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1547}}

'
<i>2024-12-17 17:46:01.778987</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1547}}'
<i>2024-12-17 17:46:01.793512</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:46:01.793530</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:46:01.793555</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:46:01.793562</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:46:09.801721</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1547}}'
<i>2024-12-17 17:46:09.817060</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXggMy4xMC4wLTExNjAuNzEuMS5lbDcueDg2XzY0IHg4Nl82NCB4ODZfNjQgeDg2XzY0IEdOVS9MaW51eAo=","exited":true}}

'
<i>2024-12-17 17:46:09.817083</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:46:09.817145</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:46:09.817230</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.193","cat /etc/os-release | grep PRETTY_NAME"], "capture-output": true}}'
<i>2024-12-17 17:46:09.830293</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1548}}

'
<i>2024-12-17 17:46:09.830339</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1548}}'
<i>2024-12-17 17:46:09.841395</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:46:09.841409</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:46:09.841438</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:46:09.841445</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:46:17.848795</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1548}}'
<i>2024-12-17 17:46:17.863774</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"UFJFVFRZX05BTUU9IkNlbnRPUyBMaW51eCA3IChDb3JlKSIK","exited":true}}

'
<i>2024-12-17 17:46:17.863796</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:46:17.863855</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:46:17.863958</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc004_create_windows_vsi :Verify if a Windows vm can be created on hostos hypervisor</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:46:17.864138</td>
    <td>497.97</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:46:17.864120</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:46:17.864129</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:46:17.864133</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:46:17.864174</i> <b style="color:rgb(0 133 115);">[INFO]</b> Running test for VM: windows_10
<i>2024-12-17 17:46:17.864290</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudbaseinit_templates/meta_data.json : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudbaseinit_templates/meta_data.json
<i>2024-12-17 17:46:17.864300</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/cloudbaseinit_templates/user_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudbaseinit_templates/user_data
<i>2024-12-17 17:46:17.864306</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mkdir -pv /home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2/openstack/latest
<i>2024-12-17 17:46:17.866034</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"mkdir: created directory '/home/hostos-validate/hostos_vsi_windows_10_ybj8gd'
mkdir: created directory '/home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2'
mkdir: created directory '/home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2/openstack'
mkdir: created directory '/home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2/openstack/latest'
"
<i>2024-12-17 17:46:17.866053</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudbaseinit_templates/meta_data.json /home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2/openstack/latest/meta_data.json
<i>2024-12-17 17:46:17.867885</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:17.867900</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_windows_10_ybj8gd/g' /home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2/openstack/latest/meta_data.json
<i>2024-12-17 17:46:17.869530</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:17.869545</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/PASSWORD/XWwUjZ0nEXOo57dze2iO/g' /home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2/openstack/latest/meta_data.json
<i>2024-12-17 17:46:17.871077</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:17.871091</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/cloudbaseinit_templates/user_data /home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2/openstack/latest/user_data
<i>2024-12-17 17:46:17.872568</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:17.872581</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/IP_ADDRESS/192.167.128.100/g' /home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2/openstack/latest/user_data
<i>2024-12-17 17:46:17.874210</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:17.874222</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/INTERFACE_NAME/Ethernet Instance 0/g' /home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2/openstack/latest/user_data
<i>2024-12-17 17:46:17.875727</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:17.875741</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - genisoimage -input-charset utf-8 -joliet -rock -volid config-2 -output /home/hostos-validate/cld-init-hostos_vsi_windows_10_ybj8gd /home/hostos-validate/hostos_vsi_windows_10_ybj8gd/config-2
<i>2024-12-17 17:46:17.879475</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Total translation table size: 0
Total rockridge attributes bytes: 763
Total directory bytes: 4096
Path table size(bytes): 40
Max brk space used 23000
187 extents written (0 MB)
'
<i>2024-12-17 17:46:17.879487</i> <b style="color:rgb(0 133 115);">[INFO]</b> cloudbase-init image: cld-init-hostos_vsi_windows_10_ybj8gd created successfully
<i>2024-12-17 17:46:17.879494</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/generic_vsi.xml /home/hostos-validate/hostos_vsi_windows_10_ybj8gd.xml
<i>2024-12-17 17:46:17.881102</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:17.881122</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /tmp/hostos_images/win-2k19-std-040822.qcow2 /home/hostos-validate/hostos_vsi_windows_10_ybj8gd.qcow2
<i>2024-12-17 17:46:25.761694</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:25.761734</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/VSI_NAME/hostos_vsi_windows_10_ybj8gd/' /home/hostos-validate/hostos_vsi_windows_10_ybj8gd.xml
<i>2024-12-17 17:46:25.764059</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:25.764079</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CLOUDINIT_IMAGE_PATH/\/home\/hostos-validate\/cld-init-hostos_vsi_windows_10_ybj8gd/' /home/hostos-validate/hostos_vsi_windows_10_ybj8gd.xml
<i>2024-12-17 17:46:25.765764</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:25.765780</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh capabilities | grep model | head -1
<i>2024-12-17 17:46:25.862359</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'      <model>Cascadelake-Server-noTSX</model>
'
<i>2024-12-17 17:46:25.862404</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's/CPU_MODEL/Cascadelake-Server-noTSX/' /home/hostos-validate/hostos_vsi_windows_10_ybj8gd.xml
<i>2024-12-17 17:46:25.864088</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:25.864102</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_windows_10_ybj8gd.qcow2+'  /home/hostos-validate/hostos_vsi_windows_10_ybj8gd.xml
<i>2024-12-17 17:46:25.865735</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:46:25.865749</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating VSI : hostos_vsi_windows_10_ybj8gd
<i>2024-12-17 17:46:25.865753</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh define /home/hostos-validate/hostos_vsi_windows_10_ybj8gd.xml
<i>2024-12-17 17:46:25.915132</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_windows_10_ybj8gd' defined from /home/hostos-validate/hostos_vsi_windows_10_ybj8gd.xml

"
<i>2024-12-17 17:46:25.915146</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_windows_10_ybj8gd
<i>2024-12-17 17:46:26.898240</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_windows_10_ybj8gd' started

"
<i>2024-12-17 17:46:26.898387</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list | grep hostos_vsi_windows_10_ybj8gd | awk '{print $3}'
<i>2024-12-17 17:46:26.915210</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'running
'
<i>2024-12-17 17:46:26.915321</i> <b style="color:rgb(0 133 115);">[INFO]</b> Waiting for VSI network connectivity...
<i>2024-12-17 17:46:26.915341</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:46:26.931135</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1549}}

'
<i>2024-12-17 17:46:26.931190</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1549}}'
<i>2024-12-17 17:46:26.942551</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:46:26.942584</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:46:26.942619</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:46:26.942626</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:46:34.950782</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1549}}'
<i>2024-12-17 17:46:34.965261</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:46:34.965282</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:46:34.965345</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:46:34.965352</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:47:15.004024</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:47:15.020411</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1553}}

'
<i>2024-12-17 17:47:15.020470</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1553}}'
<i>2024-12-17 17:47:15.032333</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:47:15.032350</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:47:15.032382</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:47:15.032389</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:47:23.040544</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1553}}'
<i>2024-12-17 17:47:23.055317</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:47:23.055340</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:47:23.055402</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:47:23.055410</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:48:03.067648</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:48:03.083932</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1554}}

'
<i>2024-12-17 17:48:03.083986</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1554}}'
<i>2024-12-17 17:48:03.095432</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:48:03.095447</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:48:03.095476</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:48:03.095482</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:48:11.100672</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1554}}'
<i>2024-12-17 17:48:11.115118</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:48:11.115140</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:48:11.115200</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:48:11.115208</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:48:51.117498</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:48:51.148069</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1555}}

'
<i>2024-12-17 17:48:51.148120</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1555}}'
<i>2024-12-17 17:48:51.159547</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:48:51.159562</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:48:51.159588</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:48:51.159593</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:48:59.167756</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1555}}'
<i>2024-12-17 17:48:59.182568</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:48:59.182589</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:48:59.182650</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:48:59.182658</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:49:39.222821</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:49:39.238324</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1556}}

'
<i>2024-12-17 17:49:39.238383</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1556}}'
<i>2024-12-17 17:49:39.250347</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:49:39.250363</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:49:39.250397</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:49:39.250404</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:49:47.252668</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1556}}'
<i>2024-12-17 17:49:47.267415</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:49:47.267443</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:49:47.267513</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:49:47.267522</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:50:27.303140</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:50:27.320587</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1558}}

'
<i>2024-12-17 17:50:27.320660</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1558}}'
<i>2024-12-17 17:50:27.333253</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:50:27.333272</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:50:27.333304</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:50:27.333311</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:50:35.340764</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1558}}'
<i>2024-12-17 17:50:35.355376</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:50:35.355400</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:50:35.355462</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:50:35.355470</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:51:15.395635</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:51:15.415859</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1560}}

'
<i>2024-12-17 17:51:15.415915</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1560}}'
<i>2024-12-17 17:51:15.427444</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:51:15.427461</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:15.427490</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:51:15.427496</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:51:23.435576</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1560}}'
<i>2024-12-17 17:51:23.452397</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:51:23.452425</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:51:23.452490</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:51:23.452499</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:52:03.486661</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:52:03.504903</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1561}}

'
<i>2024-12-17 17:52:03.504964</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1561}}'
<i>2024-12-17 17:52:03.517092</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:52:03.517113</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:03.517147</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:52:03.517154</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:52:11.524769</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1561}}'
<i>2024-12-17 17:52:11.539132</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:52:11.539155</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:11.539224</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:52:11.539233</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:52:51.579397</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:52:51.606878</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1562}}

'
<i>2024-12-17 17:52:51.606932</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1562}}'
<i>2024-12-17 17:52:51.618705</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:52:51.618720</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:51.618750</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:52:51.618756</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:52:59.626927</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1562}}'
<i>2024-12-17 17:52:59.641215</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:52:59.641239</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:52:59.641303</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:52:59.641312</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:53:39.680789</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:53:39.697592</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1563}}

'
<i>2024-12-17 17:53:39.697650</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1563}}'
<i>2024-12-17 17:53:39.709596</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:53:39.709614</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:39.709646</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:53:39.709653</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:53:47.713781</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1563}}'
<i>2024-12-17 17:53:47.728688</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":1,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCkZyb20gMTkyLjE2Ny4xMjguNzkgaWNtcF9zZXE9MSBEZXN0aW5hdGlvbiBIb3N0IFVucmVhY2hhYmxlCgotLS0gMTkyLjE2Ny4xMjguMTAwIHBpbmcgc3RhdGlzdGljcyAtLS0KMSBwYWNrZXRzIHRyYW5zbWl0dGVkLCAwIHJlY2VpdmVkLCArMSBlcnJvcnMsIDEwMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCgo=","exited":true}}

'
<i>2024-12-17 17:53:47.728710</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:53:47.728772</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:53:47.728780</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 40 seconds
<i>2024-12-17 17:54:27.768949</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ping", "arg": ["-c 1", "192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:54:27.785255</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1564}}

'
<i>2024-12-17 17:54:27.785312</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1564}}'
<i>2024-12-17 17:54:27.796936</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"UElORyAxOTIuMTY3LjEyOC4xMDAgKDE5Mi4xNjcuMTI4LjEwMCkgNTYoODQpIGJ5dGVzIG9mIGRhdGEuCjY0IGJ5dGVzIGZyb20gMTkyLjE2Ny4xMjguMTAwOiBpY21wX3NlcT0xIHR0bD0xMjggdGltZT0wLjk0MCBtcwoKLS0tIDE5Mi4xNjcuMTI4LjEwMCBwaW5nIHN0YXRpc3RpY3MgLS0tCjEgcGFja2V0cyB0cmFuc21pdHRlZCwgMSByZWNlaXZlZCwgMCUgcGFja2V0IGxvc3MsIHRpbWUgMG1zCnJ0dCBtaW4vYXZnL21heC9tZGV2ID0gMC45NDAvMC45NDAvMC45NDAvMC4wMDAgbXMK","exited":true}}

'
<i>2024-12-17 17:54:27.796951</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:27.796999</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:54:27.797004</i> <b style="color:rgb(0 133 115);">[INFO]</b> Network connectivity successful!
<i>2024-12-17 17:54:27.797009</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking Remote Desktop connectivity...
<i>2024-12-17 17:54:27.797020</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "xfreerdp", "arg": ["/cert-ignore", "+auth-only", "/u:Administrator" , "/p:XWwUjZ0nEXOo57dze2iO", "/v:192.167.128.100"], "capture-output": true}}'
<i>2024-12-17 17:54:27.809079</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1565}}

'
<i>2024-12-17 17:54:27.809106</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1565}}'
<i>2024-12-17 17:54:27.819414</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:54:27.819427</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:27.819447</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:54:27.819453</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:54:35.820803</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1565}}'
<i>2024-12-17 17:54:35.836680</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"err-data":"L2J1aWxkL2ZyZWVyZHAtS0I2RW90L2ZyZWVyZHAtMS4xLjB+Z2l0MjAxNDA5MjEuMS40NDA5MTZlK2Rmc2cxL2NsaWVudC9YMTEveGZfY2xpZW50LmM6NjkyOiBBdXRoZW50aWNhdGlvbiBvbmx5LiBEb24ndCBjb25uZWN0IHRvIFguCmNvbm5lY3RlZCB0byAxOTIuMTY3LjEyOC4xMDA6MzM4OQpjcmVhdGluZyBkaXJlY3RvcnkgL3RtcC8uY29uZmlnL2ZyZWVyZHAKY3JlYXRpbmcgZGlyZWN0b3J5IC90bXAvLmNvbmZpZy9mcmVlcmRwL2NlcnRzCmNyZWF0aW5nIGRpcmVjdG9yeSAvdG1wLy5jb25maWcvZnJlZXJkcC9zZXJ2ZXIKY2VydGlmaWNhdGVfc3RvcmVfb3BlbjogZXJyb3Igb3BlbmluZyBbL3RtcC8uY29uZmlnL2ZyZWVyZHAva25vd25faG9zdHNdIGZvciB3cml0aW5nClVuYWJsZSB0byBmaW5kIGEgbWF0Y2ggZm9yIHVuaXggdGltZXpvbmU6IEV0Yy9VVEMKL2J1aWxkL2ZyZWVyZHAtS0I2RW90L2ZyZWVyZHAtMS4xLjB+Z2l0MjAxNDA5MjEuMS40NDA5MTZlK2Rmc2cxL2xpYmZyZWVyZHAvY29yZS9mcmVlcmRwLmM6OTU6IEF1dGhlbnRpY2F0aW9uIG9ubHksIGV4aXQgc3RhdHVzIDAKL2J1aWxkL2ZyZWVyZHAtS0I2RW90L2ZyZWVyZHAtMS4xLjB+Z2l0MjAxNDA5MjEuMS40NDA5MTZlK2Rmc2cxL2NsaWVudC9YMTEveGZfY2xpZW50LmM6MTI3ODogQXV0aGVudGljYXRpb24gb25seSwgZXhpdCBzdGF0dXMgMAo=","exited":true}}

'
<i>2024-12-17 17:54:35.836700</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:35.836763</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:54:35.836770</i> <b style="color:rgb(0 133 115);">[INFO]</b> RDP connection message: /build/freerdp-KB6Eot/freerdp-1.1.0~git20140921.1.440916e+dfsg1/client/X11/xf_client.c:692: Authentication only. Don't connect to X.
connected to 192.167.128.100:3389
creating directory /tmp/.config/freerdp
creating directory /tmp/.config/freerdp/certs
creating directory /tmp/.config/freerdp/server
certificate_store_open: error opening [/tmp/.config/freerdp/known_hosts] for writing
Unable to find a match for unix timezone: Etc/UTC
/build/freerdp-KB6Eot/freerdp-1.1.0~git20140921.1.440916e+dfsg1/libfreerdp/core/freerdp.c:95: Authentication only, exit status 0
/build/freerdp-KB6Eot/freerdp-1.1.0~git20140921.1.440916e+dfsg1/client/X11/xf_client.c:1278: Authentication only, exit status 0
<i>2024-12-17 17:54:35.836835</i> <b style="color:rgb(0 133 115);">[INFO]</b> Remote Desktop authentication is successful
<i>2024-12-17 17:54:35.836868</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc005_get_qemusupported_machines :Verify if the list of supported machines of hostos hypervisor matches the base file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:35.837040</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:35.837028</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:54:35.837034</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:54:35.837037</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:35.837071</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - qemu-system-x86_64 --machine help | sort
<i>2024-12-17 17:54:35.864101</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Supported machines are:
isapc                ISA-only PC
none                 empty machine
pc                   Standard PC (i440FX + PIIX, 1996) (alias of pc-i440fx-6.2)
pc-i440fx-1.4        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-1.5        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-1.6        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-1.7        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.0        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.1        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.10       Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.11       Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.12       Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.2        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.3        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.4        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.5        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.6        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.7        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.8        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-2.9        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-3.0        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-3.1        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-4.0        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-4.1        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-4.2        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-5.0        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-5.1        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-5.2        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-6.0        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-6.1        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-6.2        Standard PC (i440FX + PIIX, 1996)
pc-i440fx-artful     Ubuntu 17.10 PC (i440FX + PIIX, 1996)
pc-i440fx-bionic     Ubuntu 18.04 PC (i440FX + PIIX, 1996)
pc-i440fx-bionic-hpb Ubuntu 18.04 PC (i440FX + PIIX, +host-phys-bits=true, 1996)
pc-i440fx-cosmic     Ubuntu 18.10 PC (i440FX + PIIX, 1996)
pc-i440fx-cosmic-hpb Ubuntu 18.10 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-disco      Ubuntu 19.04 PC (i440FX + PIIX, 1996)
pc-i440fx-disco-hpb  Ubuntu 19.04 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-eoan       Ubuntu 19.10 PC (i440FX + PIIX, 1996)
pc-i440fx-eoan-hpb   Ubuntu 19.10 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-focal      Ubuntu 20.04 PC (i440FX + PIIX, 1996)
pc-i440fx-focal-hpb  Ubuntu 20.04 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-groovy     Ubuntu 20.10 PC (i440FX + PIIX, 1996)
pc-i440fx-groovy-hpb Ubuntu 20.10 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-hirsute    Ubuntu 21.04 PC (i440FX + PIIX, 1996)
pc-i440fx-hirsute-hpb Ubuntu 21.04 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-impish     Ubuntu 21.10 PC (i440FX + PIIX, 1996)
pc-i440fx-impish-hpb Ubuntu 21.10 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-jammy      Ubuntu 22.04 PC (i440FX + PIIX, 1996) (default)
pc-i440fx-jammy-hpb  Ubuntu 22.04 PC (i440FX + PIIX +host-phys-bits=true, 1996)
pc-i440fx-jammy-hpb-maxcpus Ubuntu 22.04 PC (i440FX + PIIX +host-phys-bits=true, maxcpus=1024, 1996)
pc-i440fx-jammy-maxcpus Ubuntu 22.04 PC (i440FX + PIIX, maxcpus=1024, 1996)
pc-i440fx-trusty     Ubuntu 14.04 PC (i440FX + PIIX, 1996)
pc-i440fx-wily       Ubuntu 15.04 PC (i440FX + PIIX, 1996)
pc-i440fx-xenial     Ubuntu 16.04 PC (i440FX + PIIX, 1996)
pc-i440fx-yakkety    Ubuntu 16.10 PC (i440FX + PIIX, 1996)
pc-i440fx-zesty      Ubuntu 17.04 PC (i440FX + PIIX, 1996)
pc-q35-2.10          Standard PC (Q35 + ICH9, 2009)
pc-q35-2.11          Standard PC (Q35 + ICH9, 2009)
pc-q35-2.12          Standard PC (Q35 + ICH9, 2009)
pc-q35-2.4           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.5           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.6           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.7           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.8           Standard PC (Q35 + ICH9, 2009)
pc-q35-2.9           Standard PC (Q35 + ICH9, 2009)
pc-q35-3.0           Standard PC (Q35 + ICH9, 2009)
pc-q35-3.1           Standard PC (Q35 + ICH9, 2009)
pc-q35-4.0           Standard PC (Q35 + ICH9, 2009)
pc-q35-4.0.1         Standard PC (Q35 + ICH9, 2009)
pc-q35-4.1           Standard PC (Q35 + ICH9, 2009)
pc-q35-4.2           Standard PC (Q35 + ICH9, 2009)
pc-q35-5.0           Standard PC (Q35 + ICH9, 2009)
pc-q35-5.1           Standard PC (Q35 + ICH9, 2009)
pc-q35-5.2           Standard PC (Q35 + ICH9, 2009)
pc-q35-6.0           Standard PC (Q35 + ICH9, 2009)
pc-q35-6.1           Standard PC (Q35 + ICH9, 2009)
pc-q35-6.2           Standard PC (Q35 + ICH9, 2009)
pc-q35-artful        Ubuntu 17.10 PC (Q35 + ICH9, 2009)
pc-q35-bionic        Ubuntu 18.04 PC (Q35 + ICH9, 2009)
pc-q35-bionic-hpb    Ubuntu 18.04 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-cosmic        Ubuntu 18.10 PC (Q35 + ICH9, 2009)
pc-q35-cosmic-hpb    Ubuntu 18.10 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-disco         Ubuntu 19.04 PC (Q35 + ICH9, 2009)
pc-q35-disco-hpb     Ubuntu 19.04 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-eoan          Ubuntu 19.10 PC (Q35 + ICH9, 2009)
pc-q35-eoan-hpb      Ubuntu 19.10 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-focal         Ubuntu 20.04 PC (Q35 + ICH9, 2009)
pc-q35-focal-hpb     Ubuntu 20.04 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-groovy        Ubuntu 20.10 PC (Q35 + ICH9, 2009)
pc-q35-groovy-hpb    Ubuntu 20.10 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-hirsute       Ubuntu 21.04 PC (Q35 + ICH9, 2009)
pc-q35-hirsute-hpb   Ubuntu 21.04 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-impish        Ubuntu 21.10 PC (Q35 + ICH9, 2009)
pc-q35-impish-hpb    Ubuntu 21.10 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-jammy         Ubuntu 22.04 PC (Q35 + ICH9, 2009)
pc-q35-jammy-hpb     Ubuntu 22.04 PC (Q35 + ICH9, +host-phys-bits=true, 2009)
pc-q35-jammy-hpb-maxcpus Ubuntu 22.04 PC (Q35 + ICH9, +host-phys-bits=true, maxcpus=1024, 2009)
pc-q35-jammy-maxcpus Ubuntu 22.04 PC (Q35 + ICH9, maxcpus=1024, 2009)
pc-q35-xenial        Ubuntu 16.04 PC (Q35 + ICH9, 2009)
pc-q35-yakkety       Ubuntu 16.10 PC (Q35 + ICH9, 2009)
pc-q35-zesty         Ubuntu 17.04 PC (Q35 + ICH9, 2009)
q35                  Standard PC (Q35 + ICH9, 2009) (alias of pc-q35-6.2)
ubuntu               Ubuntu 22.04 PC (i440FX + PIIX, 1996) (alias of pc-i440fx-jammy)
ubuntu-q35           Ubuntu 22.04 PC (Q35 + ICH9, 2009) (alias of pc-q35-jammy)
x-remote             Experimental remote machine
'
<i>2024-12-17 17:54:35.864158</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/supported_machines_release_6.txt : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/supported_machines_release_6.txt
<i>2024-12-17 17:54:35.864185</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/supported_machines_release_6.txt : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/supported_machines_release_6.txt
<i>2024-12-17 17:54:35.864291</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -y --suppress-common-lines -EZbwB /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/supported_machines_release_6.txt /home/hostos-validate/result.txt
<i>2024-12-17 17:54:35.866027</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:35.866125</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc006_libvirt_protocol_support :Verify ssl/tls protocol versions supported by libvirt for remote connections</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:35.866265</td>
    <td>0.73</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:35.866252</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:54:35.866260</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:54:35.866262</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:35.866472</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using compute node dal1-qz2-sr2-rk203-s12 for checking remote virsh connection
<i>2024-12-17 17:54:35.866480</i> <b style="color:rgb(0 133 115);">[INFO]</b> Starting virsh remote shell -> virsh -c qemu+tls://dal1-qz2-sr2-rk203-s12/system?tls_priority=NORMAL:-VERS-ALL:+VERS-TLS1.2
<i>2024-12-17 17:54:36.138658</i> <b style="color:rgb(0 133 115);">[INFO]</b> Connectivity is successful, output as follows:
Welcome to virsh, the virtualization interactive terminal.

Type:  'help' for help with commands
       'quit' to quit

virsh # 
virsh #                             hostname
dal1-qz2-sr2-rk203-s12

virsh #                             quit


<i>2024-12-17 17:54:36.138667</i> <b style="color:rgb(0 133 115);">[INFO]</b> TLS1.2 is enabled for virsh remote connections
<i>2024-12-17 17:54:36.138673</i> <b style="color:rgb(0 133 115);">[INFO]</b> Starting virsh remote shell -> virsh -c qemu+tls://dal1-qz2-sr2-rk203-s12/system?tls_priority=NORMAL:-VERS-ALL:+VERS-TLS1.0
<i>2024-12-17 17:54:36.159660</i> <b style="color:rgb(0 133 115);">[INFO]</b> Connectivity failed as expected, error as follows:
error: failed to connect to the hypervisor
error: authentication failed: TLS handshake failed The TLS connection was non-properly terminated.

<i>2024-12-17 17:54:36.159669</i> <b style="color:rgb(0 133 115);">[INFO]</b> TLS1.0 is disabled for virsh remote connections
<i>2024-12-17 17:54:36.159674</i> <b style="color:rgb(0 133 115);">[INFO]</b> Starting virsh remote shell -> virsh -c qemu+tls://dal1-qz2-sr2-rk203-s12/system?tls_priority=NORMAL:-VERS-ALL:+VERS-TLS1.1
<i>2024-12-17 17:54:36.597265</i> <b style="color:rgb(0 133 115);">[INFO]</b> Connectivity failed as expected, error as follows:
error: failed to connect to the hypervisor
error: authentication failed: TLS handshake failed The TLS connection was non-properly terminated.

<i>2024-12-17 17:54:36.597290</i> <b style="color:rgb(0 133 115);">[INFO]</b> TLS1.1 is disabled for virsh remote connections
<i>2024-12-17 17:54:36.597401</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc007_process_monitoring :Validate the process monitoring output with the manifest created from last release deployed</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:54:36.597641</td>
    <td>2.27</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:36.597618</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:54:36.597631</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:54:36.597636</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:36.597694</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - hostos-monitoring -n process-monitoring --verbose
<i>2024-12-17 17:54:37.755087</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'hostos-process-monitoring[924177]: process-monitoring: skipped: 5266, excluded: 0, compliant: 72, non-compliant: [{"/usr/bin/bash": {"checks": [{"owner": {"loginuid": {"expected": 4294967295, "found": 0}, "groups": {"expected": [], "found": [0]}}}], "cmdline": ["bash", "-c", "stdbuf -oL cat /sys/kernel/debug/tracing/trace_pipe | egrep --line-buffered -v bpf_trace_printk >> /var/log/kernel-rpc-traces.txt"], "pid": 840513}}, {"/usr/bin/python3.10": {"checks": [{"apparmor": {"profile_name": {"expected": "/etc/hostos-monitoring/plugins.d/process-monitoring", "found": ""}, "confinement": {"expected": "enforce", "found": "unconfined"}}}, {"cmdline": {"expected": ["/usr/bin/python3.10", "/usr/bin/ceph-crash"], "found": ["python3", "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}, {"cmdline": {"expected": ["/usr/bin/python3.10", "/usr/bin/keylime_agent"], "found": ["python3", "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}, {"cmdline": {"expected": ["/usr/bin/python3.10", "/usr/bin/rclone-configurator"], "found": ["python3", "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}], "cmdline": ["python3", "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"], "pid": 890813}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5900]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_driver_5kb2da,debug-threads=on", "-S", "-object", "{"qom-type":"secret","id":"masterKey0","format":"raw","file":"/var/lib/libvirt/qemu/domain-94-hostos_vsi_driver_5k/master-key.aes"}", "-machine", "pc-i440fx-4.2,usb=off,dump-guest-core=off,memory-backend=pc.ram", "-accel", "kvm", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-object", "{"qom-type":"memory-backend-ram","id":"pc.ram","size":1073741824}", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "2f9bde1b-96e0-4f28-9c7a-83dc928bd242", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=59,server=on,wait=off", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_driver_5kb2da.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_driver_5kb2da","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=60,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:b9:f1:3f,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=58,server=on,wait=off", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-audiodev", "{"id":"audio1","driver":"none"}", "-vnc", "0.0.0.0:0,audiodev=audio1", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 890951}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5901]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_ubuntu_bionic_ebnpya,debug-threads=on", "-S", "-object", "{"qom-type":"secret","id":"masterKey0","format":"raw","file":"/var/lib/libvirt/qemu/domain-95-hostos_vsi_ubuntu_bi/master-key.aes"}", "-machine", "pc-i440fx-4.2,usb=off,dump-guest-core=off,memory-backend=pc.ram", "-accel", "kvm", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-object", "{"qom-type":"memory-backend-ram","id":"pc.ram","size":1073741824}", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "aaecaff8-afb6-4783-9a51-34d540ec7c83", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=64,server=on,wait=off", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_ubuntu_bionic_ebnpya","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=65,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:be:05:86,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=63,server=on,wait=off", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-audiodev", "{"id":"audio1","driver":"none"}", "-vnc", "0.0.0.0:1,audiodev=audio1", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 891561}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5902]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_rhel_8_6_zk54hz,debug-threads=on", "-S", "-object", "{"qom-type":"secret","id":"masterKey0","format":"raw","file":"/var/lib/libvirt/qemu/domain-96-hostos_vsi_rhel_8_6_/master-key.aes"}", "-machine", "pc-i440fx-4.2,usb=off,dump-guest-core=off,memory-backend=pc.ram", "-accel", "kvm", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-object", "{"qom-type":"memory-backend-ram","id":"pc.ram","size":1073741824}", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "e1b75c1e-ed38-4fde-861d-dc1be0b8c2f0", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=68,server=on,wait=off", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_rhel_8_6_zk54hz","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=69,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:0f:0b:84,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=66,server=on,wait=off", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-audiodev", "{"id":"audio1","driver":"none"}", "-vnc", "0.0.0.0:2,audiodev=audio1", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 896171}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5903]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_centos_7_9_jx2r45,debug-threads=on", "-S", "-object", "{"qom-type":"secret","id":"masterKey0","format":"raw","file":"/var/lib/libvirt/qemu/domain-97-hostos_vsi_centos_7_/master-key.aes"}", "-machine", "pc-i440fx-4.2,usb=off,dump-guest-core=off,memory-backend=pc.ram", "-accel", "kvm", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-object", "{"qom-type":"memory-backend-ram","id":"pc.ram","size":1073741824}", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "951e2b0a-ba0d-4c58-a31b-1065553b284e", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=73,server=on,wait=off", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_centos_7_9_jx2r45.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_centos_7_9_jx2r45","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=74,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:3c:49:26,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=72,server=on,wait=off", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-audiodev", "{"id":"audio1","driver":"none"}", "-vnc", "0.0.0.0:3,audiodev=audio1", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 897737}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5904]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_centos_7_9_jmulsc,debug-threads=on", "-S", "-object", "{"qom-type":"secret","id":"masterKey0","format":"raw","file":"/var/lib/libvirt/qemu/domain-98-hostos_vsi_centos_7_/master-key.aes"}", "-machine", "pc-i440fx-4.2,usb=off,dump-guest-core=off,memory-backend=pc.ram", "-accel", "kvm", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-object", "{"qom-type":"memory-backend-ram","id":"pc.ram","size":1073741824}", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "a725981c-0813-4bc1-bef2-a074505c34ed", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=78,server=on,wait=off", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_centos_7_9_jmulsc","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=79,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:65:de:80,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=77,server=on,wait=off", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-audiodev", "{"id":"audio1","driver":"none"}", "-vnc", "0.0.0.0:4,audiodev=audio1", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 902955}}, {"/usr/bin/qemu-system-x86_64": {"checks": [{"network": {"allowed_ports": {"tcp_ports": {"expected": [], "found": [5905]}}}}], "cmdline": ["/usr/bin/qemu-system-x86_64", "-name", "guest=hostos_vsi_windows_10_ybj8gd,debug-threads=on", "-S", "-object", "{"qom-type":"secret","id":"masterKey0","format":"raw","file":"/var/lib/libvirt/qemu/domain-99-hostos_vsi_windows_1/master-key.aes"}", "-machine", "pc-i440fx-4.2,usb=off,dump-guest-core=off,memory-backend=pc.ram", "-accel", "kvm", "-cpu", "Cascadelake-Server-noTSX", "-m", "1024", "-object", "{"qom-type":"memory-backend-ram","id":"pc.ram","size":1073741824}", "-overcommit", "mem-lock=off", "-smp", "6,sockets=6,cores=1,threads=1", "-uuid", "784809c7-d1d2-4d6f-a0b1-654107cade0b", "-no-user-config", "-nodefaults", "-chardev", "socket,id=charmonitor,fd=83,server=on,wait=off", "-mon", "chardev=charmonitor,id=monitor,mode=control", "-rtc", "base=utc,driftfix=slew", "-no-shutdown", "-boot", "strict=on", "-device", "piix3-usb-uhci,id=usb,bus=pci.0,addr=0x1.0x2", "-device", "virtio-serial-pci,id=virtio-serial0,bus=pci.0,addr=0x6", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/hostos_vsi_windows_10_ybj8gd.qcow2","node-name":"libvirt-2-storage","cache":{"direct":false,"no-flush":false},"auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-2-format","read-only":false,"cache":{"direct":false,"no-flush":false},"driver":"qcow2","file":"libvirt-2-storage","backing":null}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x3,drive=libvirt-2-format,id=virtio-disk0,bootindex=1,write-cache=off", "-blockdev", "{"driver":"file","filename":"/home/hostos-validate/cld-init-hostos_vsi_windows_10_ybj8gd","node-name":"libvirt-1-storage","auto-read-only":true,"discard":"unmap"}", "-blockdev", "{"node-name":"libvirt-1-format","read-only":false,"driver":"raw","file":"libvirt-1-storage"}", "-device", "virtio-blk-pci,bus=pci.0,addr=0x7,drive=libvirt-1-format,id=virtio-disk1", "-netdev", "tap,fd=84,id=hostnet0", "-device", "rtl8139,netdev=hostnet0,id=net0,mac=52:54:00:7e:d9:8e,bus=pci.0,addr=0x4", "-chardev", "pty,id=charserial0", "-device", "isa-serial,chardev=charserial0,id=serial0", "-chardev", "socket,id=charchannel0,fd=82,server=on,wait=off", "-device", "virtserialport,bus=virtio-serial0.0,nr=1,chardev=charchannel0,id=channel0,name=org.qemu.guest_agent.0", "-audiodev", "{"id":"audio1","driver":"none"}", "-vnc", "0.0.0.0:5,audiodev=audio1", "-device", "cirrus-vga,id=video0,bus=pci.0,addr=0x2", "-device", "virtio-balloon-pci,id=balloon0,bus=pci.0,addr=0x5", "-sandbox", "on,obsolete=deny,elevateprivileges=deny,spawn=deny,resourcecontrol=deny", "-msg", "timestamp=on"], "pid": 904916}}], unknown: [{"/opt/Tanium/TaniumClient/TaniumClient": {"pid": 1202876, "owner": {"uid": 0, "gid": 0, "loginuid": 4294967295, "groups": []}, "apparmor": {"profile_name": "", "confinement": "unconfined"}, "network": {"listen": {"tcp": [], "udp": [], "tcp_src": [], "udp_src": [], "tcp_dest": [], "udp_dest": []}}, "cmdline": ["/opt/Tanium/TaniumClient/TaniumClient", "-d"]}}], zombies: 0, vanished: 0
'
<i>2024-12-17 17:54:37.755120</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - hostos-monitoring -n process-monitoring --verbose --exclude "/usr/bin/qemu-system-x86_64"| awk -F'non-compliant:' '{print $2}' 
<i>2024-12-17 17:54:38.859631</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b' [{"/usr/bin/bash": {"checks": [{"owner": {"loginuid": {"expected": 4294967295, "found": 0}, "groups": {"expected": [], "found": [0]}}}], "cmdline": ["bash", "-c", "stdbuf -oL cat /sys/kernel/debug/tracing/trace_pipe | egrep --line-buffered -v bpf_trace_printk >> /var/log/kernel-rpc-traces.txt"], "pid": 840513}}, {"/usr/bin/python3.10": {"checks": [{"apparmor": {"profile_name": {"expected": "/etc/hostos-monitoring/plugins.d/process-monitoring", "found": ""}, "confinement": {"expected": "enforce", "found": "unconfined"}}}, {"cmdline": {"expected": ["/usr/bin/python3.10", "/usr/bin/ceph-crash"], "found": ["python3", "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}, {"cmdline": {"expected": ["/usr/bin/python3.10", "/usr/bin/keylime_agent"], "found": ["python3", "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}, {"cmdline": {"expected": ["/usr/bin/python3.10", "/usr/bin/rclone-configurator"], "found": ["python3", "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"]}}], "cmdline": ["python3", "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py"], "pid": 890813}}], unknown: [{"/opt/Tanium/TaniumClient/TaniumClient": {"pid": 1202876, "owner": {"uid": 0, "gid": 0, "loginuid": 4294967295, "groups": []}, "apparmor": {"profile_name": "", "confinement": "unconfined"}, "network": {"listen": {"tcp": [], "udp": [], "tcp_src": [], "udp_src": [], "tcp_dest": [], "udp_dest": []}}, "cmdline": ["/opt/Tanium/TaniumClient/TaniumClient", "-d"]}}], zombies: 0, vanished: 0
'
<i>2024-12-17 17:54:38.860073</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -e '/"-cpu"/,+1d' //home/hostos-validate/actual.json > /home/hostos-validate/tempfile.json
<i>2024-12-17 17:54:38.861816</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:38.862407</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/process_monitoring/process_monitoring_data_6.json : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/process_monitoring/process_monitoring_data_6.json
<i>2024-12-17 17:54:38.862435</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/process_monitoring/process_monitoring_data_6.json : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/process_monitoring/process_monitoring_data_6.json
<i>2024-12-17 17:54:38.862440</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -e '/"-cpu"/,+1d' /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/process_monitoring/process_monitoring_data_6.json > /home/hostos-validate/tempfile.json
<i>2024-12-17 17:54:38.863918</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:54:38.864407</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -y --ignore-matching-lines='[0-9]' --ignore-matching-lines='hostos_vsi.*'                      --ignore-matching-lines='cld-init-hostos_vsi.*' --suppress-common-lines //home/hostos-validate/expected.json //home/hostos-validate/actual.json
<i>2024-12-17 17:54:38.866216</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'                  "complain"				      |	                  "unconfined"
                  "/opt/Tanium/TaniumClient/TaniumClient"     |	                  ""
'
<i>2024-12-17 17:54:38.866344</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown
<i>2024-12-17 17:54:38.866772</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/virtualization/test_vsi_operations.py", line 461, in test_vpc007_process_monitoring
    self.assertEqual(exit_code, 0, "Base File comparison Failed!")
  File "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 226, in assertEqual
    raise e
  File "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
AssertionError: 1 != 0 : Base File comparison Failed!
</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc008_create_storagepool :Verify if a storage pool can be created on the host and verify its state</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:38.866966</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:38.866953</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:54:38.866960</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:54:38.866962</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:38.866992</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating storage pool
<i>2024-12-17 17:54:38.866998</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-define-as guest_vsi_disk dir --target /home/hostos-validate
<i>2024-12-17 17:54:38.880028</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk defined

'
<i>2024-12-17 17:54:38.880040</i> <b style="color:rgb(0 133 115);">[INFO]</b> b'Pool guest_vsi_disk defined

'
<i>2024-12-17 17:54:38.880047</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-build guest_vsi_disk
<i>2024-12-17 17:54:38.891199</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk built

'
<i>2024-12-17 17:54:38.891211</i> <b style="color:rgb(0 133 115);">[INFO]</b> b'Pool guest_vsi_disk built

'
<i>2024-12-17 17:54:38.891217</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-start guest_vsi_disk
<i>2024-12-17 17:54:38.902433</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk started

'
<i>2024-12-17 17:54:38.902445</i> <b style="color:rgb(0 133 115);">[INFO]</b> b'Pool guest_vsi_disk started

'
<i>2024-12-17 17:54:38.902448</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking Storage pool status
<i>2024-12-17 17:54:38.902453</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-info guest_vsi_disk | grep State | sed 's/ //g'
<i>2024-12-17 17:54:38.912874</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'State:running
'
<i>2024-12-17 17:54:38.912962</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc009_attach_volume_ubuntu :Verify if a storage volume is created and is attached to Ubuntu vsi</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:38.913096</td>
    <td>9.82</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:38.913084</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:54:38.913091</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:54:38.913094</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:38.913130</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-create-as --pool guest_vsi_disk --name vol_ubuntu_bionic_ebnpya --capacity 5GiB --format raw
<i>2024-12-17 17:54:40.509957</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_ubuntu_bionic_ebnpya created

'
<i>2024-12-17 17:54:40.509994</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating and attaching volume vdc on hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:54:40.509999</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-disk hostos_vsi_ubuntu_bionic_ebnpya /home/hostos-validate/vol_ubuntu_bionic_ebnpya vdc
<i>2024-12-17 17:54:40.662659</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk attached successfully

'
<i>2024-12-17 17:54:40.662700</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","lsblk -po NAME,SIZE,TYPE | grep vdc"], "capture-output": true}}'
<i>2024-12-17 17:54:40.681376</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1568}}

'
<i>2024-12-17 17:54:40.681427</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1568}}'
<i>2024-12-17 17:54:40.708244</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:54:40.708260</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:40.708287</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:54:40.708293</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:54:48.712719</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1568}}'
<i>2024-12-17 17:54:48.729518</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"L2Rldi92ZGMgICAgICAgIDVHIGRpc2sK","exited":true}}

'
<i>2024-12-17 17:54:48.729536</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:48.729582</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:54:48.729683</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc010_attach_volume_rhel :Verify if a storage volume is created and is attached to Redhat vsi</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:48.729818</td>
    <td>9.8</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:48.729807</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:54:48.729813</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:54:48.729816</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:48.729850</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-create-as --pool guest_vsi_disk --name vol_rhel_8_6_zk54hz --capacity 5GiB --format raw
<i>2024-12-17 17:54:50.312126</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_rhel_8_6_zk54hz created

'
<i>2024-12-17 17:54:50.312162</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating and attaching volume vdc on hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:54:50.312166</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-disk hostos_vsi_rhel_8_6_zk54hz /home/hostos-validate/vol_rhel_8_6_zk54hz vdc
<i>2024-12-17 17:54:50.465024</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk attached successfully

'
<i>2024-12-17 17:54:50.465057</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.97","lsblk -po NAME,SIZE,TYPE | grep vdc"], "capture-output": true}}'
<i>2024-12-17 17:54:50.489466</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1569}}

'
<i>2024-12-17 17:54:50.489528</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1569}}'
<i>2024-12-17 17:54:50.501294</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:54:50.501314</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:50.501346</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:54:50.501352</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:54:58.509432</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1569}}'
<i>2024-12-17 17:54:58.525479</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"L2Rldi92ZGMgICAgICAgNUcgZGlzawo=","exited":true}}

'
<i>2024-12-17 17:54:58.525500</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:54:58.525556</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:54:58.525653</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc011_attach_volume_centos :Verify if a storage volume is created and is attached to Centos vsi</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:54:58.525783</td>
    <td>9.78</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:54:58.525772</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:54:58.525778</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:54:58.525780</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:54:58.525819</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-create-as --pool guest_vsi_disk --name vol_centos_7_9_jmulsc --capacity 5GiB --format raw
<i>2024-12-17 17:55:00.092826</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_centos_7_9_jmulsc created

'
<i>2024-12-17 17:55:00.092864</i> <b style="color:rgb(0 133 115);">[INFO]</b> Creating and attaching volume vdc on hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:55:00.092869</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-disk hostos_vsi_centos_7_9_jmulsc /home/hostos-validate/vol_centos_7_9_jmulsc vdc
<i>2024-12-17 17:55:00.249182</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk attached successfully

'
<i>2024-12-17 17:55:00.249219</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.193","lsblk -po NAME,SIZE,TYPE | grep vdc"], "capture-output": true}}'
<i>2024-12-17 17:55:00.264925</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1570}}

'
<i>2024-12-17 17:55:00.264976</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1570}}'
<i>2024-12-17 17:55:00.276812</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:55:00.276843</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:55:00.276888</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:55:00.276895</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:55:08.284958</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1570}}'
<i>2024-12-17 17:55:08.300682</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"L2Rldi92ZGMgICAgICAgICAgICAgICAgICAgICAgICAgICA1RyBkaXNrCg==","exited":true}}

'
<i>2024-12-17 17:55:08.300701</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:55:08.300747</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:55:08.300845</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc012_create_revert_ubuntu_snap :Verify if a snapshot is created, reverted and verified for ubuntu VSI</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:55:08.300979</td>
    <td>70.36</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:55:08.300967</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:55:08.300974</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:55:08.300976</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:55:08.301009</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_ubuntu_bionic_ebnpya | awk -F" " '{print $1}' | tail -n+3
<i>2024-12-17 17:55:08.313431</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'vda
vdb
vdc

'
<i>2024-12-17 17:55:08.313455</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-create-as hostos_vsi_ubuntu_bionic_ebnpya  --name snap1 --disk-only --diskspec vda,snapshot=external,file=/home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.snap1 diskspec vdb,snapshot=no vdc,snapshot=no
<i>2024-12-17 17:55:08.476287</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 created
'
<i>2024-12-17 17:55:08.476305</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_ubuntu_bionic_ebnpya | grep snap1 | wc -l
<i>2024-12-17 17:55:08.488657</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'1
'
<i>2024-12-17 17:55:08.488723</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_ubuntu_bionic_ebnpya | grep vda | grep snap1 | awk -F" " '{print $2}'
<i>2024-12-17 17:55:08.500915</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.snap1
'
<i>2024-12-17 17:55:08.500979</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","pwd > sample.txt"], "capture-output": true}}'
<i>2024-12-17 17:55:08.516859</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1571}}

'
<i>2024-12-17 17:55:08.516899</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1571}}'
<i>2024-12-17 17:55:08.528540</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:55:08.528556</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:55:08.528581</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:55:08.528587</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:55:16.532880</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1571}}'
<i>2024-12-17 17:55:16.549751</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"exited":true}}

'
<i>2024-12-17 17:55:16.549775</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:55:16.549812</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> No stderr or stdout found !!
<i>2024-12-17 17:55:16.549824</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:55:16.549835</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:55:16.563147</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1590}}

'
<i>2024-12-17 17:55:16.563187</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1590}}'
<i>2024-12-17 17:55:16.575751</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:55:16.575766</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:55:16.575788</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:55:16.575794</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:55:24.580713</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1590}}'
<i>2024-12-17 17:55:24.594898</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MQo=","exited":true}}

'
<i>2024-12-17 17:55:24.594915</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:55:24.594957</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:55:24.595046</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/disk_info.xml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml
<i>2024-12-17 17:55:24.595051</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya_diskinfo.xml
<i>2024-12-17 17:55:24.597016</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:55:24.597028</i> <b style="color:rgb(0 133 115);">[INFO]</b> created a source diskinfo xml for hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:55:24.597032</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.qcow2+' /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya_diskinfo.xml
<i>2024-12-17 17:55:24.599417</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:55:24.599425</i> <b style="color:rgb(0 133 115);">[INFO]</b> qcow2 diskinfo xml for hostos_vsi_ubuntu_bionic_ebnpya created!
<i>2024-12-17 17:55:24.599432</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh detach-disk --persistent hostos_vsi_ubuntu_bionic_ebnpya vda
<i>2024-12-17 17:55:24.884300</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk detached successfully

'
<i>2024-12-17 17:55:24.884328</i> <b style="color:rgb(0 133 115);">[INFO]</b> detached the snapshot from vsi hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:55:24.884333</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-device --persistent hostos_vsi_ubuntu_bionic_ebnpya /home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya_diskinfo.xml
<i>2024-12-17 17:55:25.031825</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Device attached successfully

'
<i>2024-12-17 17:55:25.031853</i> <b style="color:rgb(0 133 115);">[INFO]</b> attached the qcow2 diskinfo to vsi hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:55:25.031857</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh destroy hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:55:25.390889</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_ubuntu_bionic_ebnpya' destroyed

"
<i>2024-12-17 17:55:25.390925</i> <b style="color:rgb(0 133 115);">[INFO]</b> VSI hostos_vsi_ubuntu_bionic_ebnpya shutdown successful
<i>2024-12-17 17:55:25.390930</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:55:26.414129</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_ubuntu_bionic_ebnpya' started

"
<i>2024-12-17 17:55:26.414160</i> <b style="color:rgb(0 133 115);">[INFO]</b> hostos_vsi_ubuntu_bionic_ebnpya restart successful
<i>2024-12-17 17:55:26.414177</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","uname"], "capture-output": true}}'
<i>2024-12-17 17:55:26.430392</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1591}}

'
<i>2024-12-17 17:55:26.430457</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1591}}'
<i>2024-12-17 17:55:26.442616</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:55:26.442634</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:55:26.442665</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:55:26.442671</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:55:34.450847</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1591}}'
<i>2024-12-17 17:55:34.469591</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:55:34.469613</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:55:34.469656</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:55:34.469663</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:55:42.477838</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1591}}'
<i>2024-12-17 17:55:42.492848</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":255,"err-data":"c3NoOiBjb25uZWN0IHRvIGhvc3QgMTkyLjE2Ny4xMjguMTA3IHBvcnQgMjI6IENvbm5lY3Rpb24gcmVmdXNlZA0K","exited":true}}

'
<i>2024-12-17 17:55:42.492871</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:55:42.492928</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:55:42.492935</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 20 seconds
<i>2024-12-17 17:56:02.508803</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","uname"], "capture-output": true}}'
<i>2024-12-17 17:56:02.525789</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1593}}

'
<i>2024-12-17 17:56:02.525861</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1593}}'
<i>2024-12-17 17:56:02.540883</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:56:02.540908</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:02.540943</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:56:02.540949</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:56:10.549074</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1593}}'
<i>2024-12-17 17:56:10.565839</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:56:10.565858</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:10.565901</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:56:10.565906</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:56:10.565912</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_ubuntu_bionic_ebnpya | grep vda| grep "qcow2" | awk                     -F" " '{print $2}'
<i>2024-12-17 17:56:10.579550</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_ubuntu_bionic_ebnpya.qcow2
'
<i>2024-12-17 17:56:10.579633</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.107","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:56:10.595321</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1594}}

'
<i>2024-12-17 17:56:10.595370</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1594}}'
<i>2024-12-17 17:56:10.608880</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:56:10.608896</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:10.608923</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:56:10.608929</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:56:18.616715</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1594}}'
<i>2024-12-17 17:56:18.634081</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MAo=","exited":true}}

'
<i>2024-12-17 17:56:18.634105</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:18.634163</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:56:18.634247</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-delete --metadata hostos_vsi_ubuntu_bionic_ebnpya snap1
<i>2024-12-17 17:56:18.645752</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 deleted

'
<i>2024-12-17 17:56:18.645772</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-list hostos_vsi_ubuntu_bionic_ebnpya | grep snap1 | wc -l
<i>2024-12-17 17:56:18.656551</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:56:18.656666</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc013_create_revert_rhel_snap :Verify if a snapshot is created, reverted and verified for rhel VSI</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:56:18.656814</td>
    <td>58.31</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:56:18.656801</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:56:18.656808</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:56:18.656811</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:56:18.656845</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_rhel_8_6_zk54hz | awk -F" " '{print $1}' | tail -n+3
<i>2024-12-17 17:56:18.668086</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'vda
vdb
vdc

'
<i>2024-12-17 17:56:18.668109</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-create-as hostos_vsi_rhel_8_6_zk54hz  --name snap1 --disk-only --diskspec vda,snapshot=external,file=/home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.snap1 diskspec vdb,snapshot=no vdc,snapshot=no
<i>2024-12-17 17:56:18.820710</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 created
'
<i>2024-12-17 17:56:18.820729</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_rhel_8_6_zk54hz | grep snap1 | wc -l
<i>2024-12-17 17:56:18.832344</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'1
'
<i>2024-12-17 17:56:18.832415</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_rhel_8_6_zk54hz | grep vda | grep snap1 | awk -F" " '{print $2}'
<i>2024-12-17 17:56:18.844905</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.snap1
'
<i>2024-12-17 17:56:18.844978</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.97","pwd > sample.txt"], "capture-output": true}}'
<i>2024-12-17 17:56:18.859364</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1595}}

'
<i>2024-12-17 17:56:18.859431</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1595}}'
<i>2024-12-17 17:56:18.873986</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:56:18.874011</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:18.874056</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:56:18.874063</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:56:26.882169</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1595}}'
<i>2024-12-17 17:56:26.898899</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"exited":true}}

'
<i>2024-12-17 17:56:26.898918</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:26.898953</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> No stderr or stdout found !!
<i>2024-12-17 17:56:26.898967</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:56:26.898980</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.97","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:56:26.912669</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1596}}

'
<i>2024-12-17 17:56:26.912702</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1596}}'
<i>2024-12-17 17:56:26.924317</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:56:26.924331</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:26.924352</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:56:26.924357</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:56:34.932500</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1596}}'
<i>2024-12-17 17:56:34.950347</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MQo=","exited":true}}

'
<i>2024-12-17 17:56:34.950365</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:34.950408</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:56:34.950508</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/disk_info.xml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml
<i>2024-12-17 17:56:34.950514</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz_diskinfo.xml
<i>2024-12-17 17:56:34.952482</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:56:34.952494</i> <b style="color:rgb(0 133 115);">[INFO]</b> created a source diskinfo xml for hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:56:34.952497</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.qcow2+' /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz_diskinfo.xml
<i>2024-12-17 17:56:34.954595</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:56:34.954607</i> <b style="color:rgb(0 133 115);">[INFO]</b> qcow2 diskinfo xml for hostos_vsi_rhel_8_6_zk54hz created!
<i>2024-12-17 17:56:34.954615</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh detach-disk --persistent hostos_vsi_rhel_8_6_zk54hz vda
<i>2024-12-17 17:56:35.209568</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk detached successfully

'
<i>2024-12-17 17:56:35.209594</i> <b style="color:rgb(0 133 115);">[INFO]</b> detached the snapshot from vsi hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:56:35.209599</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-device --persistent hostos_vsi_rhel_8_6_zk54hz /home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz_diskinfo.xml
<i>2024-12-17 17:56:35.372779</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Device attached successfully

'
<i>2024-12-17 17:56:35.372805</i> <b style="color:rgb(0 133 115);">[INFO]</b> attached the qcow2 diskinfo to vsi hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:56:35.372811</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh destroy hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:56:35.746555</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_rhel_8_6_zk54hz' destroyed

"
<i>2024-12-17 17:56:35.746589</i> <b style="color:rgb(0 133 115);">[INFO]</b> VSI hostos_vsi_rhel_8_6_zk54hz shutdown successful
<i>2024-12-17 17:56:35.746594</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:56:36.731297</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_rhel_8_6_zk54hz' started

"
<i>2024-12-17 17:56:36.731329</i> <b style="color:rgb(0 133 115);">[INFO]</b> hostos_vsi_rhel_8_6_zk54hz restart successful
<i>2024-12-17 17:56:36.731349</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.97","uname"], "capture-output": true}}'
<i>2024-12-17 17:56:36.760908</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1597}}

'
<i>2024-12-17 17:56:36.760968</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1597}}'
<i>2024-12-17 17:56:36.775446</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:56:36.775463</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:36.775489</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:56:36.775495</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:56:44.780674</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1597}}'
<i>2024-12-17 17:56:44.812076</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:56:44.812104</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:44.812141</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:56:44.812147</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:56:52.816732</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1597}}'
<i>2024-12-17 17:56:52.831287</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:56:52.831310</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:56:52.831353</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:56:52.831360</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:57:00.839532</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1597}}'
<i>2024-12-17 17:57:00.855659</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:57:00.855681</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:00.855723</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:57:00.855730</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:57:08.863892</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1597}}'
<i>2024-12-17 17:57:08.878499</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:57:08.878522</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:08.878577</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:57:08.878583</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:57:08.878591</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_rhel_8_6_zk54hz | grep vda| grep "qcow2" | awk                     -F" " '{print $2}'
<i>2024-12-17 17:57:08.891375</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_rhel_8_6_zk54hz.qcow2
'
<i>2024-12-17 17:57:08.891468</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.97","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:57:08.903829</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1598}}

'
<i>2024-12-17 17:57:08.903864</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1598}}'
<i>2024-12-17 17:57:08.914199</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:57:08.914213</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:08.914235</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:57:08.914241</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:57:16.922405</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1598}}'
<i>2024-12-17 17:57:16.938628</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MAo=","exited":true}}

'
<i>2024-12-17 17:57:16.938662</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:16.938721</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:57:16.938811</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-delete --metadata hostos_vsi_rhel_8_6_zk54hz snap1
<i>2024-12-17 17:57:16.952423</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 deleted

'
<i>2024-12-17 17:57:16.952446</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-list hostos_vsi_rhel_8_6_zk54hz | grep snap1 | wc -l
<i>2024-12-17 17:57:16.963724</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:57:16.963844</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc014_create_revert_centos_snap :Verify if a snapshot is created, reverted and verified for CentOS VSI</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:57:16.964042</td>
    <td>42.25</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:57:16.964018</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:57:16.964029</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:57:16.964037</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:57:16.964087</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_centos_7_9_jmulsc | awk -F" " '{print $1}' | tail -n+3
<i>2024-12-17 17:57:16.978941</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'vda
vdb
vdc

'
<i>2024-12-17 17:57:16.978967</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-create-as hostos_vsi_centos_7_9_jmulsc  --name snap1 --disk-only --diskspec vda,snapshot=external,file=/home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.snap1 diskspec vdb,snapshot=no vdc,snapshot=no
<i>2024-12-17 17:57:17.126476</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 created
'
<i>2024-12-17 17:57:17.126503</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_centos_7_9_jmulsc | grep snap1 | wc -l
<i>2024-12-17 17:57:17.138888</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'1
'
<i>2024-12-17 17:57:17.138975</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_centos_7_9_jmulsc | grep vda | grep snap1 | awk -F" " '{print $2}'
<i>2024-12-17 17:57:17.152442</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.snap1
'
<i>2024-12-17 17:57:17.152556</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.193","pwd > sample.txt"], "capture-output": true}}'
<i>2024-12-17 17:57:17.169730</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1599}}

'
<i>2024-12-17 17:57:17.169777</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1599}}'
<i>2024-12-17 17:57:17.182057</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:57:17.182072</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:17.182095</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:57:17.182100</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:57:25.190195</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1599}}'
<i>2024-12-17 17:57:25.215155</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"exited":true}}

'
<i>2024-12-17 17:57:25.215177</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:25.215214</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> No stderr or stdout found !!
<i>2024-12-17 17:57:25.215226</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:57:25.215240</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.193","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:57:25.228654</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1600}}

'
<i>2024-12-17 17:57:25.228688</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1600}}'
<i>2024-12-17 17:57:25.240140</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:57:25.240154</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:25.240177</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:57:25.240183</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:57:33.247725</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1600}}'
<i>2024-12-17 17:57:33.273371</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MQo=","exited":true}}

'
<i>2024-12-17 17:57:33.273398</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:33.273450</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:57:33.273561</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/disk_info.xml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml
<i>2024-12-17 17:57:33.273568</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/disk_info.xml /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc_diskinfo.xml
<i>2024-12-17 17:57:33.275839</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:57:33.275860</i> <b style="color:rgb(0 133 115);">[INFO]</b> created a source diskinfo xml for hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:57:33.275868</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sed -i 's+GUEST_IMAGE_PATH+/home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.qcow2+' /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc_diskinfo.xml
<i>2024-12-17 17:57:33.277915</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:57:33.277934</i> <b style="color:rgb(0 133 115);">[INFO]</b> qcow2 diskinfo xml for hostos_vsi_centos_7_9_jmulsc created!
<i>2024-12-17 17:57:33.277949</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh detach-disk --persistent hostos_vsi_centos_7_9_jmulsc vda
<i>2024-12-17 17:57:33.544836</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Disk detached successfully

'
<i>2024-12-17 17:57:33.544867</i> <b style="color:rgb(0 133 115);">[INFO]</b> detached the snapshot from vsi hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:57:33.544873</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh attach-device --persistent hostos_vsi_centos_7_9_jmulsc /home/hostos-validate/hostos_vsi_centos_7_9_jmulsc_diskinfo.xml
<i>2024-12-17 17:57:33.695694</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Device attached successfully

'
<i>2024-12-17 17:57:33.695711</i> <b style="color:rgb(0 133 115);">[INFO]</b> attached the qcow2 diskinfo to vsi hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:57:33.695715</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh destroy hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:57:34.058749</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_centos_7_9_jmulsc' destroyed

"
<i>2024-12-17 17:57:34.058781</i> <b style="color:rgb(0 133 115);">[INFO]</b> VSI hostos_vsi_centos_7_9_jmulsc shutdown successful
<i>2024-12-17 17:57:34.058786</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh start hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:57:35.041799</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_centos_7_9_jmulsc' started

"
<i>2024-12-17 17:57:35.041832</i> <b style="color:rgb(0 133 115);">[INFO]</b> hostos_vsi_centos_7_9_jmulsc restart successful
<i>2024-12-17 17:57:35.041864</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.193","uname"], "capture-output": true}}'
<i>2024-12-17 17:57:35.071351</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1601}}

'
<i>2024-12-17 17:57:35.071397</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1601}}'
<i>2024-12-17 17:57:35.083371</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:57:35.083387</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:35.083417</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:57:35.083422</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:57:43.088744</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1601}}'
<i>2024-12-17 17:57:43.110426</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:57:43.110460</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:43.110509</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:57:43.110518</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:57:51.116798</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1601}}'
<i>2024-12-17 17:57:51.131954</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"TGludXgK","exited":true}}

'
<i>2024-12-17 17:57:51.131976</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:51.132034</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:57:51.132039</i> <b style="color:rgb(0 133 115);">[INFO]</b> SSH connection established with return code 0!!
<i>2024-12-17 17:57:51.132047</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh domblklist hostos_vsi_centos_7_9_jmulsc | grep vda| grep "qcow2" | awk                     -F" " '{print $2}'
<i>2024-12-17 17:57:51.144627</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/hostos-validate/hostos_vsi_centos_7_9_jmulsc.qcow2
'
<i>2024-12-17 17:57:51.144741</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec","arguments": {"path": "ssh", "arg": ["-o StrictHostKeyChecking=no", "hostosvalidate@192.167.128.193","find -name sample.txt| wc -l"], "capture-output": true}}'
<i>2024-12-17 17:57:51.156085</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"pid":1602}}

'
<i>2024-12-17 17:57:51.156119</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1602}}'
<i>2024-12-17 17:57:51.166099</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exited":false}}

'
<i>2024-12-17 17:57:51.166113</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:51.166137</i> <b style="color:rgb(239, 193, 0);">[WARN]</b> Exit status could not be checked
<i>2024-12-17 17:57:51.166144</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is False, waiting for 8 seconds
<i>2024-12-17 17:57:59.174315</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh qemu-agent-command hostos_vsi_driver_5kb2da '{"execute": "guest-exec-status", "arguments": { "pid" :1602}}'
<i>2024-12-17 17:57:59.189170</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{"return":{"exitcode":0,"out-data":"MAo=","exited":true}}

'
<i>2024-12-17 17:57:59.189194</i> <b style="color:rgb(0 133 115);">[INFO]</b> Parsing the qemu agent command output
<i>2024-12-17 17:57:59.189256</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command Exit status is True
<i>2024-12-17 17:57:59.189343</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-delete --metadata hostos_vsi_centos_7_9_jmulsc snap1
<i>2024-12-17 17:57:59.200743</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Domain snapshot snap1 deleted

'
<i>2024-12-17 17:57:59.200761</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh snapshot-list hostos_vsi_centos_7_9_jmulsc | grep snap1 | wc -l
<i>2024-12-17 17:57:59.212235</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:57:59.212334</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc015_volume_cleanup :Verify if the storage volumes are deleted</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:57:59.212504</td>
    <td>1.08</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:57:59.212492</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:57:59.212499</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:57:59.212502</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:57:59.212537</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying storage volumes
<i>2024-12-17 17:57:59.212543</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-list guest_vsi_disk | grep vol | awk -F" " '{print $1}'
<i>2024-12-17 17:57:59.228457</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'vol_centos_7_9_jmulsc
vol_rhel_8_6_zk54hz
vol_ubuntu_bionic_ebnpya
'
<i>2024-12-17 17:57:59.228483</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-delete vol_centos_7_9_jmulsc --pool guest_vsi_disk
<i>2024-12-17 17:57:59.578348</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_centos_7_9_jmulsc deleted

'
<i>2024-12-17 17:57:59.578383</i> <b style="color:rgb(0 133 115);">[INFO]</b> Volume vol_centos_7_9_jmulsc deleted
<i>2024-12-17 17:57:59.578394</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-delete vol_rhel_8_6_zk54hz --pool guest_vsi_disk
<i>2024-12-17 17:57:59.928184</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_rhel_8_6_zk54hz deleted

'
<i>2024-12-17 17:57:59.928211</i> <b style="color:rgb(0 133 115);">[INFO]</b> Volume vol_rhel_8_6_zk54hz deleted
<i>2024-12-17 17:57:59.928220</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-delete vol_ubuntu_bionic_ebnpya --pool guest_vsi_disk
<i>2024-12-17 17:58:00.276786</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Vol vol_ubuntu_bionic_ebnpya deleted

'
<i>2024-12-17 17:58:00.276815</i> <b style="color:rgb(0 133 115);">[INFO]</b> Volume vol_ubuntu_bionic_ebnpya deleted
<i>2024-12-17 17:58:00.276823</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh vol-list guest_vsi_disk | grep vol | wc -l
<i>2024-12-17 17:58:00.291628</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:58:00.291731</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc016_vhost_pinning :Validate if the vhost processes were correctly pinned acc to the emulatorpin setting of libvirtd</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:58:00.291868</td>
    <td>7.4</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:00.291855</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:00.291862</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:00.291865</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:00.291915</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/virtualization/test_pin.sh : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/test_pin.sh
<i>2024-12-17 17:58:00.291920</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/virtualization/test_pin.sh && echo match || echo mismatch
<i>2024-12-17 17:58:07.688037</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'match
'
<i>2024-12-17 17:58:07.688185</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc017_vsi_cleanup :Verify if the VSIs created are deleted</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:58:07.688307</td>
    <td>2.34</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:07.688294</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:07.688301</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:07.688304</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:07.688334</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all |awk -F" " '{print $2}'
<i>2024-12-17 17:58:07.703605</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Name

k8s_d9bcdd4212ff4637a6efc1d48d8a802b_2114_5b5f0fb5-3efb-4a95-8032-7140f5096d81
k8s_d9bcdd4212ff4637a6efc1d48d8a802b_2114_1a2f4cef-208b-4bdf-9b54-7b4248bd29e7
k8s_a75f2a54c5114ce5b4055016f250e8e5_2114_c8dd410c-781e-46fa-855c-d867ed5c63ec
k8s_a75f2a54c5114ce5b4055016f250e8e5_2114_33f22359-a64a-4e96-b914-d2914e5a6d84
k8s_a75f2a54c5114ce5b4055016f250e8e5_2114_524536fa-a847-412c-8b6f-22a438924884
k8s_a75f2a54c5114ce5b4055016f250e8e5_2114_e513a8fa-5e06-454d-bd2b-ec7f3caf0eb0
hostos_vsi_driver_5kb2da
hostos_vsi_centos_7_9_jx2r45
hostos_vsi_windows_10_ybj8gd
hostos_vsi_ubuntu_bionic_ebnpya
hostos_vsi_rhel_8_6_zk54hz
hostos_vsi_centos_7_9_jmulsc

'
<i>2024-12-17 17:58:07.703655</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_driver_5kb2da
<i>2024-12-17 17:58:07.703666</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_driver_5kb2da; virsh destroy hostos_vsi_driver_5kb2da
<i>2024-12-17 17:58:08.084357</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_driver_5kb2da' has been undefined

Domain 'hostos_vsi_driver_5kb2da' destroyed

"
<i>2024-12-17 17:58:08.084394</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_driver_5kb2da | wc -l
<i>2024-12-17 17:58:08.097153</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:58:08.097239</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:58:08.097249</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_ubuntu_bionic_ebnpya; virsh destroy hostos_vsi_ubuntu_bionic_ebnpya
<i>2024-12-17 17:58:08.471794</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_ubuntu_bionic_ebnpya' has been undefined

Domain 'hostos_vsi_ubuntu_bionic_ebnpya' destroyed

"
<i>2024-12-17 17:58:08.471832</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_ubuntu_bionic_ebnpya | wc -l
<i>2024-12-17 17:58:08.486027</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:58:08.486122</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:58:08.486132</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_rhel_8_6_zk54hz; virsh destroy hostos_vsi_rhel_8_6_zk54hz
<i>2024-12-17 17:58:08.859816</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_rhel_8_6_zk54hz' has been undefined

Domain 'hostos_vsi_rhel_8_6_zk54hz' destroyed

"
<i>2024-12-17 17:58:08.859852</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_rhel_8_6_zk54hz | wc -l
<i>2024-12-17 17:58:08.872122</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:58:08.872215</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_centos_7_9_jx2r45
<i>2024-12-17 17:58:08.872223</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_centos_7_9_jx2r45; virsh destroy hostos_vsi_centos_7_9_jx2r45
<i>2024-12-17 17:58:09.244480</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_centos_7_9_jx2r45' has been undefined

Domain 'hostos_vsi_centos_7_9_jx2r45' destroyed

"
<i>2024-12-17 17:58:09.244509</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_centos_7_9_jx2r45 | wc -l
<i>2024-12-17 17:58:09.257628</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:58:09.257712</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:58:09.257720</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_centos_7_9_jmulsc; virsh destroy hostos_vsi_centos_7_9_jmulsc
<i>2024-12-17 17:58:09.626144</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_centos_7_9_jmulsc' has been undefined

Domain 'hostos_vsi_centos_7_9_jmulsc' destroyed

"
<i>2024-12-17 17:58:09.626183</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_centos_7_9_jmulsc | wc -l
<i>2024-12-17 17:58:09.638898</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:58:09.638994</i> <b style="color:rgb(0 133 115);">[INFO]</b> Destroying vsi hostos_vsi_windows_10_ybj8gd
<i>2024-12-17 17:58:09.639002</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh undefine hostos_vsi_windows_10_ybj8gd; virsh destroy hostos_vsi_windows_10_ybj8gd
<i>2024-12-17 17:58:10.011968</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b"Domain 'hostos_vsi_windows_10_ybj8gd' has been undefined

Domain 'hostos_vsi_windows_10_ybj8gd' destroyed

"
<i>2024-12-17 17:58:10.011996</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh list --all | grep hostos_vsi_windows_10_ybj8gd | wc -l
<i>2024-12-17 17:58:10.024031</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:58:10.024146</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_vpc018_storagepool_cleanup :Verify if the storage pool is deleted</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:58:10.024290</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:10.024277</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:10.024284</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:10.024288</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:10.024318</i> <b style="color:rgb(0 133 115);">[INFO]</b> destroying the pool guest_vsi_disk
<i>2024-12-17 17:58:10.024325</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-destroy guest_vsi_disk
<i>2024-12-17 17:58:10.034118</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk destroyed

'
<i>2024-12-17 17:58:10.034133</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-undefine guest_vsi_disk
<i>2024-12-17 17:58:10.043938</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'Pool guest_vsi_disk has been undefined

'
<i>2024-12-17 17:58:10.043954</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - virsh pool-list --all | grep guest_vsi_disk| wc -l
<i>2024-12-17 17:58:10.057460</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'0
'
<i>2024-12-17 17:58:10.057545</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:58:11.546551</td>
    <td>0.23</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:11.546538</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:11.546546</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:11.546548</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:11.546568</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:58:11.546584</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:58:11.546599</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:58:11.546602</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml for test validation
<i>2024-12-17 17:58:11.578110</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:58:11.578155</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:58:11.768507</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
	"version":	"2",
	"profiles":	{
		"/etc/hostos-monitoring/plugins.d/configuration-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/ipset-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/iptables-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/liveness":	"enforce",
		"/etc/hostos-monitoring/plugins.d/process-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/smartnic-monitoring":	"enforce",
		"/sbin/block-agent-server":	"enforce",
		"/sbin/capause":	"enforce",
		"/sbin/coalesce-agent":	"enforce",
		"/sbin/coalesce-agent-nr":	"enforce",
		"/sbin/computeproxy":	"enforce",
		"/sbin/consolemultiplexer":	"enforce",
		"/sbin/cos-transfer-agent":	"enforce",
		"/sbin/cos-transfer-agent-nr":	"enforce",
		"/sbin/guestproxysvc":	"enforce",
		"/sbin/launch_rmds_agent":	"enforce",
		"/sbin/metadataagent":	"enforce",
		"/sbin/threadbare":	"enforce",
		"/usr/bin/autofs_rclone":	"enforce",
		"/usr/bin/prometheus-node-exporter":	"enforce",
		"/usr/bin/rclone-agent":	"enforce",
		"/usr/bin/rclone-configurator":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-client.action":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-helper":	"enforce",
		"/usr/lib/connman/scripts/dhclient-script":	"enforce",
		"/usr/sbin/dropbear":	"enforce",
		"/usr/sbin/hostos-monitoring":	"enforce",
		"/usr/sbin/sshd":	"enforce",
		"/usr/sbin/sshd//DEFAULT":	"enforce",
		"/usr/sbin/sshd//root":	"enforce",
		"/usr/sbin/sshd//sysop":	"enforce",
		"/{,usr/}sbin/dhclient":	"enforce",
		"/{,usr/}sbin/net-block-agent":	"enforce",
		"cri-containerd.apparmor.d":	"enforce",
		"fluent-bit-logs":	"enforce",
		"fluentbit-logs":	"enforce",
		"genctl-ingress-controller":	"enforce",
		"libvirt-1a2f4cef-208b-4bdf-9b54-7b4248bd29e7":	"enforce",
		"libvirt-33f22359-a64a-4e96-b914-d2914e5a6d84":	"enforce",
		"libvirt-524536fa-a847-412c-8b6f-22a438924884":	"enforce",
		"libvirt-5b5f0fb5-3efb-4a95-8032-7140f5096d81":	"enforce",
		"libvirt-c8dd410c-781e-46fa-855c-d867ed5c63ec":	"enforce",
		"libvirt-e513a8fa-5e06-454d-bd2b-ec7f3caf0eb0":	"enforce",
		"libvirtd":	"enforce",
		"libvirtd//qemu_bridge_helper":	"enforce",
		"lsb_release":	"enforce",
		"nvidia_modprobe":	"enforce",
		"nvidia_modprobe//kmod":	"enforce",
		"sysdig-agent":	"enforce",
		"sysdig-agent-kmodule":	"enforce",
		"sysdig-agent-kmodule//ln_profile":	"enforce",
		"tcpdump":	"enforce",
		"virt-aa-helper":	"enforce",
		"/usr/lib/frr/bgpd":	"complain",
		"/usr/lib/frr/staticd":	"complain",
		"/usr/lib/frr/watchfrr":	"complain",
		"/usr/lib/frr/zebra":	"complain",
		"/usr/local/fabcon/fabcon_server":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/find":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/gawk":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/grep":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/install":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/jq":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/kubectl":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/mkdir":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/rm":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/base64":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/jq":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/wc":	"complain",
		"/usr/local/iobricks/bessctl/bessctl":	"complain",
		"/usr/local/iobricks/iobricksd":	"complain",
		"/usr/local/iobricks/monitor/monitor":	"complain",
		"/usr/local/iobricks/monitor/monitor_datapath":	"complain",
		"/usr/local/iobricks/monitor/monitor_fmt":	"complain",
		"/usr/local/iobricks/monitor/monitor_vpe_enable":	"complain",
		"/usr/local/skydive/skydive":	"complain",
		"/usr/sbin/mlx-setup.sh":	"complain",
		"confined_user":	"complain",
		"docker-extended":	"complain",
		"fluentd-logs":	"complain",
		"fluentd-qradar":	"complain"
	},
	"processes":	{
		"/bin/ssf-validator-fluentbit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382291",
				"status":	"enforce"
			}],
		"/compute-agent":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1386258",
				"status":	"enforce"
			}],
		"/fabcon-manager":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1385658",
				"status":	"enforce"
			}],
		"/fluent-bit/bin/fluent-bit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382361",
				"status":	"enforce"
			}],
		"/home/genctl/stunnelserver":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381366",
				"status":	"enforce"
			}],
		"/storage-agent":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"3920388",
				"status":	"enforce"
			}],
		"/synthetics/datagen":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382421",
				"status":	"enforce"
			}],
		"/usr/bin/bash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381344",
				"status":	"enforce"
			}],
		"/usr/bin/dash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380830",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381166",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382245",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"3920317",
				"status":	"enforce"
			}],
		"/usr/bin/prometheus-node-exporter":	[{
				"profile":	"/usr/bin/prometheus-node-exporter",
				"pid":	"1193805",
				"status":	"enforce"
			}],
		"/usr/bin/qemu-system-x86_64":	[{
				"profile":	"libvirt-5b5f0fb5-3efb-4a95-8032-7140f5096d81",
				"pid":	"1387709",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-1a2f4cef-208b-4bdf-9b54-7b4248bd29e7",
				"pid":	"1387793",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-c8dd410c-781e-46fa-855c-d867ed5c63ec",
				"pid":	"1388049",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-33f22359-a64a-4e96-b914-d2914e5a6d84",
				"pid":	"1389089",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-524536fa-a847-412c-8b6f-22a438924884",
				"pid":	"1389313",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-e513a8fa-5e06-454d-bd2b-ec7f3caf0eb0",
				"pid":	"1389541",
				"status":	"enforce"
			}],
		"/usr/bin/ruby":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1379168",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1379199",
				"status":	"enforce"
			}],
		"/usr/bin/stunnel":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381365",
				"status":	"enforce"
			}],
		"/usr/bin/vault":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380860",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381182",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382260",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"3920331",
				"status":	"enforce"
			}],
		"/usr/sbin/block-agent-server":	[{
				"profile":	"/sbin/block-agent-server",
				"pid":	"1200850",
				"status":	"enforce"
			}],
		"/usr/sbin/coalesce-agent":	[{
				"profile":	"/sbin/coalesce-agent",
				"pid":	"1074750",
				"status":	"enforce"
			}],
		"/usr/sbin/coalesce-agent-nr":	[{
				"profile":	"/sbin/coalesce-agent-nr",
				"pid":	"1191074",
				"status":	"enforce"
			}],
		"/usr/sbin/computeproxy":	[{
				"profile":	"/sbin/computeproxy",
				"pid":	"1190973",
				"status":	"enforce"
			}],
		"/usr/sbin/consolemultiplexer":	[{
				"profile":	"/sbin/consolemultiplexer",
				"pid":	"1191018",
				"status":	"enforce"
			}],
		"/usr/sbin/cos-transfer-agent":	[{
				"profile":	"/sbin/cos-transfer-agent",
				"pid":	"1076383",
				"status":	"enforce"
			}],
		"/usr/sbin/cos-transfer-agent-nr":	[{
				"profile":	"/sbin/cos-transfer-agent-nr",
				"pid":	"1191113",
				"status":	"enforce"
			}],
		"/usr/sbin/dhclient":	[{
				"profile":	"/{,usr/}sbin/dhclient",
				"pid":	"3495553",
				"status":	"enforce"
			}],
		"/usr/sbin/guestproxysvc":	[{
				"profile":	"/sbin/guestproxysvc",
				"pid":	"1073846",
				"status":	"enforce"
			}],
		"/usr/sbin/libvirtd":	[{
				"profile":	"libvirtd",
				"pid":	"1190891",
				"status":	"enforce"
			}],
		"/usr/sbin/metadataagent":	[{
				"profile":	"/sbin/metadataagent",
				"pid":	"1387518",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1387699",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1387983",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1389008",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1389029",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1389463",
				"status":	"enforce"
			}],
		"/usr/sbin/net-block-agent":	[{
				"profile":	"/{,usr/}sbin/net-block-agent",
				"pid":	"1076587",
				"status":	"enforce"
			}],
		"/usr/sbin/sshd":	[{
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"880206",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"880218",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd",
				"pid":	"1202126",
				"status":	"enforce"
			}],
		"/usr/sbin/threadbare":	[{
				"profile":	"/sbin/threadbare",
				"pid":	"1073712",
				"status":	"enforce"
			}],
		"/usr/lib/frr/bgpd":	[{
				"profile":	"/usr/lib/frr/bgpd",
				"pid":	"89225",
				"status":	"complain"
			}],
		"/usr/lib/frr/staticd":	[{
				"profile":	"/usr/lib/frr/staticd",
				"pid":	"89232",
				"status":	"complain"
			}],
		"/usr/lib/frr/watchfrr":	[{
				"profile":	"/usr/lib/frr/watchfrr",
				"pid":	"89205",
				"status":	"complain"
			}],
		"/usr/lib/frr/zebra":	[{
				"profile":	"/usr/lib/frr/zebra",
				"pid":	"89219",
				"status":	"complain"
			}],
		"/usr/local/fabcon/fabcon_server":	[{
				"profile":	"/usr/local/fabcon/fabcon_server",
				"pid":	"1195941",
				"status":	"complain"
			}],
		"/usr/local/iobricks/iobricksd":	[{
				"profile":	"/usr/local/iobricks/iobricksd",
				"pid":	"340797",
				"status":	"complain"
			}],
		"/usr/local/skydive/skydive":	[{
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"339190",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"339221",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"339331",
				"status":	"complain"
			}]
	}
}
'
<i>2024-12-17 17:58:11.776989</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 845, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 1226, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[399 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[2226 chars]e"}}' != '{"pr[399 chars]", "/sbin/block-agent-server": "enforce", "/sb[2173 chars]e"}}'
Diff is 5773 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:58:11.777075</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:58:11.777183</td>
    <td>0.31</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:11.777173</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:11.777178</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:11.777181</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:11.777203</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:58:11.858385</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:58:11.858401</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:58:11.858404</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:58:11.858430</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:58:11.858451</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:58:11.858454</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml for test validation
<i>2024-12-17 17:58:11.889891</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:58:11.889940</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:58:12.075137</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
	"version":	"2",
	"profiles":	{
		"/etc/hostos-monitoring/plugins.d/configuration-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/ipset-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/iptables-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/liveness":	"enforce",
		"/etc/hostos-monitoring/plugins.d/process-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/smartnic-monitoring":	"enforce",
		"/sbin/block-agent-server":	"enforce",
		"/sbin/capause":	"enforce",
		"/sbin/coalesce-agent":	"enforce",
		"/sbin/coalesce-agent-nr":	"enforce",
		"/sbin/computeproxy":	"enforce",
		"/sbin/consolemultiplexer":	"enforce",
		"/sbin/cos-transfer-agent":	"enforce",
		"/sbin/cos-transfer-agent-nr":	"enforce",
		"/sbin/guestproxysvc":	"enforce",
		"/sbin/launch_rmds_agent":	"enforce",
		"/sbin/metadataagent":	"enforce",
		"/sbin/threadbare":	"enforce",
		"/usr/bin/autofs_rclone":	"enforce",
		"/usr/bin/prometheus-node-exporter":	"enforce",
		"/usr/bin/rclone-agent":	"enforce",
		"/usr/bin/rclone-configurator":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-client.action":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-helper":	"enforce",
		"/usr/lib/connman/scripts/dhclient-script":	"enforce",
		"/usr/sbin/dropbear":	"enforce",
		"/usr/sbin/hostos-monitoring":	"enforce",
		"/usr/sbin/sshd":	"enforce",
		"/usr/sbin/sshd//DEFAULT":	"enforce",
		"/usr/sbin/sshd//root":	"enforce",
		"/usr/sbin/sshd//sysop":	"enforce",
		"/{,usr/}sbin/dhclient":	"enforce",
		"/{,usr/}sbin/net-block-agent":	"enforce",
		"cri-containerd.apparmor.d":	"enforce",
		"fluent-bit-logs":	"enforce",
		"fluentbit-logs":	"enforce",
		"genctl-ingress-controller":	"enforce",
		"libvirt-1a2f4cef-208b-4bdf-9b54-7b4248bd29e7":	"enforce",
		"libvirt-33f22359-a64a-4e96-b914-d2914e5a6d84":	"enforce",
		"libvirt-524536fa-a847-412c-8b6f-22a438924884":	"enforce",
		"libvirt-5b5f0fb5-3efb-4a95-8032-7140f5096d81":	"enforce",
		"libvirt-c8dd410c-781e-46fa-855c-d867ed5c63ec":	"enforce",
		"libvirt-e513a8fa-5e06-454d-bd2b-ec7f3caf0eb0":	"enforce",
		"libvirtd":	"enforce",
		"libvirtd//qemu_bridge_helper":	"enforce",
		"lsb_release":	"enforce",
		"nvidia_modprobe":	"enforce",
		"nvidia_modprobe//kmod":	"enforce",
		"sysdig-agent":	"enforce",
		"sysdig-agent-kmodule":	"enforce",
		"sysdig-agent-kmodule//ln_profile":	"enforce",
		"tcpdump":	"enforce",
		"virt-aa-helper":	"enforce",
		"/usr/lib/frr/bgpd":	"complain",
		"/usr/lib/frr/staticd":	"complain",
		"/usr/lib/frr/watchfrr":	"complain",
		"/usr/lib/frr/zebra":	"complain",
		"/usr/local/fabcon/fabcon_server":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/find":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/gawk":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/grep":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/install":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/jq":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/kubectl":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/mkdir":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/rm":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/base64":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/sudo//null-/usr/bin/jq":	"complain",
		"/usr/local/fabcon/fabcon_server//null-/usr/local/fabcon/eventing_config//null-/usr/bin/wc":	"complain",
		"/usr/local/iobricks/bessctl/bessctl":	"complain",
		"/usr/local/iobricks/iobricksd":	"complain",
		"/usr/local/iobricks/monitor/monitor":	"complain",
		"/usr/local/iobricks/monitor/monitor_datapath":	"complain",
		"/usr/local/iobricks/monitor/monitor_fmt":	"complain",
		"/usr/local/iobricks/monitor/monitor_vpe_enable":	"complain",
		"/usr/local/skydive/skydive":	"complain",
		"/usr/sbin/mlx-setup.sh":	"complain",
		"confined_user":	"complain",
		"docker-extended":	"complain",
		"fluentd-logs":	"complain",
		"fluentd-qradar":	"complain"
	},
	"processes":	{
		"/bin/ssf-validator-fluentbit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382291",
				"status":	"enforce"
			}],
		"/compute-agent":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1386258",
				"status":	"enforce"
			}],
		"/fabcon-manager":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1385658",
				"status":	"enforce"
			}],
		"/fluent-bit/bin/fluent-bit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382361",
				"status":	"enforce"
			}],
		"/home/genctl/stunnelserver":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381366",
				"status":	"enforce"
			}],
		"/storage-agent":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"3920388",
				"status":	"enforce"
			}],
		"/synthetics/datagen":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382421",
				"status":	"enforce"
			}],
		"/usr/bin/bash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381344",
				"status":	"enforce"
			}],
		"/usr/bin/dash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380830",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381166",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382245",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"3920317",
				"status":	"enforce"
			}],
		"/usr/bin/prometheus-node-exporter":	[{
				"profile":	"/usr/bin/prometheus-node-exporter",
				"pid":	"1193805",
				"status":	"enforce"
			}],
		"/usr/bin/qemu-system-x86_64":	[{
				"profile":	"libvirt-5b5f0fb5-3efb-4a95-8032-7140f5096d81",
				"pid":	"1387709",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-1a2f4cef-208b-4bdf-9b54-7b4248bd29e7",
				"pid":	"1387793",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-c8dd410c-781e-46fa-855c-d867ed5c63ec",
				"pid":	"1388049",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-33f22359-a64a-4e96-b914-d2914e5a6d84",
				"pid":	"1389089",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-524536fa-a847-412c-8b6f-22a438924884",
				"pid":	"1389313",
				"status":	"enforce"
			}, {
				"profile":	"libvirt-e513a8fa-5e06-454d-bd2b-ec7f3caf0eb0",
				"pid":	"1389541",
				"status":	"enforce"
			}],
		"/usr/bin/ruby":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1379168",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1379199",
				"status":	"enforce"
			}],
		"/usr/bin/stunnel":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381365",
				"status":	"enforce"
			}],
		"/usr/bin/vault":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380860",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381182",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1382260",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"3920331",
				"status":	"enforce"
			}],
		"/usr/sbin/block-agent-server":	[{
				"profile":	"/sbin/block-agent-server",
				"pid":	"1200850",
				"status":	"enforce"
			}],
		"/usr/sbin/coalesce-agent":	[{
				"profile":	"/sbin/coalesce-agent",
				"pid":	"1074750",
				"status":	"enforce"
			}],
		"/usr/sbin/coalesce-agent-nr":	[{
				"profile":	"/sbin/coalesce-agent-nr",
				"pid":	"1191074",
				"status":	"enforce"
			}],
		"/usr/sbin/computeproxy":	[{
				"profile":	"/sbin/computeproxy",
				"pid":	"1190973",
				"status":	"enforce"
			}],
		"/usr/sbin/consolemultiplexer":	[{
				"profile":	"/sbin/consolemultiplexer",
				"pid":	"1191018",
				"status":	"enforce"
			}],
		"/usr/sbin/cos-transfer-agent":	[{
				"profile":	"/sbin/cos-transfer-agent",
				"pid":	"1076383",
				"status":	"enforce"
			}],
		"/usr/sbin/cos-transfer-agent-nr":	[{
				"profile":	"/sbin/cos-transfer-agent-nr",
				"pid":	"1191113",
				"status":	"enforce"
			}],
		"/usr/sbin/dhclient":	[{
				"profile":	"/{,usr/}sbin/dhclient",
				"pid":	"3495553",
				"status":	"enforce"
			}],
		"/usr/sbin/guestproxysvc":	[{
				"profile":	"/sbin/guestproxysvc",
				"pid":	"1073846",
				"status":	"enforce"
			}],
		"/usr/sbin/libvirtd":	[{
				"profile":	"libvirtd",
				"pid":	"1190891",
				"status":	"enforce"
			}],
		"/usr/sbin/metadataagent":	[{
				"profile":	"/sbin/metadataagent",
				"pid":	"1387518",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1387699",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1387983",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1389008",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1389029",
				"status":	"enforce"
			}, {
				"profile":	"/sbin/metadataagent",
				"pid":	"1389463",
				"status":	"enforce"
			}],
		"/usr/sbin/net-block-agent":	[{
				"profile":	"/{,usr/}sbin/net-block-agent",
				"pid":	"1076587",
				"status":	"enforce"
			}],
		"/usr/sbin/sshd":	[{
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"880206",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"880218",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd",
				"pid":	"1202126",
				"status":	"enforce"
			}],
		"/usr/sbin/threadbare":	[{
				"profile":	"/sbin/threadbare",
				"pid":	"1073712",
				"status":	"enforce"
			}],
		"/usr/lib/frr/bgpd":	[{
				"profile":	"/usr/lib/frr/bgpd",
				"pid":	"89225",
				"status":	"complain"
			}],
		"/usr/lib/frr/staticd":	[{
				"profile":	"/usr/lib/frr/staticd",
				"pid":	"89232",
				"status":	"complain"
			}],
		"/usr/lib/frr/watchfrr":	[{
				"profile":	"/usr/lib/frr/watchfrr",
				"pid":	"89205",
				"status":	"complain"
			}],
		"/usr/lib/frr/zebra":	[{
				"profile":	"/usr/lib/frr/zebra",
				"pid":	"89219",
				"status":	"complain"
			}],
		"/usr/local/fabcon/fabcon_server":	[{
				"profile":	"/usr/local/fabcon/fabcon_server",
				"pid":	"1195941",
				"status":	"complain"
			}],
		"/usr/local/iobricks/iobricksd":	[{
				"profile":	"/usr/local/iobricks/iobricksd",
				"pid":	"340797",
				"status":	"complain"
			}],
		"/usr/local/skydive/skydive":	[{
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"339190",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"339221",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"339331",
				"status":	"complain"
			}]
	}
}
'
<i>2024-12-17 17:58:12.083048</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 845, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 1226, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[399 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[2226 chars]e"}}' != '{"pr[399 chars]", "/sbin/block-agent-server": "enforce", "/sb[2173 chars]e"}}'
Diff is 5773 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:58:12.083132</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:58:12.219985</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:12.219966</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:12.219977</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:12.219980</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:12.220028</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:58:12.220047</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:58:12.267701</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:58:12.270873</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
messagebus
systemd-timesync
input
sgx
kvm
render
lxd
tss
_ssh
fwupd-refresh
admin
netdev
syslog
sysop
crontab
nslcd
tcpdump
_lldpd
uuidd
rdma
libvirt
libvirt-qemu
libvirt-dnsmasq
swtpm
ssl-cert
postfix
postdrop
frrvty
frr
vault
rmds
consolemux
host-logging
prometheus
docker
sugroup
sysgt
no_user
'
<i>2024-12-17 17:58:12.270970</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:58:12.271089</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:12.271076</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:12.271083</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:12.271086</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:12.271134</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:58:12.271155</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:58:12.324984</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:58:12.327018</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin
messagebus::/nonexistent:/usr/sbin/nologin
systemd-timesync:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
sshd::/run/sshd:/usr/sbin/nologin
fwupd-refresh:fwupd-refresh user,,,:/run/systemd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
nslcd:nslcd name service LDAP connection daemon,,,:/run/nslcd:/usr/sbin/nologin
tcpdump::/nonexistent:/usr/sbin/nologin
_lldpd::/run/lldpd:/usr/sbin/nologin
uuidd::/run/uuidd:/usr/sbin/nologin
libvirt-qemu:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
libvirt-dnsmasq:Libvirt Dnsmasq,,,:/var/lib/libvirt/dnsmasq:/usr/sbin/nologin
swtpm:virtual TPM software stack,,,:/var/lib/swtpm:/bin/false
postfix::/var/spool/postfix:/usr/sbin/nologin
_rpc::/run/rpcbind:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
rmds:VPC Metadata Services:/home/rmds:/usr/sbin/nologin
genctl:GenCTL User,,,:/home/genctl:/usr/sbin/nologin
consolemux:VSI Console Multiplexer account:/home/consolemux:/usr/sbin/nologin
host-logging:Logging account:/home/host-logging:/usr/sbin/nologin
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:58:12.327132</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:58:12.450929</td>
    <td>0.32</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:12.450916</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:12.450924</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:12.450926</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:12.450987</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.451041</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.451057</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:58:12.451127</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.451140</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:58:12.452035</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.452053</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:58:12.452138</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.452151</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.452166</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:58:12.452233</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.452246</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release6 : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release6
<i>2024-12-17 17:58:12.452398</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.452412</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:58:12.453650</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.453667</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:58:12.454069</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:58:12.769353</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:58:12.771323</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root    0 Dec 17 17:58 cron.allow
drwxr-x--- 2 root root  100 Dec 17 17:58 cron.d
drwxr-x--- 2 root root  300 Dec 17 17:58 cron.daily
drwxr-x--- 2 root root  200 Dec 17 17:58 cron.hourly
drwxr-x--- 2 root root   40 Dec 17 17:58 cron.monthly
drwxr-x--- 2 root root   40 Dec 17 17:58 cron.weekly
-rw-r----- 1 root root 1229 Dec 17 17:58 crontab
'
<i>2024-12-17 17:58:12.771337</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:58:12.774746</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:58:12.774761</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:58:12.774776</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:58:12.774890</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:12.774880</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:12.774884</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:12.774887</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:12.774906</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:58:12.776547</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'*/15 * * * * /usr/bin/rclone_cache_monitor.sh -r 10 -i 10 | /usr/bin/logger -t rclone_cache_monitor
* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
'
<i>2024-12-17 17:58:12.776561</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:58:12.778064</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:58:12.778096</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release6/compute : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release6/compute
<i>2024-12-17 17:58:12.778119</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release6/compute : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release6/compute
<i>2024-12-17 17:58:12.778125</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -y --suppress-common-lines -EZbwB /tmp/crontab_data /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release6/compute
<i>2024-12-17 17:58:12.779808</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger	      <
'
<i>2024-12-17 17:58:12.779883</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown
<i>2024-12-17 17:58:12.780198</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/cronjob_info/test_crontasks.py", line 140, in test_crontab_diff
    self.assertEqual(exit_code, 0, "Diffs in crontab tasks found!")
  File "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 226, in assertEqual
    raise e
  File "/home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
AssertionError: 1 != 0 : Diffs in crontab tasks found!
</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:58:12.780304</td>
    <td>53.68</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:58:12.780293</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:58:12.780299</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:58:12.780302</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:58:12.780320</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:58:12.782239</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:58:12.782252</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:58:12.782813</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:58:12.782821</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:58:14.798845</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:58:14.798874</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:58:14.798910</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:58:14.798914</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:58:14.798918</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:59:04.445725</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
................
good
'
<i>2024-12-17 17:59:04.445754</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:59:04.445761</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:59:04.447933</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:59:04.447950</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:59:06.465081</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:59:06.465183</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:59:06.588966</td>
    <td>0.19</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:59:06.588952</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:59:06.588960</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:59:06.588963</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:59:06.588999</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:59:06.589003</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:59:06.589006</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:59:06.779333</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

Linked to: nmnode2-03-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:59:06.779434</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:59:06.894295</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:59:06.894282</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:59:06.894289</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:59:06.894292</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:59:06.894328</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:59:06.894332</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:59:06.894335</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:59:06.944243</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:59:06.944327</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:59:06.944435</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:59:06.944425</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:59:06.944430</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:59:06.944433</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:59:06.944474</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:59:06.944477</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:59:06.944480</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:59:06.991901</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:59:06.991989</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:59:07.106165</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:59:07.106151</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:59:07.106159</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:59:07.106162</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:59:07.106199</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:59:07.106203</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:59:07.106206</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:59:07.111539</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:59:07.111590</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:59:07.111672</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:59:07.111662</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:59:07.111667</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:59:07.111670</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:59:07.111699</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:59:07.111702</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:59:07.111705</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:59:07.116460</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:59:07.116507</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:59:07.116578</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:59:07.116568</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:59:07.116573</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:59:07.116575</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:59:07.116605</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:59:07.116608</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:59:07.116612</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014266_2724/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:59:07.121342</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:59:07.121389</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:59:07.235128</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s14 (compute)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:59:07.235115</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:59:07.235122</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:47 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:11 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:48:11 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:56:06 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:32 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:08 UTC, STATUS=success)

<i>2024-12-17 17:59:07.235125</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:59:07.235149</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:59:07.237679</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.XXXXXXXXX87BJlO
'
<i>2024-12-17 17:59:07.237691</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.XXXXXXXXX87BJlO | grep "publickey ssh-rsa"
<i>2024-12-17 17:59:07.239382</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:59:07.239428</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:54.910067</td>
    <td>1.02</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:54.910054</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:54.910062</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:54.910065</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:54.910107</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.910112</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.910116</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:55.932263</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    1878K  172M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      76M   72G KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3    1878K  172M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4      76M   72G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5      77M   73G HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     280K   17M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2     280K   17M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3      66M   91G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4      66M   91G HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    1856K  197M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      24M   13G KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3    1840K  196M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4    1840K  196M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5    1840K  196M DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
6    1840K  196M DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
7        0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
8        0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0           
9        0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0           
10       0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0           
11       0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
12   1840K  196M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 2 packets, 144 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     514K  398M KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      765  352K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3     514K  398M KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      765  352K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     517K  399M HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     513K  398M KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      148 11840 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      148 11840 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4     516K  399M HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2     1233 71956 KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     1239 72400 HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION                                                                  
  acpid.service                        loaded    inactive dead    ACPI event daemon                                                            
# am-utils.service                     not-found inactive dead    am-utils.service                                                             
# apache2.service                      not-found inactive dead    apache2.service                                                              
  apparmor.service                     loaded    active   exited  AppArmor initialization                                                      
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities                                       
# apt-daily.service                    masked    inactive dead    apt-daily.service                                                            
# atd.service                          not-found inactive dead    atd.service                                                                  
  auditd.service                       loaded    active   running Security Auditing Service                                                    
# autofs.service                       not-found inactive dead    autofs.service                                                               
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats                      
  blk-availability.service             loaded    active   exited  Availability of block devices                                                
# citadel.service                      not-found inactive dead    citadel.service                                                              
  cloudnet-gobgp.service               loaded    inactive dead    gobgpd service                                                               
  containerd.service                   loaded    active   running containerd container runtime                                                 
# courier-ldap.service                 not-found inactive dead    courier-ldap.service                                                         
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service                                                      
# courier-mta.service                  not-found inactive dead    courier-mta.service                                                          
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service                                                      
# courier-pop.service                  not-found inactive dead    courier-pop.service                                                          
  cron.service                         loaded    active   running Regular background program processing daemon                                 
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service                                                          
  dbus.service                         loaded    active   running D-Bus System Message Bus                                                     
# display-manager.service              not-found inactive dead    display-manager.service                                                      
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon                                                   
  docker.service                       loaded    active   running Docker Application Container Engine                                          
# dovecot.service                      not-found inactive dead    dovecot.service                                                              
  ebtables.service                     loaded    active   exited  ebtables ruleset management                                                  
  emergency.service                    loaded    inactive dead    Emergency Shell                                                              
  etcd.service                         loaded    active   running etcd                                                                         
# etcd2.service                        not-found inactive dead    etcd2.service                                                                
# exim4.service                        not-found inactive dead    exim4.service                                                                
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service                                    
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.      
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor                                                    
# fcoe.service                         not-found inactive dead    fcoe.service                                                                 
# firewalld.service                    not-found inactive dead    firewalld.service                                                            
  frr.service                          loaded    active   running FRRouting                                                                    
  fstrim.service                       loaded    inactive dead    Discard unused blocks                                                        
# gdm3.service                         not-found inactive dead    gdm3.service                                                                 
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available                      
  getty@tty1.service                   loaded    active   running Getty on tty1                                                                
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes                                    
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service                                                 
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service                                                          
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service                                                          
  hmonagent-mlx.service                loaded    active   running Genesis Fabric-3 Health Monitor Agent                                        
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device          
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service                                                       
# iscsi.service                        not-found inactive dead    iscsi.service                                                                
# iscsid.service                       not-found inactive dead    iscsid.service                                                               
# kdm.service                          not-found inactive dead    kdm.service                                                                  
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service                                            
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec                                            
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system                           
# keylime_agent.service                masked    inactive dead    keylime_agent.service                                                        
  kmod-static-nodes.service            loaded    active   exited  Create list of required static device nodes for the current kernel           
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service                                                   
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service                                                             
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster                                                 
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent                                           
  lldpd.service                        loaded    active   running LLDP daemon                                                                  
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service                                                      
  lvm2-lvmetad.service                 loaded    active   running LVM2 metadata daemon                                                         
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon                                                             
  lvm2-monitor.service                 loaded    active   exited  Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service                                                 
# masqmail.service                     not-found inactive dead    masqmail.service                                                             
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.                      
  motd-news.service                    loaded    inactive dead    Message of the Day                                                           
  mst.service                          loaded    active   exited  LSB: mst                                                                     
  nessusagent.service                  loaded    active   running The Nessus Client Agent                                                      
# network.service                      not-found inactive dead    network.service                                                              
  networking.service                   loaded    inactive dead    Raise network interfaces                                                     
# nfs-blkmap.service                   not-found inactive dead    nfs-blkmap.service                                                           
  nfs-config.service                   loaded    inactive dead    Preprocess NFS configuration                                                 
# nfs-server.service                   not-found inactive dead    nfs-server.service                                                           
  nfs-utils.service                    loaded    active   exited  NFS server and client services                                               
  nftables.service                     loaded    active   exited  nftables                                                                     
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon                                                  
# nullmailer.service                   not-found inactive dead    nullmailer.service                                                           
  ondemand.service                     loaded    inactive dead    Set the CPU Frequency Scaling governor                                       
  osqueryd.service                     loaded    active   running The osquery Daemon                                                           
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service                                                   
# plymouth-start.service               not-found inactive dead    plymouth-start.service                                                       
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics                                      
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility                                                  
  rescue.service                       loaded    inactive dead    Rescue Shell                                                                 
  rpc-gssd.service                     loaded    inactive dead    RPC security service for NFS client and server                               
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart                                                
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.                                      
  rpcbind.service                      loaded    inactive dead    RPC bind portmap service                                                     
  rsync.service                        loaded    inactive dead    fast remote file copy program daemon                                         
  rsyslog.service                      loaded    active   running System Logging Service                                                       
# sendmail.service                     not-found inactive dead    sendmail.service                                                             
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0                                                        
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1                                                        
# set-hostname.service                 not-found inactive dead    set-hostname.service                                                         
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service                                                           
  skydive.service                      loaded    active   running Skydive                                                                      
# slapd.service                        not-found inactive dead    slapd.service                                                                
# slim.service                         not-found inactive dead    slim.service                                                                 
  ssh.service                          loaded    active   running OpenBSD Secure Shell server                                                  
  strongswan.service                   loaded    active   running strongSwan IPsec IKEv1/IKEv2 daemon using ipsec.conf                         
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console                                        
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall                                            
  systemd-binfmt.service               loaded    inactive dead    Set Up Additional Binary Formats                                             
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device                                             
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status                                    
  systemd-hwdb-update.service          loaded    inactive dead    Rebuild Hardware Database                                                    
  systemd-initctl.service              loaded    inactive dead    /dev/initctl Compatibility Daemon                                            
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage                                          
  systemd-journald.service             loaded    active   running Journal Service                                                              
  systemd-logind.service               loaded    active   running Login Service                                                                
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk                                        
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules                                                          
  systemd-networkd-wait-online.service loaded    active   exited  Wait for Network to be Configured                                            
  systemd-networkd.service             loaded    active   running Network Service                                                              
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed                                                        
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems                                         
  systemd-resolved.service             loaded    active   running Network Name Resolution                                                      
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables                                                       
# systemd-sysusers.service             not-found inactive dead    systemd-sysusers.service                                                     
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization                                                 
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories                                             
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev                                           
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories                                        
  systemd-udev-trigger.service         loaded    active   exited  udev Coldplug all Devices                                                    
  systemd-udevd.service                loaded    active   running udev Kernel Device Manager                                                   
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service                                                  
  systemd-update-utmp-runlevel.service loaded    inactive dead    Update UTMP about System Runlevel Changes                                    
  systemd-update-utmp.service          loaded    active   exited  Update UTMP about System Boot/Shutdown                                       
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions                                                         
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service                                               
  taniumclient.service                 loaded    active   running Tanium Client                                                                
  user@1000.service                    loaded    active   running User Manager for UID 1000                                                    
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent                                      
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent                                       
  vagentx.service                      loaded    active   running service wrapper around vault agent                                           
# wdm.service                          not-found inactive dead    wdm.service                                                                  
# xdm.service                          not-found inactive dead    xdm.service                                                                  

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.

140 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State   Recv-Q  Send-Q         Local Address:Port      Peer Address:Port                                                                                  
udp   UNCONN  0       0                    0.0.0.0:47575          0.0.0.0:*      users:(("rpc.statd",pid=159496,fd=8))                                          
udp   UNCONN  0       0                11.50.210.2:50052          0.0.0.0:*      users:(("fabcon_server",pid=169925,fd=14))                                     
udp   UNCONN  0       0              127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=120945,fd=12))                                   
udp   UNCONN  0       0                    0.0.0.0:500            0.0.0.0:*      users:(("charon",pid=12285,fd=14))                                             
udp   UNCONN  0       0                  127.0.0.1:672            0.0.0.0:*      users:(("rpc.statd",pid=159496,fd=5))                                          
udp   UNCONN  0       0                    0.0.0.0:4500           0.0.0.0:*      users:(("charon",pid=12285,fd=15))                                             
udp   UNCONN  0       0                    0.0.0.0:4789           0.0.0.0:*                                                                                     
udp   UNCONN  0       0                          *:500                  *:*      users:(("charon",pid=12285,fd=12))                                             
udp   UNCONN  0       0                          *:4500                 *:*      users:(("charon",pid=12285,fd=13))                                             
udp   UNCONN  0       0                       [::]:28082             [::]:*      users:(("rpc.statd",pid=159496,fd=10))                                         
tcp   LISTEN  0       16384              127.0.0.1:10248          0.0.0.0:*      users:(("kubelet",pid=21895,fd=16))                                            
tcp   LISTEN  0       16384              127.0.0.1:10249          0.0.0.0:*      users:(("kube-proxy",pid=1248,fd=14))                                          
tcp   LISTEN  0       3                  127.0.0.1:2601           0.0.0.0:*      users:(("zebra",pid=161643,fd=25))                                             
tcp   LISTEN  0       16384              127.0.0.1:50059          0.0.0.0:*      users:(("fabcon_server",pid=169925,fd=20))                                     
tcp   LISTEN  0       16384              127.0.0.1:9100           0.0.0.0:*      users:(("prometheus-node",pid=167083,fd=3))                                    
tcp   LISTEN  0       3                  127.0.0.1:2605           0.0.0.0:*      users:(("bgpd",pid=161648,fd=18))                                              
tcp   LISTEN  0       16384              127.0.0.1:10257          0.0.0.0:*      users:(("kube-controller",pid=23151,fd=3))                                     
tcp   LISTEN  0       16384              127.0.0.1:10259          0.0.0.0:*      users:(("kube-scheduler",pid=23128,fd=3))                                      
tcp   LISTEN  0       128                  0.0.0.0:179            0.0.0.0:*      users:(("bgpd",pid=161648,fd=22))                                              
tcp   LISTEN  0       128            127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=120945,fd=13))                                   
tcp   LISTEN  0       128                  0.0.0.0:22             0.0.0.0:*      users:(("sshd",pid=175795,fd=3))                                               
tcp   LISTEN  0       3                  127.0.0.1:2616           0.0.0.0:*      users:(("staticd",pid=161655,fd=11))                                           
tcp   LISTEN  0       16384              127.0.0.1:27519          0.0.0.0:*      users:(("containerd",pid=182480,fd=14))                                        
tcp   LISTEN  0       1024             11.50.210.2:17472          0.0.0.0:*      users:(("TaniumClient",pid=172182,fd=65))                                      
tcp   LISTEN  0       1024               127.0.0.1:17473          0.0.0.0:*      users:(("TaniumClient",pid=172182,fd=67))                                      
tcp   LISTEN  0       16384              127.0.0.1:50055          0.0.0.0:*      users:(("fabcon_server",pid=169925,fd=19))                                     
tcp   LISTEN  0       128                  0.0.0.0:23367          0.0.0.0:*      users:(("rpc.statd",pid=159496,fd=9))                                          
tcp   LISTEN  0       16384                      *:50057                *:*      users:(("fabcon_server",pid=169925,fd=17))                                     
tcp   LISTEN  0       16384                      *:10250                *:*      users:(("kubelet",pid=21895,fd=18))                                            
tcp   LISTEN  0       16384                      *:6443                 *:*      users:(("kube-apiserver",pid=25123,fd=3))                                      
tcp   LISTEN  0       16384                      *:2379                 *:*      users:(("etcd",pid=179482,fd=7))                                               
tcp   LISTEN  0       16384                      *:2380                 *:*      users:(("etcd",pid=179482,fd=3))                                               
tcp   LISTEN  0       16384                      *:10256                *:*      users:(("kube-proxy",pid=1248,fd=15))                                          
tcp   LISTEN  0       128       [::ffff:127.0.0.1]:10514                *:*      users:(("iobricksd",pid=81503,fd=30))                                          
tcp   LISTEN  0       128                     [::]:179               [::]:*      users:(("bgpd",pid=161648,fd=23))                                              
tcp   LISTEN  0       128                     [::]:22                [::]:*      users:(("sshd",pid=175795,fd=4))                                               
tcp   LISTEN  0       16384                      *:50051                *:*      users:(("fabcon_server",pid=169925,fd=18))                                     
tcp   LISTEN  0       128                     [::]:38979             [::]:*      users:(("rpc.statd",pid=159496,fd=11))                                         

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==
#	$OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/bin:/bin:/usr/sbin:/sbin

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# PasswordAuthentication.  Depending on your PAM configuration,
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#UseLogin no
#Compression delayed
#UseDNS no
#PidFile /var/run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:

#includedir /etc/sudoers.d
Defaults use_pty
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
lxd:x:104:
input:x:105:
crontab:x:106:
messagebus:x:107:
ssh:x:108:
admin:x:110:
netdev:x:111:
uuidd:x:109:
syslog:x:112:
sysop:x:1000:
nslcd:x:113:
_lldpd:x:114:
docker:x:999:
ssl-cert:x:115:
postfix:x:116:
postdrop:x:117:
tss:x:118:
frrvty:x:119:frr
frr:x:120:
vault:x:998:
prometheus:x:62700:
systemd-timesync:x:997:
libvirt:x:200:
sugroup:x:1001:
sysgt:x:1002:
no_user:x:996:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_tally2.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth  [success=2 default=ignore] pam_unix.so nullok_secure
auth  [success=1 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth  required                   pam_deny.so
auth  required                   pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900
auth  required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so remember=5
password [success=2 default=ignore] pam_unix.so obscure use_authtok try_first_pass sha512
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

session optional /usr/lib/pam_osquery.so

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows root logins except on tty\'s listed in /etc/securetty
# (Replaces the `CONSOLE\' setting from login.defs)
#
# With the default control of this module:
#   [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die]
# root will not be prompted for a password on insecure lines.
# if an invalid username is entered, a password is prompted (but login
# will eventually be rejected)
#
# You can change it to a "requisite" module if you think root may mis-type
# her login and should not be prompted for a password in that case. But
# this will leave the system as vulnerable to user enumeration attacks.
#
# You can change it to a "required" module if you think it permits to
# guess valid user names of your system (invalid user names are considered
# as possibly being root on insecure lines), but root passwords may be
# communicated over insecure lines.
auth [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die] pam_securetty.so

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_04_15_00 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group root
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "root" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/sudo <==
#%PAM-1.0

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/systemd-user <==
# This file is part of systemd.
#
# Used by systemd --user instances.

@include common-account

session  required pam_selinux.so close
session  required pam_selinux.so nottys open
session  required pam_loginuid.so
session  required pam_limits.so
@include common-session-noninteractive
session optional pam_systemd.so

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd:x:103:65534::/var/lib/lxd/:/bin/false
messagebus:x:105:107::/nonexistent:/usr/sbin/nologin
sshd:x:106:65534::/run/sshd:/usr/sbin/nologin
uuidd:x:107:109::/run/uuidd:/usr/sbin/nologin
syslog:x:109:112::/home/syslog:/usr/sbin/nologin
sysop:x:1000:1000::/home/sysop:/bin/bash
nslcd:x:104:113:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd:x:108:114::/var/run/lldpd:/usr/sbin/nologin
strongswan:x:110:65534::/var/lib/strongswan:/usr/sbin/nologin
postfix:x:111:116::/var/spool/postfix:/usr/sbin/nologin
statd:x:112:65534::/var/lib/nfs:/usr/sbin/nologin
tss:x:113:118:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:x:114:118:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:x:115:120:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:998::/home/vault:/bin/false
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:x:998:997:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt:x:1001:1002::/home/sysgt:/bin/bash
genctl:x:60000:200::/home/genctl:/usr/sbin/nologin
no_user:x:65535:996:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
mail.*				-/var/log/mail.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.28.12504.0aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        fluentbit-logs-llq7q                                              4/4     Running     0             25h     11.50.210.8    dal1-qz2-sr2-rk203-s18   <none>           <none>
genctl        fluentd-qradar-ds-xxkmw                                           1/1     Running     0             25h     11.50.210.6    dal1-qz2-sr2-rk203-s18   <none>           <none>
genctl        genctl-etcd-cluster-8zcv5fll69                                    3/3     Running     0             25h     11.50.210.9    dal1-qz2-sr2-rk203-s18   <none>           <none>
genctl        net-control-cleanup-67d7cd797f-bdc4x                              2/2     Running     3 (25h ago)   25h     11.50.210.7    dal1-qz2-sr2-rk203-s18   <none>           <none>
kube-system   kube-apiserver-dal1-qz2-sr2-rk203-s18                             1/1     Running     0             25h     10.22.64.57    dal1-qz2-sr2-rk203-s18   <none>           <none>
kube-system   kube-controller-manager-dal1-qz2-sr2-rk203-s18                    1/1     Running     1 (25h ago)   25h     10.22.64.57    dal1-qz2-sr2-rk203-s18   <none>           <none>
kube-system   kube-etcd-backup-operator-595cbbd7bc-949pj                        2/2     Running     0             20h     11.50.210.10   dal1-qz2-sr2-rk203-s18   <none>           <none>
kube-system   kube-proxy-qtb6h                                                  1/1     Running     0             25h     10.22.64.57    dal1-qz2-sr2-rk203-s18   <none>           <none>
kube-system   kube-scheduler-dal1-qz2-sr2-rk203-s18                             1/1     Running     2 (25h ago)   25h     10.22.64.57    dal1-qz2-sr2-rk203-s18   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
47 profiles are loaded.
29 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /sbin/dhclient
   /usr/bin/etcd
   /usr/bin/prometheus-node-exporter
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/lib/ipsec/charon
   /usr/lib/ipsec/stroke
   /usr/sbin/canonical-livepatchd
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /usr/sbin/swanctl
   /usr/sbin/tcpdump
   cri-containerd.apparmor.d
   docker-default
   fluentbit-logs
   genctl-ingress-controller
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
18 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/hmonagent
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
43 processes have profiles defined.
28 processes are in enforce mode.
   /sbin/dhclient (117758) 
   /usr/bin/etcd (179482) 
   /usr/bin/prometheus-node-exporter (167083) 
   /usr/lib/ipsec/charon (12285) 
   /usr/sbin/sshd (175795) 
   /usr/sbin/sshd//sysop (109692) 
   /usr/sbin/sshd//sysop (109710) 
   cri-containerd.apparmor.d (23128) 
   cri-containerd.apparmor.d (23151) 
   cri-containerd.apparmor.d (25123) 
   cri-containerd.apparmor.d (62399) 
   cri-containerd.apparmor.d (62840) 
   cri-containerd.apparmor.d (62901) 
   cri-containerd.apparmor.d (63096) 
   cri-containerd.apparmor.d (64049) 
   cri-containerd.apparmor.d (64076) 
   cri-containerd.apparmor.d (64111) 
   cri-containerd.apparmor.d (64256) 
   cri-containerd.apparmor.d (64400) 
   cri-containerd.apparmor.d (65719) 
   cri-containerd.apparmor.d (65790) 
   cri-containerd.apparmor.d (65813) 
   cri-containerd.apparmor.d (65847) 
   cri-containerd.apparmor.d (65960) 
   cri-containerd.apparmor.d (68431) 
   cri-containerd.apparmor.d (73498) 
   cri-containerd.apparmor.d (73561) 
   cri-containerd.apparmor.d (73585) 
15 processes are in complain mode.
   /usr/lib/frr/bgpd (161648) 
   /usr/lib/frr/staticd (161655) 
   /usr/lib/frr/watchfrr (161618) 
   /usr/lib/frr/zebra (161643) 
   /usr/local/fabcon/fabcon_server (169925) 
   /usr/local/fabcon/fabcon_server (170846) 
   /usr/local/fabcon/fabcon_server (170852) 
   /usr/local/fabcon/fabcon_server (170858) 
   /usr/local/fabcon/fabcon_server (170863) 
   /usr/local/fabcon/fabcon_server (170868) 
   /usr/local/iobricks/iobricksd (81503) 
   /usr/local/skydive/skydive (79781) 
   /usr/local/skydive/skydive (79834) 
   /usr/local/skydive/skydive (79912) 
   /usr/sbin/hmonagent (82476) 
0 processes are unconfined but have a profile defined.
'
<i>2024-12-17 17:36:55.932456</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.025542</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.025529</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.025536</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:56.025539</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.025572</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:36:56.026710</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:36:56.026859</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_master_node_releases :Verify release bundles deployed on master node</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.027046</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.027030</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.027040</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:56.027043</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.027072</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/genesis/release_bundles
<i>2024-12-17 17:36:56.029046</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)
hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)
hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)
hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)
hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)
hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)
hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)
etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)
kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)
kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)
kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)
hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)
'
<i>2024-12-17 17:36:56.029193</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.029400</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.029388</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.029394</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:56.029398</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.029430</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'master'}
<i>2024-12-17 17:36:56.029455</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.228218</td>
    <td>0.23</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.228205</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.228212</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:56.228215</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.228243</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.228262</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.228281</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.228284</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:56.268938</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.269082</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:56.455935</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/dhclient": [
            {
                "pid": "117758",
                "status": "enforce"
            }
        ],
        "/usr/bin/etcd": [
            {
                "pid": "179482",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "167083",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "161648",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "161655",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "161618",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "161643",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "12285",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "169925",
                "status": "complain"
            },
            {
                "pid": "170846",
                "status": "complain"
            },
            {
                "pid": "170852",
                "status": "complain"
            },
            {
                "pid": "170858",
                "status": "complain"
            },
            {
                "pid": "170863",
                "status": "complain"
            },
            {
                "pid": "170868",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "81503",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "79781",
                "status": "complain"
            },
            {
                "pid": "79834",
                "status": "complain"
            },
            {
                "pid": "79912",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "82476",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "175795",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "109692",
                "status": "enforce"
            },
            {
                "pid": "109710",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "23128",
                "status": "enforce"
            },
            {
                "pid": "23151",
                "status": "enforce"
            },
            {
                "pid": "25123",
                "status": "enforce"
            },
            {
                "pid": "62399",
                "status": "enforce"
            },
            {
                "pid": "62840",
                "status": "enforce"
            },
            {
                "pid": "62901",
                "status": "enforce"
            },
            {
                "pid": "63096",
                "status": "enforce"
            },
            {
                "pid": "64049",
                "status": "enforce"
            },
            {
                "pid": "64076",
                "status": "enforce"
            },
            {
                "pid": "64111",
                "status": "enforce"
            },
            {
                "pid": "64256",
                "status": "enforce"
            },
            {
                "pid": "64400",
                "status": "enforce"
            },
            {
                "pid": "65719",
                "status": "enforce"
            },
            {
                "pid": "65790",
                "status": "enforce"
            },
            {
                "pid": "65813",
                "status": "enforce"
            },
            {
                "pid": "65847",
                "status": "enforce"
            },
            {
                "pid": "65960",
                "status": "enforce"
            },
            {
                "pid": "68431",
                "status": "enforce"
            },
            {
                "pid": "73498",
                "status": "enforce"
            },
            {
                "pid": "73561",
                "status": "enforce"
            },
            {
                "pid": "73585",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/etcd": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:56.462117</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1664 chars]e"}}' != '{"pr[333 chars]", "/sbin/dhclient": "enforce", "/usr/bin/etcd[1611 chars]e"}}'
Diff is 4907 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:56.462275</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.462435</td>
    <td>0.43</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.462423</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.462429</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:56.462432</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.462460</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:36:56.646185</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:56.646231</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:36:56.646241</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.646310</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.646351</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.646356</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:56.685536</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.685586</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:56.883314</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/dhclient": [
            {
                "pid": "117758",
                "status": "enforce"
            }
        ],
        "/usr/bin/etcd": [
            {
                "pid": "179482",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "167083",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "161648",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "161655",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "161618",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "161643",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "12285",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "169925",
                "status": "complain"
            },
            {
                "pid": "170846",
                "status": "complain"
            },
            {
                "pid": "170852",
                "status": "complain"
            },
            {
                "pid": "170858",
                "status": "complain"
            },
            {
                "pid": "170863",
                "status": "complain"
            },
            {
                "pid": "170868",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "81503",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "79781",
                "status": "complain"
            },
            {
                "pid": "79834",
                "status": "complain"
            },
            {
                "pid": "79912",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "82476",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "175795",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "109692",
                "status": "enforce"
            },
            {
                "pid": "109710",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "23128",
                "status": "enforce"
            },
            {
                "pid": "23151",
                "status": "enforce"
            },
            {
                "pid": "25123",
                "status": "enforce"
            },
            {
                "pid": "62399",
                "status": "enforce"
            },
            {
                "pid": "62840",
                "status": "enforce"
            },
            {
                "pid": "62901",
                "status": "enforce"
            },
            {
                "pid": "63096",
                "status": "enforce"
            },
            {
                "pid": "64049",
                "status": "enforce"
            },
            {
                "pid": "64076",
                "status": "enforce"
            },
            {
                "pid": "64111",
                "status": "enforce"
            },
            {
                "pid": "64256",
                "status": "enforce"
            },
            {
                "pid": "64400",
                "status": "enforce"
            },
            {
                "pid": "65719",
                "status": "enforce"
            },
            {
                "pid": "65790",
                "status": "enforce"
            },
            {
                "pid": "65813",
                "status": "enforce"
            },
            {
                "pid": "65847",
                "status": "enforce"
            },
            {
                "pid": "65960",
                "status": "enforce"
            },
            {
                "pid": "68431",
                "status": "enforce"
            },
            {
                "pid": "73498",
                "status": "enforce"
            },
            {
                "pid": "73561",
                "status": "enforce"
            },
            {
                "pid": "73585",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/etcd": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:56.888540</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1664 chars]e"}}' != '{"pr[333 chars]", "/sbin/dhclient": "enforce", "/usr/bin/etcd[1611 chars]e"}}'
Diff is 4907 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:56.888645</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.994765</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.994753</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.994760</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:56.994762</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.994806</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:56.994831</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.047945</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:36:57.051220</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
lxd
input
crontab
messagebus
ssh
admin
netdev
uuidd
syslog
sysop
nslcd
_lldpd
docker
ssl-cert
postfix
postdrop
tss
frrvty
frr
vault
prometheus
systemd-timesync
libvirt
sugroup
sysgt
no_user
'
<i>2024-12-17 17:36:57.051457</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.051645</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.051634</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.051639</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:57.051642</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.051705</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:57.051737</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.102447</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:36:57.105076</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd::/var/lib/lxd/:/bin/false
messagebus::/nonexistent:/usr/sbin/nologin
sshd::/run/sshd:/usr/sbin/nologin
uuidd::/run/uuidd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
nslcd:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd::/var/run/lldpd:/usr/sbin/nologin
strongswan::/var/lib/strongswan:/usr/sbin/nologin
postfix::/var/spool/postfix:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
genctl::/home/genctl:/usr/sbin/nologin
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:36:57.105406</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.199875</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.199862</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.199869</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:57.199872</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.199944</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.199973</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.199989</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:36:57.200052</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.200064</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:36:57.200462</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.200476</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:36:57.200515</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.200527</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.200538</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:36:57.200590</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.200602</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.200612</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:36:57.201222</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.201237</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:36:57.201386</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.201404</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release5 : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release5
<i>2024-12-17 17:36:57.223803</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:36:57.226743</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root   0 Dec 17 17:36 cron.allow
drwxr-x--- 2 root root  60 Dec 17 17:36 cron.d
drwxr-x--- 2 root root 300 Dec 17 17:36 cron.daily
drwxr-x--- 2 root root 180 Dec 17 17:36 cron.hourly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.monthly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.weekly
-rw-r----- 1 root root 815 Dec 17 17:36 crontab
'
<i>2024-12-17 17:36:57.226787</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:36:57.229771</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.229814</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:36:57.229856</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:57.230069</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.230054</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.230061</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:57.230065</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.230091</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:36:57.232618</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'45 */12 * * * /opt/network/bin/cleanup_leaked_objs.sh >> /opt/network/cleanup/cleanup_leaked_objs.sh.log 2>&1
* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
* * * * * /opt/cron/sharedipcron 2>&1 | logger
'
<i>2024-12-17 17:36:57.232658</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:36:57.235057</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.235131</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release5/master : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/master
<i>2024-12-17 17:36:57.235168</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release5/master : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/master
<i>2024-12-17 17:36:57.235174</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -y --suppress-common-lines -EZbwB /tmp/crontab_data /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/master
<i>2024-12-17 17:36:57.237741</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger	      <
'
<i>2024-12-17 17:36:57.237972</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown
<i>2024-12-17 17:36:57.238419</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/cronjob_info/test_crontasks.py", line 140, in test_crontab_diff
    self.assertEqual(exit_code, 0, "Diffs in crontab tasks found!")
  File "/home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 226, in assertEqual
    raise e
  File "/home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
AssertionError: 1 != 0 : Diffs in crontab tasks found!
</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.238587</td>
    <td>7.26</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.238576</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.238582</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:36:57.238585</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.238622</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:36:57.240967</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.241030</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:36:57.242186</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.242222</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:36:59.257320</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:59.257378</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:36:59.257452</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.257459</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.257466</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:02.481670</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
.
good
'
<i>2024-12-17 17:37:02.481731</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:37:02.481744</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:37:02.484493</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:02.484532</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:04.498327</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:04.498488</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.606681</td>
    <td>0.09</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.606665</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.606673</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:37:04.606677</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.606730</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.606735</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.606738</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.693465</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

{"pid":110722,"time":1734457024632,"tid":1,"msg":"Warning -- could not open /usr/share/zoneinfo. Set the NESSUS_TZ_DIR env. variable","severity":"INFO"}
Linked to: nmnode2-01-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:37:04.693665</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.777862</td>
    <td>0.02</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.777848</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.777855</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:37:04.777859</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.777904</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:04.777908</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:04.777911</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:04.801481</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:37:04.801612</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.801761</td>
    <td>0.02</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.801750</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.801756</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:37:04.801759</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.801810</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:04.801816</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:04.801820</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:04.823329</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:37:04.823484</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.914716</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.914701</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.914709</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:37:04.914712</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.914764</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:04.914768</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:04.914771</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:04.920713</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:37:04.920870</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.921070</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.921059</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.921065</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:37:04.921068</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.921132</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:04.921138</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:04.921141</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:04.926747</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:37:04.926897</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.927078</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.927065</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.927072</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:37:04.927075</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.927136</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:04.927142</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:04.927145</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014276_8552/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:04.932277</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:37:04.932384</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.020055</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s18 (master)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.020040</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.020048</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:27 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:01:16 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:03 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:56 UTC, STATUS=success)

<i>2024-12-17 17:37:05.020052</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.020085</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:37:05.022741</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.9KuuK4HlmDqQQCK
'
<i>2024-12-17 17:37:05.022778</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.9KuuK4HlmDqQQCK | grep "publickey ssh-rsa"
<i>2024-12-17 17:37:05.025178</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:37:05.025348</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:54.975786</td>
    <td>1.13</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:54.975770</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:54.975779</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:54.975782</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:54.975841</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.975846</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.975850</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:56.106131</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     568K   93M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2     162M   64G KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3     568K   93M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4     162M   64G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5     230M   91G HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    46318 2881K KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    46318 2881K KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3     161M   56G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4     229M   81G HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    5955K  643M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      39M   14G KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3    5941K  642M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4    5941K  642M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5    5941K  642M DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
6    5941K  642M DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
7        0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
8        0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0           
9        0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0           
10       0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0           
11       0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
12   5941K  642M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 2 packets, 144 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      682  345K KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      617  341K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      682  345K KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      617  341K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5      993  502K HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      181 11152 KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4      247 14888 HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2     2516  145K KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     2516  145K HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION                                                                  
  acpid.service                        loaded    inactive dead    ACPI event daemon                                                            
# am-utils.service                     not-found inactive dead    am-utils.service                                                             
# apache2.service                      not-found inactive dead    apache2.service                                                              
  apparmor.service                     loaded    active   exited  AppArmor initialization                                                      
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities                                       
# apt-daily.service                    masked    inactive dead    apt-daily.service                                                            
# atd.service                          not-found inactive dead    atd.service                                                                  
  auditd.service                       loaded    active   running Security Auditing Service                                                    
# autofs.service                       not-found inactive dead    autofs.service                                                               
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats                      
  blk-availability.service             loaded    active   exited  Availability of block devices                                                
# citadel.service                      not-found inactive dead    citadel.service                                                              
  cloudnet-gobgp.service               loaded    active   running gobgpd service                                                               
  containerd.service                   loaded    active   running containerd container runtime                                                 
# courier-ldap.service                 not-found inactive dead    courier-ldap.service                                                         
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service                                                      
# courier-mta.service                  not-found inactive dead    courier-mta.service                                                          
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service                                                      
# courier-pop.service                  not-found inactive dead    courier-pop.service                                                          
  cron.service                         loaded    active   running Regular background program processing daemon                                 
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service                                                          
  dbus.service                         loaded    active   running D-Bus System Message Bus                                                     
# display-manager.service              not-found inactive dead    display-manager.service                                                      
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon                                                   
  docker.service                       loaded    active   running Docker Application Container Engine                                          
# dovecot.service                      not-found inactive dead    dovecot.service                                                              
  ebtables.service                     loaded    active   exited  ebtables ruleset management                                                  
  emergency.service                    loaded    inactive dead    Emergency Shell                                                              
# exim4.service                        not-found inactive dead    exim4.service                                                                
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service                                    
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.      
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor                                                    
# fcoe.service                         not-found inactive dead    fcoe.service                                                                 
# firewalld.service                    not-found inactive dead    firewalld.service                                                            
  frr.service                          loaded    active   running FRRouting                                                                    
  fstrim.service                       loaded    inactive dead    Discard unused blocks                                                        
# gdm3.service                         not-found inactive dead    gdm3.service                                                                 
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available                      
  getty@tty1.service                   loaded    active   running Getty on tty1                                                                
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes                                    
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service                                                 
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service                                                          
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service                                                          
  hmonagent-mlx.service                loaded    active   running Genesis Fabric-3 Health Monitor Agent                                        
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device          
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service                                                       
# iscsi.service                        not-found inactive dead    iscsi.service                                                                
# iscsid.service                       not-found inactive dead    iscsid.service                                                               
# kdm.service                          not-found inactive dead    kdm.service                                                                  
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service                                            
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec                                            
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system                           
# keylime_agent.service                masked    inactive dead    keylime_agent.service                                                        
  kmod-static-nodes.service            loaded    active   exited  Create list of required static device nodes for the current kernel           
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service                                                   
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service                                                             
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster                                                 
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent                                           
  lldpd.service                        loaded    active   running LLDP daemon                                                                  
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service                                                      
  lvm2-lvmetad.service                 loaded    active   running LVM2 metadata daemon                                                         
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon                                                             
  lvm2-monitor.service                 loaded    active   exited  Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service                                                 
# masqmail.service                     not-found inactive dead    masqmail.service                                                             
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.                      
  motd-news.service                    loaded    inactive dead    Message of the Day                                                           
  mst.service                          loaded    active   exited  LSB: mst                                                                     
  nessusagent.service                  loaded    active   running The Nessus Client Agent                                                      
# network.service                      not-found inactive dead    network.service                                                              
  networking.service                   loaded    inactive dead    Raise network interfaces                                                     
# nfs-blkmap.service                   not-found inactive dead    nfs-blkmap.service                                                           
  nfs-config.service                   loaded    inactive dead    Preprocess NFS configuration                                                 
# nfs-server.service                   not-found inactive dead    nfs-server.service                                                           
  nfs-utils.service                    loaded    active   exited  NFS server and client services                                               
  nftables.service                     loaded    active   exited  nftables                                                                     
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon                                                  
# nullmailer.service                   not-found inactive dead    nullmailer.service                                                           
  ondemand.service                     loaded    inactive dead    Set the CPU Frequency Scaling governor                                       
  osqueryd.service                     loaded    active   running The osquery Daemon                                                           
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service                                                   
# plymouth-start.service               not-found inactive dead    plymouth-start.service                                                       
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics                                      
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility                                                  
  rescue.service                       loaded    inactive dead    Rescue Shell                                                                 
  rpc-gssd.service                     loaded    inactive dead    RPC security service for NFS client and server                               
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart                                                
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.                                      
  rpcbind.service                      loaded    inactive dead    RPC bind portmap service                                                     
  rsync.service                        loaded    inactive dead    fast remote file copy program daemon                                         
  rsyslog.service                      loaded    active   running System Logging Service                                                       
# sendmail.service                     not-found inactive dead    sendmail.service                                                             
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0                                                        
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1                                                        
# set-hostname.service                 not-found inactive dead    set-hostname.service                                                         
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service                                                           
  skydive.service                      loaded    active   running Skydive                                                                      
# slapd.service                        not-found inactive dead    slapd.service                                                                
# slim.service                         not-found inactive dead    slim.service                                                                 
  ssh.service                          loaded    active   running OpenBSD Secure Shell server                                                  
  strongswan.service                   loaded    active   running strongSwan IPsec IKEv1/IKEv2 daemon using ipsec.conf                         
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console                                        
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall                                            
  systemd-binfmt.service               loaded    inactive dead    Set Up Additional Binary Formats                                             
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device                                             
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status                                    
  systemd-hwdb-update.service          loaded    inactive dead    Rebuild Hardware Database                                                    
  systemd-initctl.service              loaded    inactive dead    /dev/initctl Compatibility Daemon                                            
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage                                          
  systemd-journald.service             loaded    active   running Journal Service                                                              
  systemd-logind.service               loaded    active   running Login Service                                                                
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk                                        
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules                                                          
  systemd-networkd-wait-online.service loaded    active   exited  Wait for Network to be Configured                                            
  systemd-networkd.service             loaded    active   running Network Service                                                              
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed                                                        
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems                                         
  systemd-resolved.service             loaded    active   running Network Name Resolution                                                      
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables                                                       
# systemd-sysusers.service             not-found inactive dead    systemd-sysusers.service                                                     
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization                                                 
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories                                             
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev                                           
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories                                        
  systemd-udev-trigger.service         loaded    active   exited  udev Coldplug all Devices                                                    
  systemd-udevd.service                loaded    active   running udev Kernel Device Manager                                                   
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service                                                  
  systemd-update-utmp-runlevel.service loaded    inactive dead    Update UTMP about System Runlevel Changes                                    
  systemd-update-utmp.service          loaded    active   exited  Update UTMP about System Boot/Shutdown                                       
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions                                                         
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service                                               
  taniumclient.service                 loaded    active   running Tanium Client                                                                
  user@1000.service                    loaded    active   running User Manager for UID 1000                                                    
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent                                      
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent                                       
  vagentx.service                      loaded    active   running service wrapper around vault agent                                           
# wdm.service                          not-found inactive dead    wdm.service                                                                  
# xdm.service                          not-found inactive dead    xdm.service                                                                  

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.

138 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State   Recv-Q  Send-Q         Local Address:Port      Peer Address:Port                                                                                  
udp   UNCONN  0       0                    0.0.0.0:47853          0.0.0.0:*      users:(("rpc.statd",pid=159939,fd=8))                                          
udp   UNCONN  0       0                11.50.212.2:50052          0.0.0.0:*      users:(("fabcon_server",pid=170472,fd=15))                                     
udp   UNCONN  0       0              127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=121375,fd=12))                                   
udp   UNCONN  0       0                    0.0.0.0:500            0.0.0.0:*      users:(("charon",pid=11979,fd=14))                                             
udp   UNCONN  0       0                  127.0.0.1:691            0.0.0.0:*      users:(("rpc.statd",pid=159939,fd=5))                                          
udp   UNCONN  0       0                    0.0.0.0:4072           0.0.0.0:*                                                                                     
udp   UNCONN  0       0                    0.0.0.0:4500           0.0.0.0:*      users:(("charon",pid=11979,fd=15))                                             
udp   UNCONN  0       0                    0.0.0.0:4789           0.0.0.0:*                                                                                     
udp   UNCONN  0       0                       [::]:64521             [::]:*      users:(("rpc.statd",pid=159939,fd=10))                                         
udp   UNCONN  0       0                          *:500                  *:*      users:(("charon",pid=11979,fd=12))                                             
udp   UNCONN  0       0                          *:4500                 *:*      users:(("charon",pid=11979,fd=13))                                             
tcp   LISTEN  0       16384              127.0.0.1:10248          0.0.0.0:*      users:(("kubelet",pid=2662,fd=15))                                             
tcp   LISTEN  0       16384              127.0.0.1:10249          0.0.0.0:*      users:(("kube-proxy",pid=179557,fd=9))                                         
tcp   LISTEN  0       3                  127.0.0.1:2601           0.0.0.0:*      users:(("zebra",pid=160649,fd=27))                                             
tcp   LISTEN  0       16384              127.0.0.1:50059          0.0.0.0:*      users:(("fabcon_server",pid=170472,fd=16))                                     
tcp   LISTEN  0       16384              127.0.0.1:9100           0.0.0.0:*      users:(("prometheus-node",pid=168304,fd=3))                                    
tcp   LISTEN  0       128                127.0.0.1:6060           0.0.0.0:*      users:(("gobgpd",pid=79339,fd=5))                                              
tcp   LISTEN  0       3                  127.0.0.1:2605           0.0.0.0:*      users:(("bgpd",pid=160654,fd=18))                                              
tcp   LISTEN  0       128                  0.0.0.0:179            0.0.0.0:*      users:(("bgpd",pid=160654,fd=22))                                              
tcp   LISTEN  0       128            127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=121375,fd=13))                                   
tcp   LISTEN  0       128                  0.0.0.0:22             0.0.0.0:*      users:(("sshd",pid=177067,fd=3))                                               
tcp   LISTEN  0       3                  127.0.0.1:2616           0.0.0.0:*      users:(("staticd",pid=160662,fd=11))                                           
tcp   LISTEN  0       128                  0.0.0.0:30041          0.0.0.0:*      users:(("rpc.statd",pid=159939,fd=9))                                          
tcp   LISTEN  0       128                  0.0.0.0:1790           0.0.0.0:*      users:(("gobgpd",pid=79339,fd=7))                                              
tcp   LISTEN  0       16384              127.0.0.1:27519          0.0.0.0:*      users:(("containerd",pid=167071,fd=14))                                        
tcp   LISTEN  0       1024             11.50.212.2:17472          0.0.0.0:*      users:(("TaniumClient",pid=23614,fd=65))                                       
tcp   LISTEN  0       1024               127.0.0.1:17473          0.0.0.0:*      users:(("TaniumClient",pid=23614,fd=68))                                       
tcp   LISTEN  0       16384              127.0.0.1:50055          0.0.0.0:*      users:(("fabcon_server",pid=170472,fd=17))                                     
tcp   LISTEN  0       16384                      *:50057                *:*      users:(("fabcon_server",pid=170472,fd=22))                                     
tcp   LISTEN  0       16384                      *:10250                *:*      users:(("kubelet",pid=2662,fd=20))                                             
tcp   LISTEN  0       128                     [::]:58253             [::]:*      users:(("rpc.statd",pid=159939,fd=11))                                         
tcp   LISTEN  0       16384                      *:10256                *:*      users:(("kube-proxy",pid=179557,fd=8))                                         
tcp   LISTEN  0       128       [::ffff:127.0.0.1]:10514                *:*      users:(("iobricksd",pid=82236,fd=128))                                         
tcp   LISTEN  0       128                     [::]:179               [::]:*      users:(("bgpd",pid=160654,fd=23))                                              
tcp   LISTEN  0       128                     [::]:22                [::]:*      users:(("sshd",pid=177067,fd=4))                                               
tcp   LISTEN  0       128                        *:50555                *:*      users:(("gobgpd",pid=79339,fd=6))                                              
tcp   LISTEN  0       128                     [::]:1790              [::]:*      users:(("gobgpd",pid=79339,fd=8))                                              
tcp   LISTEN  0       16384                      *:50051                *:*      users:(("fabcon_server",pid=170472,fd=19))                                     

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==
#	$OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/bin:/bin:/usr/sbin:/sbin

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# PasswordAuthentication.  Depending on your PAM configuration,
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#UseLogin no
#Compression delayed
#UseDNS no
#PidFile /var/run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:

#includedir /etc/sudoers.d
Defaults use_pty
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
lxd:x:104:
input:x:105:
crontab:x:106:
messagebus:x:107:
ssh:x:108:
admin:x:110:
netdev:x:111:
uuidd:x:109:
syslog:x:112:
sysop:x:1000:
nslcd:x:113:
_lldpd:x:114:
docker:x:999:
ssl-cert:x:115:
postfix:x:116:
postdrop:x:117:
tss:x:118:
frrvty:x:119:frr
frr:x:120:
vault:x:998:
prometheus:x:62700:
systemd-timesync:x:997:
libvirt:x:200:
sugroup:x:1001:
sysgt:x:1002:
no_user:x:996:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_tally2.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth  [success=2 default=ignore] pam_unix.so nullok_secure
auth  [success=1 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth  required                   pam_deny.so
auth  required                   pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900
auth  required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so remember=5
password [success=2 default=ignore] pam_unix.so obscure use_authtok try_first_pass sha512
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

session optional /usr/lib/pam_osquery.so

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows root logins except on tty\'s listed in /etc/securetty
# (Replaces the `CONSOLE\' setting from login.defs)
#
# With the default control of this module:
#   [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die]
# root will not be prompted for a password on insecure lines.
# if an invalid username is entered, a password is prompted (but login
# will eventually be rejected)
#
# You can change it to a "requisite" module if you think root may mis-type
# her login and should not be prompted for a password in that case. But
# this will leave the system as vulnerable to user enumeration attacks.
#
# You can change it to a "required" module if you think it permits to
# guess valid user names of your system (invalid user names are considered
# as possibly being root on insecure lines), but root passwords may be
# communicated over insecure lines.
auth [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die] pam_securetty.so

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_04_15_14 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group root
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "root" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/sudo <==
#%PAM-1.0

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/systemd-user <==
# This file is part of systemd.
#
# Used by systemd --user instances.

@include common-account

session  required pam_selinux.so close
session  required pam_selinux.so nottys open
session  required pam_loginuid.so
session  required pam_limits.so
@include common-session-noninteractive
session optional pam_systemd.so

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd:x:103:65534::/var/lib/lxd/:/bin/false
messagebus:x:105:107::/nonexistent:/usr/sbin/nologin
sshd:x:106:65534::/run/sshd:/usr/sbin/nologin
uuidd:x:107:109::/run/uuidd:/usr/sbin/nologin
syslog:x:109:112::/home/syslog:/usr/sbin/nologin
sysop:x:1000:1000::/home/sysop:/bin/bash
nslcd:x:104:113:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd:x:108:114::/var/run/lldpd:/usr/sbin/nologin
strongswan:x:110:65534::/var/lib/strongswan:/usr/sbin/nologin
postfix:x:111:116::/var/spool/postfix:/usr/sbin/nologin
statd:x:112:65534::/var/lib/nfs:/usr/sbin/nologin
tss:x:113:118:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:x:114:118:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:x:115:120:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:998::/home/vault:/bin/false
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:x:998:997:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt:x:1001:1002::/home/sysgt:/bin/bash
genctl:x:60000:200::/home/genctl:/usr/sbin/nologin
no_user:x:65535:996:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
mail.*				-/var/log/mail.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.28.12504.0aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        fabcon-edge-manager-cdj5n                                         2/2     Running     3 (25h ago)   25h     11.50.212.11   dal1-qz2-sr2-rk203-s20   <none>           <none>
genctl        fluentbit-logs-2j4bg                                              4/4     Running     0             25h     11.50.212.12   dal1-qz2-sr2-rk203-s20   <none>           <none>
genctl        fluentd-qradar-ds-bbrrg                                           1/1     Running     0             25h     11.50.212.10   dal1-qz2-sr2-rk203-s20   <none>           <none>
genctl        kali-etcd-cluster-9qc9rhkx55                                      3/3     Running     0             25h     11.50.212.8    dal1-qz2-sr2-rk203-s20   <none>           <none>
genctl        kali-etcd-cluster-ghjz9vtp7c                                      3/3     Running     0             25h     11.50.212.7    dal1-qz2-sr2-rk203-s20   <none>           <none>
genctl        kali-etcd-cluster-rnp89mdcq2                                      3/3     Running     0             25h     11.50.212.9    dal1-qz2-sr2-rk203-s20   <none>           <none>
genctl        kali-server-7bf7fdfc67-hzpb4                                      2/2     Running     0             25h     11.50.212.5    dal1-qz2-sr2-rk203-s20   <none>           <none>
genctl        nscon-etcd-cluster-sx68qlncdd                                     3/3     Running     0             25h     11.50.212.6    dal1-qz2-sr2-rk203-s20   <none>           <none>
kube-system   kube-proxy-dlnmb                                                  1/1     Running     0             25h     10.22.64.58    dal1-qz2-sr2-rk203-s20   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
46 profiles are loaded.
28 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /sbin/dhclient
   /usr/bin/prometheus-node-exporter
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/lib/ipsec/charon
   /usr/lib/ipsec/stroke
   /usr/sbin/canonical-livepatchd
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /usr/sbin/swanctl
   /usr/sbin/tcpdump
   cri-containerd.apparmor.d
   docker-default
   fluentbit-logs
   genctl-ingress-controller
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
18 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/hmonagent
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
51 processes have profiles defined.
35 processes are in enforce mode.
   /sbin/dhclient (1678) 
   /usr/bin/prometheus-node-exporter (168304) 
   /usr/lib/ipsec/charon (11979) 
   /usr/sbin/sshd (177067) 
   /usr/sbin/sshd//sysop (6259) 
   /usr/sbin/sshd//sysop (6273) 
   cri-containerd.apparmor.d (13497) 
   cri-containerd.apparmor.d (13564) 
   cri-containerd.apparmor.d (13586) 
   cri-containerd.apparmor.d (13622) 
   cri-containerd.apparmor.d (14308) 
   cri-containerd.apparmor.d (14329) 
   cri-containerd.apparmor.d (14410) 
   cri-containerd.apparmor.d (15968) 
   cri-containerd.apparmor.d (16055) 
   cri-containerd.apparmor.d (16075) 
   cri-containerd.apparmor.d (16109) 
   cri-containerd.apparmor.d (20030) 
   cri-containerd.apparmor.d (20109) 
   cri-containerd.apparmor.d (20180) 
   cri-containerd.apparmor.d (20217) 
   cri-containerd.apparmor.d (22822) 
   cri-containerd.apparmor.d (22912) 
   cri-containerd.apparmor.d (22943) 
   cri-containerd.apparmor.d (22979) 
   cri-containerd.apparmor.d (90425) 
   cri-containerd.apparmor.d (90506) 
   cri-containerd.apparmor.d (92365) 
   cri-containerd.apparmor.d (92407) 
   cri-containerd.apparmor.d (93787) 
   cri-containerd.apparmor.d (93812) 
   cri-containerd.apparmor.d (93854) 
   cri-containerd.apparmor.d (93996) 
   cri-containerd.apparmor.d (94109) 
   cri-containerd.apparmor.d (102310) 
16 processes are in complain mode.
   /usr/lib/frr/bgpd (160654) 
   /usr/lib/frr/staticd (160662) 
   /usr/lib/frr/watchfrr (160627) 
   /usr/lib/frr/zebra (160649) 
   /usr/local/fabcon/fabcon_server (170472) 
   /usr/local/fabcon/fabcon_server (171541) 
   /usr/local/fabcon/fabcon_server (171545) 
   /usr/local/fabcon/fabcon_server (171551) 
   /usr/local/fabcon/fabcon_server (171558) 
   /usr/local/fabcon/fabcon_server (171569) 
   /usr/local/fabcon/fabcon_server (171575) 
   /usr/local/iobricks/iobricksd (82236) 
   /usr/local/skydive/skydive (79608) 
   /usr/local/skydive/skydive (79663) 
   /usr/local/skydive/skydive (79736) 
   /usr/sbin/hmonagent (83322) 
0 processes are unconfined but have a profile defined.
'
<i>2024-12-17 17:36:56.106355</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.200027</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.200011</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.200021</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:56.200024</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.200054</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:36:56.201230</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:36:56.201390</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.201587</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.201573</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.201580</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:56.201584</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.201616</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'edge'}
<i>2024-12-17 17:36:56.201645</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.415340</td>
    <td>0.24</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.415324</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.415334</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:56.415337</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.415372</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.415397</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.415420</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.415423</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:56.457730</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.457904</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:56.651276</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/dhclient": [
            {
                "pid": "1678",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "168304",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "160654",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "160662",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "160627",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "160649",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "11979",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "170472",
                "status": "complain"
            },
            {
                "pid": "171541",
                "status": "complain"
            },
            {
                "pid": "171545",
                "status": "complain"
            },
            {
                "pid": "171551",
                "status": "complain"
            },
            {
                "pid": "171558",
                "status": "complain"
            },
            {
                "pid": "171569",
                "status": "complain"
            },
            {
                "pid": "171575",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "82236",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "79608",
                "status": "complain"
            },
            {
                "pid": "79663",
                "status": "complain"
            },
            {
                "pid": "79736",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "83322",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "177067",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "6259",
                "status": "enforce"
            },
            {
                "pid": "6273",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "13497",
                "status": "enforce"
            },
            {
                "pid": "13564",
                "status": "enforce"
            },
            {
                "pid": "13586",
                "status": "enforce"
            },
            {
                "pid": "13622",
                "status": "enforce"
            },
            {
                "pid": "14308",
                "status": "enforce"
            },
            {
                "pid": "14329",
                "status": "enforce"
            },
            {
                "pid": "14410",
                "status": "enforce"
            },
            {
                "pid": "15968",
                "status": "enforce"
            },
            {
                "pid": "16055",
                "status": "enforce"
            },
            {
                "pid": "16075",
                "status": "enforce"
            },
            {
                "pid": "16109",
                "status": "enforce"
            },
            {
                "pid": "20030",
                "status": "enforce"
            },
            {
                "pid": "20109",
                "status": "enforce"
            },
            {
                "pid": "20180",
                "status": "enforce"
            },
            {
                "pid": "20217",
                "status": "enforce"
            },
            {
                "pid": "22822",
                "status": "enforce"
            },
            {
                "pid": "22912",
                "status": "enforce"
            },
            {
                "pid": "22943",
                "status": "enforce"
            },
            {
                "pid": "22979",
                "status": "enforce"
            },
            {
                "pid": "90425",
                "status": "enforce"
            },
            {
                "pid": "90506",
                "status": "enforce"
            },
            {
                "pid": "92365",
                "status": "enforce"
            },
            {
                "pid": "92407",
                "status": "enforce"
            },
            {
                "pid": "93787",
                "status": "enforce"
            },
            {
                "pid": "93812",
                "status": "enforce"
            },
            {
                "pid": "93854",
                "status": "enforce"
            },
            {
                "pid": "93996",
                "status": "enforce"
            },
            {
                "pid": "94109",
                "status": "enforce"
            },
            {
                "pid": "102310",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:56.657244</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1636 chars]e"}}' != '{"pr[333 chars]", "/sbin/dhclient": "enforce", "/usr/bin/prom[1583 chars]e"}}'
Diff is 4795 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:56.657408</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.657579</td>
    <td>0.5</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.657568</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.657574</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:56.657577</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.657605</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:36:56.927498</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:56.927547</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:36:56.927556</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.927628</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.927668</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.927674</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:56.967261</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.967313</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:57.155210</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/dhclient": [
            {
                "pid": "1678",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "168304",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "160654",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "160662",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "160627",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "160649",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "11979",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "170472",
                "status": "complain"
            },
            {
                "pid": "171541",
                "status": "complain"
            },
            {
                "pid": "171545",
                "status": "complain"
            },
            {
                "pid": "171551",
                "status": "complain"
            },
            {
                "pid": "171558",
                "status": "complain"
            },
            {
                "pid": "171569",
                "status": "complain"
            },
            {
                "pid": "171575",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "82236",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "79608",
                "status": "complain"
            },
            {
                "pid": "79663",
                "status": "complain"
            },
            {
                "pid": "79736",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "83322",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "177067",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "6259",
                "status": "enforce"
            },
            {
                "pid": "6273",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "13497",
                "status": "enforce"
            },
            {
                "pid": "13564",
                "status": "enforce"
            },
            {
                "pid": "13586",
                "status": "enforce"
            },
            {
                "pid": "13622",
                "status": "enforce"
            },
            {
                "pid": "14308",
                "status": "enforce"
            },
            {
                "pid": "14329",
                "status": "enforce"
            },
            {
                "pid": "14410",
                "status": "enforce"
            },
            {
                "pid": "15968",
                "status": "enforce"
            },
            {
                "pid": "16055",
                "status": "enforce"
            },
            {
                "pid": "16075",
                "status": "enforce"
            },
            {
                "pid": "16109",
                "status": "enforce"
            },
            {
                "pid": "20030",
                "status": "enforce"
            },
            {
                "pid": "20109",
                "status": "enforce"
            },
            {
                "pid": "20180",
                "status": "enforce"
            },
            {
                "pid": "20217",
                "status": "enforce"
            },
            {
                "pid": "22822",
                "status": "enforce"
            },
            {
                "pid": "22912",
                "status": "enforce"
            },
            {
                "pid": "22943",
                "status": "enforce"
            },
            {
                "pid": "22979",
                "status": "enforce"
            },
            {
                "pid": "90425",
                "status": "enforce"
            },
            {
                "pid": "90506",
                "status": "enforce"
            },
            {
                "pid": "92365",
                "status": "enforce"
            },
            {
                "pid": "92407",
                "status": "enforce"
            },
            {
                "pid": "93787",
                "status": "enforce"
            },
            {
                "pid": "93812",
                "status": "enforce"
            },
            {
                "pid": "93854",
                "status": "enforce"
            },
            {
                "pid": "93996",
                "status": "enforce"
            },
            {
                "pid": "94109",
                "status": "enforce"
            },
            {
                "pid": "102310",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:57.160548</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1636 chars]e"}}' != '{"pr[333 chars]", "/sbin/dhclient": "enforce", "/usr/bin/prom[1583 chars]e"}}'
Diff is 4795 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:57.160735</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.268474</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.268459</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.268467</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:57.268470</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.268525</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:57.268551</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.324617</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:36:57.328055</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
lxd
input
crontab
messagebus
ssh
admin
netdev
uuidd
syslog
sysop
nslcd
_lldpd
docker
ssl-cert
postfix
postdrop
tss
frrvty
frr
vault
prometheus
systemd-timesync
libvirt
sugroup
sysgt
no_user
'
<i>2024-12-17 17:36:57.328332</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.328552</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.328538</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.328546</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:57.328549</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.328622</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:57.328656</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.379688</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:36:57.382095</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd::/var/lib/lxd/:/bin/false
messagebus::/nonexistent:/usr/sbin/nologin
sshd::/run/sshd:/usr/sbin/nologin
uuidd::/run/uuidd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
nslcd:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd::/var/run/lldpd:/usr/sbin/nologin
strongswan::/var/lib/strongswan:/usr/sbin/nologin
postfix::/var/spool/postfix:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
genctl::/home/genctl:/usr/sbin/nologin
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:36:57.382385</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.476081</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.476067</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.476076</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:57.476079</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.476154</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.476187</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.476203</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:36:57.476268</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.476286</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:36:57.476716</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.476731</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:36:57.476775</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.476788</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.476799</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:36:57.476854</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.476866</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.476878</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:36:57.477509</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.477524</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:36:57.477636</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.477649</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release5 : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release5
<i>2024-12-17 17:36:57.499905</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:36:57.502493</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root   0 Dec 17 17:36 cron.allow
drwxr-x--- 2 root root  60 Dec 17 17:36 cron.d
drwxr-x--- 2 root root 300 Dec 17 17:36 cron.daily
drwxr-x--- 2 root root 180 Dec 17 17:36 cron.hourly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.monthly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.weekly
-rw-r----- 1 root root 815 Dec 17 17:36 crontab
'
<i>2024-12-17 17:36:57.502534</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:36:57.505576</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.505626</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:36:57.505665</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.505869</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.505857</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.505862</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:57.505865</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.505889</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:36:57.508010</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
'
<i>2024-12-17 17:36:57.508050</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:36:57.509885</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.509957</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release5/edge : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/edge
<i>2024-12-17 17:36:57.509983</i> <b style="color:rgb(0 133 115);">[INFO]</b> shell_artifacts/cronjobs/crontab_data/release5/edge personality folder not present for comparison
<i>2024-12-17 17:36:57.510020</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.510213</td>
    <td>7.16</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.510200</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.510207</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:36:57.510210</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.510238</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:36:57.512710</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.512757</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:36:57.514086</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.514128</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:36:59.527874</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:59.527934</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:36:59.528009</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.528017</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.528023</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:02.650413</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
.
good
'
<i>2024-12-17 17:37:02.650487</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:37:02.650502</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:37:02.653198</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:02.653262</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:04.666937</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:04.667157</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.768379</td>
    <td>0.09</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.768356</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.768372</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:37:04.768376</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.768430</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.768436</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.768439</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.857383</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

{"pid":7898,"time":1734457024798,"tid":1,"msg":"Warning -- could not open /usr/share/zoneinfo. Set the NESSUS_TZ_DIR env. variable","severity":"INFO"}
Linked to: nmnode2-03-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:37:04.857568</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.944105</td>
    <td>0.02</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.944092</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.944099</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:37:04.944103</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.944146</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:04.944151</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:04.944154</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:04.968263</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:37:04.968425</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.968572</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.968560</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.968567</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:37:04.968570</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.968620</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:04.968626</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:04.968630</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:04.994339</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:37:04.994494</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.086884</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.086869</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.086877</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:37:05.086881</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.086937</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.086941</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.086945</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.092424</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:37:05.092635</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.092848</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.092835</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.092842</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:37:05.092845</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.092920</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.092927</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.092931</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.098385</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:37:05.098547</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.098728</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.098715</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.098722</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:37:05.098725</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.098788</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.098794</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.098797</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_4883/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.103624</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:37:05.103734</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.189627</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk203-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.189611</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.189620</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:29 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:47 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:08:56 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:09:59 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:37 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:07 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:59 UTC, STATUS=success)

<i>2024-12-17 17:37:05.189624</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.189656</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:37:05.192448</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.9ZQ32EVzMrHyb5y
'
<i>2024-12-17 17:37:05.192485</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.9ZQ32EVzMrHyb5y | grep "publickey ssh-rsa"
<i>2024-12-17 17:37:05.195106</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:37:05.195250</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:54.999284</td>
    <td>1.13</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:54.999272</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:54.999279</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:54.999281</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:54.999313</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.999317</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.999320</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:56.129884</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 26955 packets, 1663K bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    1908K  173M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      81M   71G KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3    1908K  173M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4      81M   71G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5      81M   72G HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 7415 packets, 445K bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     322K   19M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2     322K   19M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3      71M   94G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4      71M   94G HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      30M 3393M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      86M   24G KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3      30M 3392M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4      30M 3392M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5        0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
6      30M 3392M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 65 packets, 4680 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     515K  398M KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      783  354K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3     515K  398M KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      783  354K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     515K  399M HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     514K  398M KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      166 13280 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      166 13280 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4     515K  398M HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2     1076 62272 KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     1076 62272 HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION
# am-utils.service                     not-found inactive dead    am-utils.service
# apache2.service                      not-found inactive dead    apache2.service
  apparmor.service                     loaded    active   exited  Load AppArmor profiles
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities
# apt-daily.service                    masked    inactive dead    apt-daily.service
# atd.service                          not-found inactive dead    atd.service
  auditd.service                       loaded    active   running Security Auditing Service
  auth-rpcgss-module.service           loaded    inactive dead    Kernel Module supporting RPCSEC_GSS
# autofs.service                       not-found inactive dead    autofs.service
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats
  blk-availability.service             loaded    active   exited  Availability of block devices
# citadel.service                      not-found inactive dead    citadel.service
  cloud-config.service                 loaded    inactive dead    Cloud-init: Config Stage
  cloud-final.service                  loaded    active   exited  Cloud-init: Final Stage
  cloud-init-hotplugd.service          loaded    inactive dead    Cloud-init: Hotplug Hook
  cloud-init-local.service             loaded    active   exited  Cloud-init: Local Stage (pre-network)
  cloud-init.service                   loaded    active   exited  Cloud-init: Network Stage
  cloudnet-gobgp.service               loaded    inactive dead    gobgpd service
# connman.service                      not-found inactive dead    connman.service
  containerd.service                   loaded    active   running containerd container runtime
# courier-ldap.service                 not-found inactive dead    courier-ldap.service
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service
# courier-mta.service                  not-found inactive dead    courier-mta.service
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service
# courier-pop.service                  not-found inactive dead    courier-pop.service
  cron.service                         loaded    active   running Regular background program processing daemon
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service
  dbus.service                         loaded    active   running D-Bus System Message Bus
# display-manager.service              not-found inactive dead    display-manager.service
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon
  dmesg.service                        loaded    inactive dead    Save initial kernel messages after boot
# dovecot.service                      not-found inactive dead    dovecot.service
  dpkg-db-backup.service               loaded    inactive dead    Daily dpkg database backup service
  e2scrub_all.service                  loaded    inactive dead    Online ext4 Metadata Check for All Filesystems
  e2scrub_reap.service                 loaded    inactive dead    Remove Stale Online ext4 Metadata Check Snapshots
  emergency.service                    loaded    inactive dead    Emergency Shell
  etcd.service                         loaded    active   running etcd
# etcd2.service                        not-found inactive dead    etcd2.service
# exim4.service                        not-found inactive dead    exim4.service
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor
# fcoe.service                         not-found inactive dead    fcoe.service
  finalrd.service                      loaded    active   exited  Create final runtime dir for shutdown pivot root
  fluent-bit-ops-logs.service          loaded    inactive dead    Fluent Bit agent forwarding ops logs to remote.
  fluent-bit-qradar.service            loaded    inactive dead    Fluent Bit agent forwarding audit logs to QRadar.
  frr.service                          loaded    active   running FRRouting
  fstrim.service                       loaded    inactive dead    Discard unused blocks on filesystems from /etc/fstab
# gdm3.service                         not-found inactive dead    gdm3.service
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available
  getty@tty1.service                   loaded    active   running Getty on tty1
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes
# gssproxy.service                     not-found inactive dead    gssproxy.service
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service
# hv_kvp_daemon.service                not-found inactive dead    hv_kvp_daemon.service
  ifupdown-pre.service                 loaded    inactive dead    Helper to synchronize boot up for ifupdown
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service
  iscsid.service                       loaded    inactive dead    iSCSI initiator daemon (iscsid)
# kdm.service                          not-found inactive dead    kdm.service
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system
  kmod-static-nodes.service            loaded    active   exited  Create List of Static Device Nodes
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent
  lldpd.service                        loaded    active   running LLDP daemon
# logrotate.service                    loaded    failed   failed  Rotate log files
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon
  lvm2-monitor.service                 loaded    active   exited  Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service
# masqmail.service                     not-found inactive dead    masqmail.service
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.
  modprobe@configfs.service            loaded    inactive dead    Load Kernel Module configfs
  modprobe@drm.service                 loaded    inactive dead    Load Kernel Module drm
  modprobe@efi_pstore.service          loaded    inactive dead    Load Kernel Module efi_pstore
  modprobe@fuse.service                loaded    inactive dead    Load Kernel Module fuse
  motd-news.service                    loaded    inactive dead    Message of the Day
  mst.service                          loaded    active   exited  LSB: mst
  nessusagent.service                  loaded    active   running The Nessus Client Agent
  netplan-ovs-cleanup.service          loaded    inactive dead    OpenVSwitch configuration for cleanup
# network.service                      not-found inactive dead    network.service
  networking.service                   loaded    inactive dead    Raise network interfaces
# NetworkManager.service               not-found inactive dead    NetworkManager.service
# nfs-server.service                   not-found inactive dead    nfs-server.service
  nfs-utils.service                    loaded    inactive dead    NFS server and client services
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon
# nullmailer.service                   not-found inactive dead    nullmailer.service
  open-iscsi.service                   loaded    inactive dead    Login to default iSCSI targets
  osqueryd.service                     loaded    active   running The osquery Daemon
# ovsdb-server.service                 not-found inactive dead    ovsdb-server.service
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service
# plymouth-start.service               not-found inactive dead    plymouth-start.service
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics
# rbdmap.service                       not-found inactive dead    rbdmap.service
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility
  rescue.service                       loaded    inactive dead    Rescue Shell
  rpc-gssd.service                     loaded    inactive dead    RPC security service for NFS client and server
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.
  rpc-svcgssd.service                  loaded    inactive dead    RPC security service for NFS server
  rpcbind.service                      loaded    inactive dead    RPC bind portmap service
  rsyslog.service                      loaded    active   running System Logging Service
  secureboot-db.service                loaded    inactive dead    Secure Boot updates for DB and DBX
# sendmail.service                     not-found inactive dead    sendmail.service
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1
# set-hostname.service                 not-found inactive dead    set-hostname.service
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service
  skydive.service                      loaded    active   running Skydive
# slapd.service                        not-found inactive dead    slapd.service
# slim.service                         not-found inactive dead    slim.service
# snapd.seeded.service                 not-found inactive dead    snapd.seeded.service
  ssh.service                          loaded    active   running OpenBSD Secure Shell server
# sshd-keygen.service                  not-found inactive dead    sshd-keygen.service
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall
  systemd-binfmt.service               loaded    active   exited  Set Up Additional Binary Formats
  systemd-boot-system-token.service    loaded    inactive dead    Store a System Token in an EFI Variable
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status
# systemd-hwdb-update.service          not-found inactive dead    systemd-hwdb-update.service
  systemd-initctl.service              loaded    inactive dead    initctl Compatibility Daemon
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage
  systemd-journald.service             loaded    active   running Journal Service
  systemd-logind.service               loaded    active   running User Login Management
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules
  systemd-networkd-wait-online.service loaded    inactive dead    Wait for Network to be Configured
# systemd-networkd.service             masked    inactive dead    systemd-networkd.service
# systemd-oomd.service                 not-found inactive dead    systemd-oomd.service
  systemd-pstore.service               loaded    inactive dead    Platform Persistent Storage Archival
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems
  systemd-resolved.service             loaded    active   running Network Name Resolution
  systemd-rfkill.service               loaded    inactive dead    Load/Save RF Kill Switch Status
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables
  systemd-sysusers.service             loaded    active   exited  Create System Users
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories
  systemd-udev-trigger.service         loaded    active   exited  Coldplug All udev Devices
  systemd-udevd.service                loaded    active   running Rule-based Manager for Device Events and Files
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service
  systemd-update-utmp-runlevel.service loaded    inactive dead    Record Runlevel Change in UTMP
  systemd-update-utmp.service          loaded    active   exited  Record System Boot/Shutdown in UTMP
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service
  taniumclient.service                 loaded    active   running Tanium Client
  user-runtime-dir@1001.service        loaded    active   exited  User Runtime Directory /run/user/1001
  user@1001.service                    loaded    active   running User Manager for UID 1001
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent
  vagentx.service                      loaded    active   running service wrapper around vault agent
# wdm.service                          not-found inactive dead    wdm.service
# xdm.service                          not-found inactive dead    xdm.service

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.
162 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State  Recv-Q Send-Q      Local Address:Port  Peer Address:PortProcess                                      
udp   UNCONN 0      0                 0.0.0.0:36420      0.0.0.0:*    users:(("rpc.statd",pid=903534,fd=8))       
udp   UNCONN 0      0              11.51.18.2:50052      0.0.0.0:*    users:(("fabcon_server",pid=911711,fd=14))  
udp   UNCONN 0      0           127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=823018,fd=13))
udp   UNCONN 0      0                 0.0.0.0:111        0.0.0.0:*    users:(("systemd",pid=1,fd=100))            
udp   UNCONN 0      0               127.0.0.1:1014       0.0.0.0:*    users:(("rpc.statd",pid=903534,fd=5))       
udp   UNCONN 0      0                 0.0.0.0:4789       0.0.0.0:*                                                
udp   UNCONN 0      0                    [::]:111           [::]:*    users:(("systemd",pid=1,fd=102))            
udp   UNCONN 0      0                    [::]:19249         [::]:*    users:(("rpc.statd",pid=903534,fd=10))      
tcp   LISTEN 0      3               127.0.0.1:2616       0.0.0.0:*    users:(("staticd",pid=59657,fd=11))         
tcp   LISTEN 0      3               127.0.0.1:2605       0.0.0.0:*    users:(("bgpd",pid=59650,fd=18))            
tcp   LISTEN 0      3               127.0.0.1:2601       0.0.0.0:*    users:(("zebra",pid=59645,fd=27))           
tcp   LISTEN 0      4096        127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=823018,fd=14))
tcp   LISTEN 0      16384           127.0.0.1:10257      0.0.0.0:*    users:(("kube-controller",pid=1049957,fd=3))
tcp   LISTEN 0      16384           127.0.0.1:10259      0.0.0.0:*    users:(("kube-scheduler",pid=1049866,fd=3)) 
tcp   LISTEN 0      16384           127.0.0.1:10249      0.0.0.0:*    users:(("kube-proxy",pid=1044609,fd=9))     
tcp   LISTEN 0      16384           127.0.0.1:10248      0.0.0.0:*    users:(("kubelet",pid=1060125,fd=18))       
tcp   LISTEN 0      16384           127.0.0.1:9100       0.0.0.0:*    users:(("prometheus-node",pid=909683,fd=3)) 
tcp   LISTEN 0      1024            127.0.0.1:17473      0.0.0.0:*    users:(("TaniumClient",pid=528728,fd=67))   
tcp   LISTEN 0      16384           127.0.0.1:27519      0.0.0.0:*    users:(("containerd",pid=1033112,fd=13))    
tcp   LISTEN 0      4096              0.0.0.0:22925      0.0.0.0:*    users:(("rpc.statd",pid=903534,fd=9))       
tcp   LISTEN 0      1024           11.51.18.2:17472      0.0.0.0:*    users:(("TaniumClient",pid=528728,fd=65))   
tcp   LISTEN 0      16384           127.0.0.1:50059      0.0.0.0:*    users:(("fabcon_server",pid=911711,fd=19))  
tcp   LISTEN 0      16384           127.0.0.1:50055      0.0.0.0:*    users:(("fabcon_server",pid=911711,fd=20))  
tcp   LISTEN 0      4096              0.0.0.0:179        0.0.0.0:*    users:(("bgpd",pid=59650,fd=22))            
tcp   LISTEN 0      128               0.0.0.0:22         0.0.0.0:*    users:(("sshd",pid=917189,fd=3))            
tcp   LISTEN 0      4096              0.0.0.0:111        0.0.0.0:*    users:(("systemd",pid=1,fd=96))             
tcp   LISTEN 0      4096   [::ffff:127.0.0.1]:10514            *:*    users:(("iobricksd",pid=119986,fd=35))      
tcp   LISTEN 0      16384                   *:50051            *:*    users:(("fabcon_server",pid=911711,fd=21))  
tcp   LISTEN 0      16384                   *:50057            *:*    users:(("fabcon_server",pid=911711,fd=16))  
tcp   LISTEN 0      4096                 [::]:33285         [::]:*    users:(("rpc.statd",pid=903534,fd=11))      
tcp   LISTEN 0      16384                   *:10256            *:*    users:(("kube-proxy",pid=1044609,fd=8))     
tcp   LISTEN 0      16384                   *:10250            *:*    users:(("kubelet",pid=1060125,fd=17))       
tcp   LISTEN 0      16384                   *:6443             *:*    users:(("kube-apiserver",pid=1062585,fd=3)) 
tcp   LISTEN 0      4096                 [::]:179           [::]:*    users:(("bgpd",pid=59650,fd=23))            
tcp   LISTEN 0      128                  [::]:22            [::]:*    users:(("sshd",pid=917189,fd=4))            
tcp   LISTEN 0      4096                 [::]:111           [::]:*    users:(("systemd",pid=1,fd=101))            
tcp   LISTEN 0      16384                   *:2379             *:*    users:(("etcd",pid=1030595,fd=8))           
tcp   LISTEN 0      16384                   *:2380             *:*    users:(("etcd",pid=1030595,fd=7))           

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

Include /etc/ssh/sshd_config.d/*.conf

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)
KbdInteractiveAuthentication no

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# be allowed through the KbdInteractiveAuthentication and
# PasswordAuthentication.  Depending on your PAM configuration,
# PAM authentication via KbdInteractiveAuthentication may bypass
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
# and KbdInteractiveAuthentication to \'no\'.
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#Compression delayed
#UseDNS no
#PidFile /run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
PubkeyAuthentication yes
PubkeyAcceptedKeyTypes=+ssh-rsa
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Defaults	use_pty

# This preserves proxy settings from user environments of root
# equivalent users (group sudo)
#Defaults:%sudo env_keep += "http_proxy https_proxy ftp_proxy all_proxy no_proxy"

# This allows running arbitrary commands, but so does ALL, and it means
# different sudoers have their choice of editor respected.
#Defaults:%sudo env_keep += "EDITOR"

# Completely harmless preservation of a user preference.
#Defaults:%sudo env_keep += "GREP_COLOR"

# While you shouldn\'t normally run git as root, you need to with etckeeper
#Defaults:%sudo env_keep += "GIT_AUTHOR_* GIT_COMMITTER_*"

# Per-user preferences; root won\'t have sensible values for them.
#Defaults:%sudo env_keep += "EMAIL DEBEMAIL DEBFULLNAME"

# "sudo scp" or "sudo rsync" should be able to use your SSH agent.
#Defaults:%sudo env_keep += "SSH_AGENT_PID SSH_AUTH_SOCK"

# Ditto for GPG agent
#Defaults:%sudo env_keep += "GPG_AGENT_INFO"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "@include" directives:

@includedir /etc/sudoers.d
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
messagebus:x:104:
systemd-timesync:x:105:
input:x:106:
sgx:x:107:
kvm:x:108:
render:x:109:
lxd:x:110:
tss:x:111:
_ssh:x:112:
fwupd-refresh:x:113:
admin:x:115:
netdev:x:116:
syslog:x:114:
sysop:x:1001:
crontab:x:117:
nslcd:x:118:
tcpdump:x:119:
_lldpd:x:120:
ssl-cert:x:121:
postfix:x:122:
postdrop:x:123:
frrvty:x:124:frr
frr:x:125:
vault:x:999:
host-logging:x:60202:
prometheus:x:62700:
docker:x:1002:
libvirt:x:200:
sugroup:x:1003:
sysgt:x:1004:
no_user:x:998:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_faillock.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth required                  pam_faillock.so preauth
auth  [success=4 default=ignore] pam_unix.so nullok_secure
auth  [success=3 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth [default=die]              pam_faillock.so authfail
auth sufficient                 pam_faillock.so authsucc
auth required                   pam_deny.so
auth required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so
password [success=2 default=ignore] pam_unix.so obscure remember=5 use_authtok try_first_pass 
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
# pam_selinux.so changes the SELinux context of the used TTY and configures
# SELinux in order to transition to the user context with the next execve()
# call.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/polkit-1 <==
#%PAM-1.0

@include common-auth
@include common-account
@include common-password
session       required   pam_env.so readenv=1 user_readenv=0
session       required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-session-noninteractive

==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_14_54_16 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group wheel
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "wheel" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/su-l <==
#%PAM-1.0
auth		include		su
account		include		su
password	include		su
session		optional	pam_keyinit.so force revoke
session		include		su

==> /etc/pam.d/sudo <==
#%PAM-1.0

# Set up user limits from /etc/security/limits.conf.
session    required   pam_limits.so

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0

@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/sudo-i <==
#%PAM-1.0

# Set up user limits from /etc/security/limits.conf.
session    required   pam_limits.so

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0

@include common-auth
@include common-account
@include common-session

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin
messagebus:x:103:104::/nonexistent:/usr/sbin/nologin
systemd-timesync:x:104:105:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin
tss:x:105:111:TPM software stack,,,:/var/lib/tpm:/bin/false
sshd:x:107:65534::/run/sshd:/usr/sbin/nologin
fwupd-refresh:x:108:113:fwupd-refresh user,,,:/run/systemd:/usr/sbin/nologin
syslog:x:106:114::/home/syslog:/usr/sbin/nologin
sysop:x:1001:1001::/home/sysop:/bin/bash
nslcd:x:109:118:nslcd name service LDAP connection daemon,,,:/run/nslcd:/usr/sbin/nologin
tcpdump:x:110:119::/nonexistent:/usr/sbin/nologin
_lldpd:x:111:120::/run/lldpd:/usr/sbin/nologin
postfix:x:112:122::/var/spool/postfix:/usr/sbin/nologin
_rpc:x:113:65534::/run/rpcbind:/usr/sbin/nologin
statd:x:114:65534::/var/lib/nfs:/usr/sbin/nologin
frr:x:115:125:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:999::/home/vault:/bin/false
host-logging:x:60201:60202:Logging account:/home/host-logging:/usr/sbin/nologin
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
sysgt:x:1002:1004::/home/sysgt:/bin/bash
genctl:x:60000:200::/home/genctl:/usr/sbin/nologin
no_user:x:65535:998:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.49.14604.0
aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        fluentbit-logs-n5mlh                                              4/4     Running     0             25h     11.51.18.7     dal1-qz2-sr2-rk204-s18   <none>           <none>
genctl        fluentd-qradar-ds-vgv58                                           1/1     Running     0             25h     11.51.18.5     dal1-qz2-sr2-rk204-s18   <none>           <none>
genctl        genctl-etcd-cluster-5g6z4gtxgt                                    3/3     Running     0             25h     11.51.18.6     dal1-qz2-sr2-rk204-s18   <none>           <none>
kube-system   coredns-5756cdd955-dbx99                                          1/1     Running     0             25h     11.51.18.4     dal1-qz2-sr2-rk204-s18   <none>           <none>
kube-system   coredns-5756cdd955-vtj7n                                          1/1     Running     0             25h     11.51.18.3     dal1-qz2-sr2-rk204-s18   <none>           <none>
kube-system   kube-apiserver-dal1-qz2-sr2-rk204-s18                             1/1     Running     0             25h     10.22.64.81    dal1-qz2-sr2-rk204-s18   <none>           <none>
kube-system   kube-controller-manager-dal1-qz2-sr2-rk204-s18                    1/1     Running     1 (25h ago)   25h     10.22.64.81    dal1-qz2-sr2-rk204-s18   <none>           <none>
kube-system   kube-proxy-lvpl5                                                  1/1     Running     0             25h     10.22.64.81    dal1-qz2-sr2-rk204-s18   <none>           <none>
kube-system   kube-scheduler-dal1-qz2-sr2-rk204-s18                             1/1     Running     1 (25h ago)   25h     10.22.64.81    dal1-qz2-sr2-rk204-s18   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
45 profiles are loaded.
28 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /usr/bin/etcd
   /usr/bin/prometheus-node-exporter
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /{,usr/}sbin/dhclient
   cri-containerd.apparmor.d
   fluent-bit-logs
   fluentbit-logs
   genctl-ingress-controller
   lsb_release
   nvidia_modprobe
   nvidia_modprobe//kmod
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
   tcpdump
17 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
0 profiles are in kill mode.
0 profiles are in unconfined mode.
31 processes have profiles defined.
22 processes are in enforce mode.
   /usr/bin/etcd (1030595) 
   /usr/bin/prometheus-node-exporter (909683) 
   /usr/sbin/sshd (917189) 
   /usr/sbin/sshd (1023217) /usr/sbin/sshd//sysop
   /usr/sbin/sshd (1023229) /usr/sbin/sshd//sysop
   /usr/sbin/dhclient (3447905) /{,usr/}sbin/dhclient
   /usr/local/bin/kube-scheduler (1049866) cri-containerd.apparmor.d
   /usr/local/bin/kube-controller-manager (1049957) cri-containerd.apparmor.d
   /coredns (1059715) cri-containerd.apparmor.d
   /coredns (1060044) cri-containerd.apparmor.d
   /usr/local/bin/kube-apiserver (1062585) cri-containerd.apparmor.d
   /usr/bin/ruby (1095092) cri-containerd.apparmor.d
   /usr/bin/ruby (1095136) cri-containerd.apparmor.d
   /usr/local/bin/etcd (1096677) cri-containerd.apparmor.d
   /usr/bin/dash (1096726) cri-containerd.apparmor.d
   /usr/bin/vault (1096742) cri-containerd.apparmor.d
   /bin/etcd-sidecar-ssf (1096771) cri-containerd.apparmor.d
   /usr/bin/dash (1097764) cri-containerd.apparmor.d
   /usr/bin/vault (1097781) cri-containerd.apparmor.d
   /bin/ssf-validator-fluentbit (1097814) cri-containerd.apparmor.d
   /fluent-bit/bin/fluent-bit (1097883) cri-containerd.apparmor.d
   /synthetics/datagen (1097930) cri-containerd.apparmor.d
9 processes are in complain mode.
   /usr/lib/frr/bgpd (59650) 
   /usr/lib/frr/staticd (59657) 
   /usr/lib/frr/watchfrr (59632) 
   /usr/lib/frr/zebra (59645) 
   /usr/local/fabcon/fabcon_server (911711) 
   /usr/local/iobricks/iobricksd (119986) 
   /usr/local/skydive/skydive (118627) 
   /usr/local/skydive/skydive (118662) 
   /usr/local/skydive/skydive (118811) 
0 processes are unconfined but have a profile defined.
0 processes are in mixed mode.
0 processes are in kill mode.
'
<i>2024-12-17 17:36:56.130036</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.234953</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.234938</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.234946</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:56.234949</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.234972</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:36:56.235651</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:36:56.235690</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_master_node_releases :Verify release bundles deployed on master node</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.235768</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.235759</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.235763</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:56.235765</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.235782</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/genesis/release_bundles
<i>2024-12-17 17:36:56.237410</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)
hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)
hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)
hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)
hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)
hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)
hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)
etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)
kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)
kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)
kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)
hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)
hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)
'
<i>2024-12-17 17:36:56.237446</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.237507</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.237498</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.237502</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:56.237504</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.237523</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'master'}
<i>2024-12-17 17:36:56.237541</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.467411</td>
    <td>0.16</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.467399</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.467405</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:56.467408</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.467427</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.467442</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:56.467457</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:56.467460</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml for test validation
<i>2024-12-17 17:36:56.499909</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.499949</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:56.624465</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
	"version":	"2",
	"profiles":	{
		"/etc/hostos-monitoring/plugins.d/configuration-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/ipset-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/iptables-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/liveness":	"enforce",
		"/etc/hostos-monitoring/plugins.d/smartnic-monitoring":	"enforce",
		"/usr/bin/etcd":	"enforce",
		"/usr/bin/prometheus-node-exporter":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-client.action":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-helper":	"enforce",
		"/usr/lib/connman/scripts/dhclient-script":	"enforce",
		"/usr/sbin/dropbear":	"enforce",
		"/usr/sbin/hostos-monitoring":	"enforce",
		"/usr/sbin/sshd":	"enforce",
		"/usr/sbin/sshd//DEFAULT":	"enforce",
		"/usr/sbin/sshd//root":	"enforce",
		"/usr/sbin/sshd//sysop":	"enforce",
		"/{,usr/}sbin/dhclient":	"enforce",
		"cri-containerd.apparmor.d":	"enforce",
		"fluent-bit-logs":	"enforce",
		"fluentbit-logs":	"enforce",
		"genctl-ingress-controller":	"enforce",
		"lsb_release":	"enforce",
		"nvidia_modprobe":	"enforce",
		"nvidia_modprobe//kmod":	"enforce",
		"sysdig-agent":	"enforce",
		"sysdig-agent-kmodule":	"enforce",
		"sysdig-agent-kmodule//ln_profile":	"enforce",
		"tcpdump":	"enforce",
		"/usr/lib/frr/bgpd":	"complain",
		"/usr/lib/frr/staticd":	"complain",
		"/usr/lib/frr/watchfrr":	"complain",
		"/usr/lib/frr/zebra":	"complain",
		"/usr/local/fabcon/fabcon_server":	"complain",
		"/usr/local/iobricks/bessctl/bessctl":	"complain",
		"/usr/local/iobricks/iobricksd":	"complain",
		"/usr/local/iobricks/monitor/monitor":	"complain",
		"/usr/local/iobricks/monitor/monitor_datapath":	"complain",
		"/usr/local/iobricks/monitor/monitor_fmt":	"complain",
		"/usr/local/iobricks/monitor/monitor_vpe_enable":	"complain",
		"/usr/local/skydive/skydive":	"complain",
		"/usr/sbin/mlx-setup.sh":	"complain",
		"confined_user":	"complain",
		"docker-extended":	"complain",
		"fluentd-logs":	"complain",
		"fluentd-qradar":	"complain"
	},
	"processes":	{
		"/bin/etcd-sidecar-ssf":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1096771",
				"status":	"enforce"
			}],
		"/bin/ssf-validator-fluentbit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097814",
				"status":	"enforce"
			}],
		"/coredns":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1059715",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1060044",
				"status":	"enforce"
			}],
		"/fluent-bit/bin/fluent-bit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097883",
				"status":	"enforce"
			}],
		"/synthetics/datagen":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097930",
				"status":	"enforce"
			}],
		"/usr/bin/dash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1096726",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097764",
				"status":	"enforce"
			}],
		"/usr/bin/etcd":	[{
				"profile":	"/usr/bin/etcd",
				"pid":	"1030595",
				"status":	"enforce"
			}],
		"/usr/bin/prometheus-node-exporter":	[{
				"profile":	"/usr/bin/prometheus-node-exporter",
				"pid":	"909683",
				"status":	"enforce"
			}],
		"/usr/bin/ruby":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1095092",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1095136",
				"status":	"enforce"
			}],
		"/usr/bin/vault":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1096742",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097781",
				"status":	"enforce"
			}],
		"/usr/local/bin/etcd":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1096677",
				"status":	"enforce"
			}],
		"/usr/local/bin/kube-apiserver":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1062585",
				"status":	"enforce"
			}],
		"/usr/local/bin/kube-controller-manager":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1049957",
				"status":	"enforce"
			}],
		"/usr/local/bin/kube-scheduler":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1049866",
				"status":	"enforce"
			}],
		"/usr/sbin/dhclient":	[{
				"profile":	"/{,usr/}sbin/dhclient",
				"pid":	"3447905",
				"status":	"enforce"
			}],
		"/usr/sbin/sshd":	[{
				"profile":	"/usr/sbin/sshd",
				"pid":	"917189",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"1023217",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"1023229",
				"status":	"enforce"
			}],
		"/usr/lib/frr/bgpd":	[{
				"profile":	"/usr/lib/frr/bgpd",
				"pid":	"59650",
				"status":	"complain"
			}],
		"/usr/lib/frr/staticd":	[{
				"profile":	"/usr/lib/frr/staticd",
				"pid":	"59657",
				"status":	"complain"
			}],
		"/usr/lib/frr/watchfrr":	[{
				"profile":	"/usr/lib/frr/watchfrr",
				"pid":	"59632",
				"status":	"complain"
			}],
		"/usr/lib/frr/zebra":	[{
				"profile":	"/usr/lib/frr/zebra",
				"pid":	"59645",
				"status":	"complain"
			}],
		"/usr/local/fabcon/fabcon_server":	[{
				"profile":	"/usr/local/fabcon/fabcon_server",
				"pid":	"911711",
				"status":	"complain"
			}],
		"/usr/local/iobricks/iobricksd":	[{
				"profile":	"/usr/local/iobricks/iobricksd",
				"pid":	"119986",
				"status":	"complain"
			}],
		"/usr/local/skydive/skydive":	[{
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"118627",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"118662",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"118811",
				"status":	"complain"
			}]
	}
}
'
<i>2024-12-17 17:36:56.630695</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 845, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 1226, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1570 chars]e"}}' != '{"pr[333 chars]", "/usr/bin/etcd": "enforce", "/usr/bin/prome[1517 chars]e"}}'
Diff is 4661 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:56.630771</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.630883</td>
    <td>0.24</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.630872</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.630878</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:56.630881</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.630902</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:36:56.704281</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:56.704302</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:36:56.704306</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.704339</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:56.704364</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:56.704369</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml for test validation
<i>2024-12-17 17:36:56.736556</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.736604</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:56.863950</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
	"version":	"2",
	"profiles":	{
		"/etc/hostos-monitoring/plugins.d/configuration-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/ipset-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/iptables-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/liveness":	"enforce",
		"/etc/hostos-monitoring/plugins.d/smartnic-monitoring":	"enforce",
		"/usr/bin/etcd":	"enforce",
		"/usr/bin/prometheus-node-exporter":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-client.action":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-helper":	"enforce",
		"/usr/lib/connman/scripts/dhclient-script":	"enforce",
		"/usr/sbin/dropbear":	"enforce",
		"/usr/sbin/hostos-monitoring":	"enforce",
		"/usr/sbin/sshd":	"enforce",
		"/usr/sbin/sshd//DEFAULT":	"enforce",
		"/usr/sbin/sshd//root":	"enforce",
		"/usr/sbin/sshd//sysop":	"enforce",
		"/{,usr/}sbin/dhclient":	"enforce",
		"cri-containerd.apparmor.d":	"enforce",
		"fluent-bit-logs":	"enforce",
		"fluentbit-logs":	"enforce",
		"genctl-ingress-controller":	"enforce",
		"lsb_release":	"enforce",
		"nvidia_modprobe":	"enforce",
		"nvidia_modprobe//kmod":	"enforce",
		"sysdig-agent":	"enforce",
		"sysdig-agent-kmodule":	"enforce",
		"sysdig-agent-kmodule//ln_profile":	"enforce",
		"tcpdump":	"enforce",
		"/usr/lib/frr/bgpd":	"complain",
		"/usr/lib/frr/staticd":	"complain",
		"/usr/lib/frr/watchfrr":	"complain",
		"/usr/lib/frr/zebra":	"complain",
		"/usr/local/fabcon/fabcon_server":	"complain",
		"/usr/local/iobricks/bessctl/bessctl":	"complain",
		"/usr/local/iobricks/iobricksd":	"complain",
		"/usr/local/iobricks/monitor/monitor":	"complain",
		"/usr/local/iobricks/monitor/monitor_datapath":	"complain",
		"/usr/local/iobricks/monitor/monitor_fmt":	"complain",
		"/usr/local/iobricks/monitor/monitor_vpe_enable":	"complain",
		"/usr/local/skydive/skydive":	"complain",
		"/usr/sbin/mlx-setup.sh":	"complain",
		"confined_user":	"complain",
		"docker-extended":	"complain",
		"fluentd-logs":	"complain",
		"fluentd-qradar":	"complain"
	},
	"processes":	{
		"/bin/etcd-sidecar-ssf":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1096771",
				"status":	"enforce"
			}],
		"/bin/ssf-validator-fluentbit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097814",
				"status":	"enforce"
			}],
		"/coredns":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1059715",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1060044",
				"status":	"enforce"
			}],
		"/fluent-bit/bin/fluent-bit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097883",
				"status":	"enforce"
			}],
		"/synthetics/datagen":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097930",
				"status":	"enforce"
			}],
		"/usr/bin/dash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1096726",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097764",
				"status":	"enforce"
			}],
		"/usr/bin/etcd":	[{
				"profile":	"/usr/bin/etcd",
				"pid":	"1030595",
				"status":	"enforce"
			}],
		"/usr/bin/prometheus-node-exporter":	[{
				"profile":	"/usr/bin/prometheus-node-exporter",
				"pid":	"909683",
				"status":	"enforce"
			}],
		"/usr/bin/ruby":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1095092",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1095136",
				"status":	"enforce"
			}],
		"/usr/bin/vault":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1096742",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1097781",
				"status":	"enforce"
			}],
		"/usr/local/bin/etcd":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1096677",
				"status":	"enforce"
			}],
		"/usr/local/bin/kube-apiserver":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1062585",
				"status":	"enforce"
			}],
		"/usr/local/bin/kube-controller-manager":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1049957",
				"status":	"enforce"
			}],
		"/usr/local/bin/kube-scheduler":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1049866",
				"status":	"enforce"
			}],
		"/usr/sbin/dhclient":	[{
				"profile":	"/{,usr/}sbin/dhclient",
				"pid":	"3447905",
				"status":	"enforce"
			}],
		"/usr/sbin/sshd":	[{
				"profile":	"/usr/sbin/sshd",
				"pid":	"917189",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"1023217",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"1023229",
				"status":	"enforce"
			}],
		"/usr/lib/frr/bgpd":	[{
				"profile":	"/usr/lib/frr/bgpd",
				"pid":	"59650",
				"status":	"complain"
			}],
		"/usr/lib/frr/staticd":	[{
				"profile":	"/usr/lib/frr/staticd",
				"pid":	"59657",
				"status":	"complain"
			}],
		"/usr/lib/frr/watchfrr":	[{
				"profile":	"/usr/lib/frr/watchfrr",
				"pid":	"59632",
				"status":	"complain"
			}],
		"/usr/lib/frr/zebra":	[{
				"profile":	"/usr/lib/frr/zebra",
				"pid":	"59645",
				"status":	"complain"
			}],
		"/usr/local/fabcon/fabcon_server":	[{
				"profile":	"/usr/local/fabcon/fabcon_server",
				"pid":	"911711",
				"status":	"complain"
			}],
		"/usr/local/iobricks/iobricksd":	[{
				"profile":	"/usr/local/iobricks/iobricksd",
				"pid":	"119986",
				"status":	"complain"
			}],
		"/usr/local/skydive/skydive":	[{
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"118627",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"118662",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"118811",
				"status":	"complain"
			}]
	}
}
'
<i>2024-12-17 17:36:56.869365</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 845, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 1226, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1570 chars]e"}}' != '{"pr[333 chars]", "/usr/bin/etcd": "enforce", "/usr/bin/prome[1517 chars]e"}}'
Diff is 4661 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:56.869438</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.982704</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.982692</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.982699</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:56.982702</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.982734</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:56.982750</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.030968</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:36:57.033339</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
messagebus
systemd-timesync
input
sgx
kvm
render
lxd
tss
_ssh
fwupd-refresh
admin
netdev
syslog
sysop
crontab
nslcd
tcpdump
_lldpd
ssl-cert
postfix
postdrop
frrvty
frr
vault
host-logging
prometheus
docker
libvirt
sugroup
sysgt
no_user
'
<i>2024-12-17 17:36:57.033402</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.033480</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.033470</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.033475</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:57.033477</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.033522</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.033539</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.079420</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:36:57.081459</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin
messagebus::/nonexistent:/usr/sbin/nologin
systemd-timesync:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
sshd::/run/sshd:/usr/sbin/nologin
fwupd-refresh:fwupd-refresh user,,,:/run/systemd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
nslcd:nslcd name service LDAP connection daemon,,,:/run/nslcd:/usr/sbin/nologin
tcpdump::/nonexistent:/usr/sbin/nologin
_lldpd::/run/lldpd:/usr/sbin/nologin
postfix::/var/spool/postfix:/usr/sbin/nologin
_rpc::/run/rpcbind:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
host-logging:Logging account:/home/host-logging:/usr/sbin/nologin
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
genctl::/home/genctl:/usr/sbin/nologin
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:36:57.081560</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.185216</td>
    <td>0.33</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.185201</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.185209</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:57.185212</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.185297</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.185350</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.185366</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:36:57.185458</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.185471</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:36:57.186254</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.186272</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:36:57.186366</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.186379</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.186394</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:36:57.186477</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.186489</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release6 : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release6
<i>2024-12-17 17:36:57.186635</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.186648</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:36:57.187596</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.187612</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:36:57.187859</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.504197</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:36:57.506576</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root    0 Dec 17 17:36 cron.allow
drwxr-x--- 2 root root   80 Dec 17 17:36 cron.d
drwxr-x--- 2 root root  260 Dec 17 17:36 cron.daily
drwxr-x--- 2 root root  180 Dec 17 17:36 cron.hourly
drwxr-x--- 2 root root   40 Dec 17 17:36 cron.monthly
drwxr-x--- 2 root root   40 Dec 17 17:36 cron.weekly
-rw-r----- 1 root root 1229 Dec 17 17:36 crontab
'
<i>2024-12-17 17:36:57.506594</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:36:57.510208</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.510222</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:36:57.510245</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:57.510386</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.510376</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.510381</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:57.510384</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.510408</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:36:57.512387</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'45 */12 * * * /opt/network/bin/cleanup_leaked_objs.sh >> /opt/network/cleanup/cleanup_leaked_objs.sh.log 2>&1
* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
* * * * * /opt/cron/sharedipcron 2>&1 | logger
'
<i>2024-12-17 17:36:57.512396</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:36:57.514112</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.514148</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release6/master : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release6/master
<i>2024-12-17 17:36:57.514174</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release6/master : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release6/master
<i>2024-12-17 17:36:57.514181</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -y --suppress-common-lines -EZbwB /tmp/crontab_data /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release6/master
<i>2024-12-17 17:36:57.516118</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger	      <
'
<i>2024-12-17 17:36:57.516200</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown
<i>2024-12-17 17:36:57.516541</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/cronjob_info/test_crontasks.py", line 140, in test_crontab_diff
    self.assertEqual(exit_code, 0, "Diffs in crontab tasks found!")
  File "/home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 226, in assertEqual
    raise e
  File "/home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
AssertionError: 1 != 0 : Diffs in crontab tasks found!
</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.516657</td>
    <td>7.3</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.516646</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.516651</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:57.516654</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.516675</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:36:57.518909</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.518922</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:36:57.519623</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.519631</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:36:59.534872</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:59.534899</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:36:59.534936</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.534940</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.534944</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:02.801590</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
.
good
'
<i>2024-12-17 17:37:02.801622</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:37:02.801630</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:37:02.803970</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:02.803987</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:04.819347</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:04.819476</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.929853</td>
    <td>0.14</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.929840</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:04.929847</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:04.929850</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.929884</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.929887</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.929890</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.067559</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

Linked to: nmnode2-03-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:37:05.067666</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.169272</td>
    <td>0.04</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.169258</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.169266</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:05.169268</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.169305</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.169308</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.169311</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.204295</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.204382</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.204493</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.204482</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.204488</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:05.204490</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.204535</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.204539</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.204543</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.235669</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.235745</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.331763</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.331749</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.331757</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:05.331759</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.331795</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.331799</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.331801</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.337859</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:37:05.337913</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.337996</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.337986</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.337991</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:05.337994</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.338022</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.338026</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.338028</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.343948</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:37:05.343995</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.344095</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.344085</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.344090</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:05.344093</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.344124</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.344127</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.344131</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014287_5242/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.349636</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:37:05.349683</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.449350</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s18 (master)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.449337</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.449344</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:28 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:01:00 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:37 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:35 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:01 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:41 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:05.449347</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.449368</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:37:05.451894</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.XXXXXXXXXScAPlj
'
<i>2024-12-17 17:37:05.451904</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.XXXXXXXXXScAPlj | grep "publickey ssh-rsa"
<i>2024-12-17 17:37:05.454086</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:37:05.454146</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:54.956668</td>
    <td>1.09</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:54.956651</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:54.956660</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:54.956664</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:54.956727</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.956733</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.956737</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:56.043120</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     549K   92M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2     166M   64G KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3     549K   92M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4     166M   64G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5     236M   92G HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    83160 5092K KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    83160 5092K KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3     165M   56G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4     235M   81G HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    5325K  575M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      39M   14G KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3    5312K  574M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4    5312K  574M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5    5312K  574M DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
6    5312K  574M DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
7        0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
8        0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0           
9        0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0           
10       0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0           
11       0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
12   5312K  574M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 2 packets, 144 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      682  345K KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      617  341K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      682  345K KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      617  341K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5      993  502K HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      175 10760 KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4      241 14496 HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2     2526  146K KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     2526  146K HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION                                                                  
  acpid.service                        loaded    inactive dead    ACPI event daemon                                                            
# am-utils.service                     not-found inactive dead    am-utils.service                                                             
# apache2.service                      not-found inactive dead    apache2.service                                                              
  apparmor.service                     loaded    active   exited  AppArmor initialization                                                      
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities                                       
# apt-daily.service                    masked    inactive dead    apt-daily.service                                                            
# atd.service                          not-found inactive dead    atd.service                                                                  
  auditd.service                       loaded    active   running Security Auditing Service                                                    
# autofs.service                       not-found inactive dead    autofs.service                                                               
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats                      
  blk-availability.service             loaded    active   exited  Availability of block devices                                                
# citadel.service                      not-found inactive dead    citadel.service                                                              
  cloudnet-gobgp.service               loaded    active   running gobgpd service                                                               
  containerd.service                   loaded    active   running containerd container runtime                                                 
# courier-ldap.service                 not-found inactive dead    courier-ldap.service                                                         
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service                                                      
# courier-mta.service                  not-found inactive dead    courier-mta.service                                                          
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service                                                      
# courier-pop.service                  not-found inactive dead    courier-pop.service                                                          
  cron.service                         loaded    active   running Regular background program processing daemon                                 
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service                                                          
  dbus.service                         loaded    active   running D-Bus System Message Bus                                                     
# display-manager.service              not-found inactive dead    display-manager.service                                                      
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon                                                   
  docker.service                       loaded    active   running Docker Application Container Engine                                          
# dovecot.service                      not-found inactive dead    dovecot.service                                                              
  ebtables.service                     loaded    active   exited  ebtables ruleset management                                                  
  emergency.service                    loaded    inactive dead    Emergency Shell                                                              
# exim4.service                        not-found inactive dead    exim4.service                                                                
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service                                    
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.      
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor                                                    
# fcoe.service                         not-found inactive dead    fcoe.service                                                                 
# firewalld.service                    not-found inactive dead    firewalld.service                                                            
  frr.service                          loaded    active   running FRRouting                                                                    
  fstrim.service                       loaded    inactive dead    Discard unused blocks                                                        
# gdm3.service                         not-found inactive dead    gdm3.service                                                                 
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available                      
  getty@tty1.service                   loaded    active   running Getty on tty1                                                                
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes                                    
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service                                                 
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service                                                          
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service                                                          
  hmonagent-mlx.service                loaded    active   running Genesis Fabric-3 Health Monitor Agent                                        
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device          
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service                                                       
# iscsi.service                        not-found inactive dead    iscsi.service                                                                
# iscsid.service                       not-found inactive dead    iscsid.service                                                               
# kdm.service                          not-found inactive dead    kdm.service                                                                  
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service                                            
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec                                            
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system                           
# keylime_agent.service                masked    inactive dead    keylime_agent.service                                                        
  kmod-static-nodes.service            loaded    active   exited  Create list of required static device nodes for the current kernel           
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service                                                   
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service                                                             
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster                                                 
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent                                           
  lldpd.service                        loaded    active   running LLDP daemon                                                                  
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service                                                      
  lvm2-lvmetad.service                 loaded    active   running LVM2 metadata daemon                                                         
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon                                                             
  lvm2-monitor.service                 loaded    active   exited  Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service                                                 
# masqmail.service                     not-found inactive dead    masqmail.service                                                             
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.                      
  motd-news.service                    loaded    inactive dead    Message of the Day                                                           
  mst.service                          loaded    active   exited  LSB: mst                                                                     
  nessusagent.service                  loaded    active   running The Nessus Client Agent                                                      
# network.service                      not-found inactive dead    network.service                                                              
  networking.service                   loaded    inactive dead    Raise network interfaces                                                     
# nfs-blkmap.service                   not-found inactive dead    nfs-blkmap.service                                                           
  nfs-config.service                   loaded    inactive dead    Preprocess NFS configuration                                                 
# nfs-server.service                   not-found inactive dead    nfs-server.service                                                           
  nfs-utils.service                    loaded    active   exited  NFS server and client services                                               
  nftables.service                     loaded    active   exited  nftables                                                                     
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon                                                  
# nullmailer.service                   not-found inactive dead    nullmailer.service                                                           
  ondemand.service                     loaded    inactive dead    Set the CPU Frequency Scaling governor                                       
  osqueryd.service                     loaded    active   running The osquery Daemon                                                           
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service                                                   
# plymouth-start.service               not-found inactive dead    plymouth-start.service                                                       
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics                                      
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility                                                  
  rescue.service                       loaded    inactive dead    Rescue Shell                                                                 
  rpc-gssd.service                     loaded    inactive dead    RPC security service for NFS client and server                               
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart                                                
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.                                      
  rpcbind.service                      loaded    inactive dead    RPC bind portmap service                                                     
  rsync.service                        loaded    inactive dead    fast remote file copy program daemon                                         
  rsyslog.service                      loaded    active   running System Logging Service                                                       
# sendmail.service                     not-found inactive dead    sendmail.service                                                             
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0                                                        
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1                                                        
# set-hostname.service                 not-found inactive dead    set-hostname.service                                                         
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service                                                           
  skydive.service                      loaded    active   running Skydive                                                                      
# slapd.service                        not-found inactive dead    slapd.service                                                                
# slim.service                         not-found inactive dead    slim.service                                                                 
  ssh.service                          loaded    active   running OpenBSD Secure Shell server                                                  
  strongswan.service                   loaded    active   running strongSwan IPsec IKEv1/IKEv2 daemon using ipsec.conf                         
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console                                        
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall                                            
  systemd-binfmt.service               loaded    inactive dead    Set Up Additional Binary Formats                                             
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device                                             
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status                                    
  systemd-hwdb-update.service          loaded    inactive dead    Rebuild Hardware Database                                                    
  systemd-initctl.service              loaded    inactive dead    /dev/initctl Compatibility Daemon                                            
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage                                          
  systemd-journald.service             loaded    active   running Journal Service                                                              
  systemd-logind.service               loaded    active   running Login Service                                                                
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk                                        
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules                                                          
  systemd-networkd-wait-online.service loaded    active   exited  Wait for Network to be Configured                                            
  systemd-networkd.service             loaded    active   running Network Service                                                              
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed                                                        
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems                                         
  systemd-resolved.service             loaded    active   running Network Name Resolution                                                      
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables                                                       
# systemd-sysusers.service             not-found inactive dead    systemd-sysusers.service                                                     
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization                                                 
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories                                             
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev                                           
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories                                        
  systemd-udev-trigger.service         loaded    active   exited  udev Coldplug all Devices                                                    
  systemd-udevd.service                loaded    active   running udev Kernel Device Manager                                                   
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service                                                  
  systemd-update-utmp-runlevel.service loaded    inactive dead    Update UTMP about System Runlevel Changes                                    
  systemd-update-utmp.service          loaded    active   exited  Update UTMP about System Boot/Shutdown                                       
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions                                                         
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service                                               
  taniumclient.service                 loaded    active   running Tanium Client                                                                
  user@1000.service                    loaded    active   running User Manager for UID 1000                                                    
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent                                      
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent                                       
  vagentx.service                      loaded    active   running service wrapper around vault agent                                           
# wdm.service                          not-found inactive dead    wdm.service                                                                  
# xdm.service                          not-found inactive dead    xdm.service                                                                  

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.

138 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State   Recv-Q  Send-Q         Local Address:Port      Peer Address:Port                                                                                  
udp   UNCONN  0       0                 11.51.20.2:50052          0.0.0.0:*      users:(("fabcon_server",pid=171045,fd=15))                                     
udp   UNCONN  0       0              127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=121965,fd=12))                                   
udp   UNCONN  0       0                    0.0.0.0:500            0.0.0.0:*      users:(("charon",pid=12012,fd=14))                                             
udp   UNCONN  0       0                  127.0.0.1:858            0.0.0.0:*      users:(("rpc.statd",pid=160530,fd=5))                                          
udp   UNCONN  0       0                    0.0.0.0:4072           0.0.0.0:*                                                                                     
udp   UNCONN  0       0                    0.0.0.0:4500           0.0.0.0:*      users:(("charon",pid=12012,fd=15))                                             
udp   UNCONN  0       0                    0.0.0.0:4789           0.0.0.0:*                                                                                     
udp   UNCONN  0       0                    0.0.0.0:17380          0.0.0.0:*      users:(("rpc.statd",pid=160530,fd=8))                                          
udp   UNCONN  0       0                          *:500                  *:*      users:(("charon",pid=12012,fd=12))                                             
udp   UNCONN  0       0                          *:4500                 *:*      users:(("charon",pid=12012,fd=13))                                             
udp   UNCONN  0       0                       [::]:29268             [::]:*      users:(("rpc.statd",pid=160530,fd=10))                                         
tcp   LISTEN  0       128                  0.0.0.0:1790           0.0.0.0:*      users:(("gobgpd",pid=79970,fd=7))                                              
tcp   LISTEN  0       16384              127.0.0.1:27519          0.0.0.0:*      users:(("containerd",pid=164123,fd=14))                                        
tcp   LISTEN  0       1024              11.51.20.2:17472          0.0.0.0:*      users:(("TaniumClient",pid=34039,fd=65))                                       
tcp   LISTEN  0       1024               127.0.0.1:17473          0.0.0.0:*      users:(("TaniumClient",pid=34039,fd=67))                                       
tcp   LISTEN  0       16384              127.0.0.1:50055          0.0.0.0:*      users:(("fabcon_server",pid=171045,fd=16))                                     
tcp   LISTEN  0       16384              127.0.0.1:10248          0.0.0.0:*      users:(("kubelet",pid=194596,fd=15))                                           
tcp   LISTEN  0       16384              127.0.0.1:10249          0.0.0.0:*      users:(("kube-proxy",pid=176938,fd=8))                                         
tcp   LISTEN  0       3                  127.0.0.1:2601           0.0.0.0:*      users:(("zebra",pid=161254,fd=26))                                             
tcp   LISTEN  0       16384              127.0.0.1:50059          0.0.0.0:*      users:(("fabcon_server",pid=171045,fd=17))                                     
tcp   LISTEN  0       16384              127.0.0.1:9100           0.0.0.0:*      users:(("prometheus-node",pid=168747,fd=3))                                    
tcp   LISTEN  0       128                127.0.0.1:6060           0.0.0.0:*      users:(("gobgpd",pid=79970,fd=5))                                              
tcp   LISTEN  0       3                  127.0.0.1:2605           0.0.0.0:*      users:(("bgpd",pid=161259,fd=18))                                              
tcp   LISTEN  0       128                  0.0.0.0:179            0.0.0.0:*      users:(("bgpd",pid=161259,fd=22))                                              
tcp   LISTEN  0       128                  0.0.0.0:17493          0.0.0.0:*      users:(("rpc.statd",pid=160530,fd=9))                                          
tcp   LISTEN  0       128            127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=121965,fd=13))                                   
tcp   LISTEN  0       128                  0.0.0.0:22             0.0.0.0:*      users:(("sshd",pid=177102,fd=3))                                               
tcp   LISTEN  0       3                  127.0.0.1:2616           0.0.0.0:*      users:(("staticd",pid=161266,fd=11))                                           
tcp   LISTEN  0       128                     [::]:1790              [::]:*      users:(("gobgpd",pid=79970,fd=8))                                              
tcp   LISTEN  0       128                     [::]:14529             [::]:*      users:(("rpc.statd",pid=160530,fd=11))                                         
tcp   LISTEN  0       16384                      *:50051                *:*      users:(("fabcon_server",pid=171045,fd=20))                                     
tcp   LISTEN  0       16384                      *:50057                *:*      users:(("fabcon_server",pid=171045,fd=22))                                     
tcp   LISTEN  0       16384                      *:10250                *:*      users:(("kubelet",pid=194596,fd=16))                                           
tcp   LISTEN  0       16384                      *:10256                *:*      users:(("kube-proxy",pid=176938,fd=18))                                        
tcp   LISTEN  0       128       [::ffff:127.0.0.1]:10514                *:*      users:(("iobricksd",pid=82789,fd=128))                                         
tcp   LISTEN  0       128                     [::]:179               [::]:*      users:(("bgpd",pid=161259,fd=23))                                              
tcp   LISTEN  0       128                     [::]:22                [::]:*      users:(("sshd",pid=177102,fd=4))                                               
tcp   LISTEN  0       128                        *:50555                *:*      users:(("gobgpd",pid=79970,fd=6))                                              

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==
#	$OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/bin:/bin:/usr/sbin:/sbin

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# PasswordAuthentication.  Depending on your PAM configuration,
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#UseLogin no
#Compression delayed
#UseDNS no
#PidFile /var/run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:

#includedir /etc/sudoers.d
Defaults use_pty
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
lxd:x:104:
input:x:105:
crontab:x:106:
messagebus:x:107:
ssh:x:108:
admin:x:110:
netdev:x:111:
uuidd:x:109:
syslog:x:112:
sysop:x:1000:
nslcd:x:113:
_lldpd:x:114:
docker:x:999:
ssl-cert:x:115:
postfix:x:116:
postdrop:x:117:
tss:x:118:
frrvty:x:119:frr
frr:x:120:
vault:x:998:
prometheus:x:62700:
systemd-timesync:x:997:
libvirt:x:200:
sugroup:x:1001:
sysgt:x:1002:
no_user:x:996:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_tally2.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth  [success=2 default=ignore] pam_unix.so nullok_secure
auth  [success=1 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth  required                   pam_deny.so
auth  required                   pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900
auth  required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so remember=5
password [success=2 default=ignore] pam_unix.so obscure use_authtok try_first_pass sha512
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

session optional /usr/lib/pam_osquery.so

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows root logins except on tty\'s listed in /etc/securetty
# (Replaces the `CONSOLE\' setting from login.defs)
#
# With the default control of this module:
#   [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die]
# root will not be prompted for a password on insecure lines.
# if an invalid username is entered, a password is prompted (but login
# will eventually be rejected)
#
# You can change it to a "requisite" module if you think root may mis-type
# her login and should not be prompted for a password in that case. But
# this will leave the system as vulnerable to user enumeration attacks.
#
# You can change it to a "required" module if you think it permits to
# guess valid user names of your system (invalid user names are considered
# as possibly being root on insecure lines), but root passwords may be
# communicated over insecure lines.
auth [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die] pam_securetty.so

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_04_15_00 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group root
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "root" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/sudo <==
#%PAM-1.0

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/systemd-user <==
# This file is part of systemd.
#
# Used by systemd --user instances.

@include common-account

session  required pam_selinux.so close
session  required pam_selinux.so nottys open
session  required pam_loginuid.so
session  required pam_limits.so
@include common-session-noninteractive
session optional pam_systemd.so

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd:x:103:65534::/var/lib/lxd/:/bin/false
messagebus:x:105:107::/nonexistent:/usr/sbin/nologin
sshd:x:106:65534::/run/sshd:/usr/sbin/nologin
uuidd:x:107:109::/run/uuidd:/usr/sbin/nologin
syslog:x:109:112::/home/syslog:/usr/sbin/nologin
sysop:x:1000:1000::/home/sysop:/bin/bash
nslcd:x:104:113:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd:x:108:114::/var/run/lldpd:/usr/sbin/nologin
strongswan:x:110:65534::/var/lib/strongswan:/usr/sbin/nologin
postfix:x:111:116::/var/spool/postfix:/usr/sbin/nologin
statd:x:112:65534::/var/lib/nfs:/usr/sbin/nologin
tss:x:113:118:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:x:114:118:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:x:115:120:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:998::/home/vault:/bin/false
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:x:998:997:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt:x:1001:1002::/home/sysgt:/bin/bash
genctl:x:60000:200::/home/genctl:/usr/sbin/nologin
no_user:x:65535:996:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
mail.*				-/var/log/mail.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.28.12504.0aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        fabcon-edge-manager-674n8                                         2/2     Running     3 (25h ago)   25h     11.51.20.10    dal1-qz2-sr2-rk204-s20   <none>           <none>
genctl        fluentbit-logs-tsq6c                                              4/4     Running     0             25h     11.51.20.11    dal1-qz2-sr2-rk204-s20   <none>           <none>
genctl        fluentd-qradar-ds-g2tts                                           1/1     Running     0             25h     11.51.20.9     dal1-qz2-sr2-rk204-s20   <none>           <none>
genctl        kali-etcd-cluster-425l8m5ms7                                      3/3     Running     0             25h     11.51.20.5     dal1-qz2-sr2-rk204-s20   <none>           <none>
genctl        kali-etcd-cluster-92jj7hx8jc                                      3/3     Running     0             25h     11.51.20.8     dal1-qz2-sr2-rk204-s20   <none>           <none>
genctl        nscon-etcd-cluster-kw4mkmql2q                                     3/3     Running     0             25h     11.51.20.7     dal1-qz2-sr2-rk204-s20   <none>           <none>
genctl        nscon-etcd-cluster-q4jrcz4h5k                                     3/3     Running     0             25h     11.51.20.6     dal1-qz2-sr2-rk204-s20   <none>           <none>
genctl        nscon-server-57f9785dbc-k4bz2                                     2/2     Running     0             25h     11.51.20.4     dal1-qz2-sr2-rk204-s20   <none>           <none>
kube-system   kube-proxy-lgrmp                                                  1/1     Running     0             25h     10.22.64.82    dal1-qz2-sr2-rk204-s20   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
46 profiles are loaded.
28 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /sbin/dhclient
   /usr/bin/prometheus-node-exporter
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/lib/ipsec/charon
   /usr/lib/ipsec/stroke
   /usr/sbin/canonical-livepatchd
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /usr/sbin/swanctl
   /usr/sbin/tcpdump
   cri-containerd.apparmor.d
   docker-default
   fluentbit-logs
   genctl-ingress-controller
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
18 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/hmonagent
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
51 processes have profiles defined.
35 processes are in enforce mode.
   /sbin/dhclient (4737) 
   /usr/bin/prometheus-node-exporter (168747) 
   /usr/lib/ipsec/charon (12012) 
   /usr/sbin/sshd (177102) 
   /usr/sbin/sshd//sysop (196457) 
   /usr/sbin/sshd//sysop (196471) 
   cri-containerd.apparmor.d (10528) 
   cri-containerd.apparmor.d (10554) 
   cri-containerd.apparmor.d (10692) 
   cri-containerd.apparmor.d (11006) 
   cri-containerd.apparmor.d (11072) 
   cri-containerd.apparmor.d (11114) 
   cri-containerd.apparmor.d (11148) 
   cri-containerd.apparmor.d (11814) 
   cri-containerd.apparmor.d (11885) 
   cri-containerd.apparmor.d (11926) 
   cri-containerd.apparmor.d (11963) 
   cri-containerd.apparmor.d (14123) 
   cri-containerd.apparmor.d (14196) 
   cri-containerd.apparmor.d (14217) 
   cri-containerd.apparmor.d (14256) 
   cri-containerd.apparmor.d (15358) 
   cri-containerd.apparmor.d (15438) 
   cri-containerd.apparmor.d (15481) 
   cri-containerd.apparmor.d (15519) 
   cri-containerd.apparmor.d (105463) 
   cri-containerd.apparmor.d (105609) 
   cri-containerd.apparmor.d (107465) 
   cri-containerd.apparmor.d (107519) 
   cri-containerd.apparmor.d (108999) 
   cri-containerd.apparmor.d (109023) 
   cri-containerd.apparmor.d (109096) 
   cri-containerd.apparmor.d (109251) 
   cri-containerd.apparmor.d (109362) 
   cri-containerd.apparmor.d (117486) 
16 processes are in complain mode.
   /usr/lib/frr/bgpd (161259) 
   /usr/lib/frr/staticd (161266) 
   /usr/lib/frr/watchfrr (161239) 
   /usr/lib/frr/zebra (161254) 
   /usr/local/fabcon/fabcon_server (171045) 
   /usr/local/fabcon/fabcon_server (171948) 
   /usr/local/fabcon/fabcon_server (171953) 
   /usr/local/fabcon/fabcon_server (171958) 
   /usr/local/fabcon/fabcon_server (171962) 
   /usr/local/fabcon/fabcon_server (171966) 
   /usr/local/fabcon/fabcon_server (171971) 
   /usr/local/iobricks/iobricksd (82789) 
   /usr/local/skydive/skydive (80240) 
   /usr/local/skydive/skydive (80296) 
   /usr/local/skydive/skydive (80373) 
   /usr/sbin/hmonagent (84151) 
0 processes are unconfined but have a profile defined.
'
<i>2024-12-17 17:36:56.043388</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.131560</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.131544</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.131553</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:56.131557</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.131591</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:36:56.132999</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:36:56.133169</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.133405</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.133393</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.133398</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:56.133402</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.133437</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'edge'}
<i>2024-12-17 17:36:56.133463</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.326798</td>
    <td>0.24</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.326786</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.326793</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:56.326796</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.326822</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.326842</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.326866</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.326869</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:56.365978</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.366127</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:56.557844</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/dhclient": [
            {
                "pid": "4737",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "168747",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "161259",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "161266",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "161239",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "161254",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "12012",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "171045",
                "status": "complain"
            },
            {
                "pid": "171948",
                "status": "complain"
            },
            {
                "pid": "171953",
                "status": "complain"
            },
            {
                "pid": "171958",
                "status": "complain"
            },
            {
                "pid": "171962",
                "status": "complain"
            },
            {
                "pid": "171966",
                "status": "complain"
            },
            {
                "pid": "171971",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "82789",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "80240",
                "status": "complain"
            },
            {
                "pid": "80296",
                "status": "complain"
            },
            {
                "pid": "80373",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "84151",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "177102",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "196457",
                "status": "enforce"
            },
            {
                "pid": "196471",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "10528",
                "status": "enforce"
            },
            {
                "pid": "10554",
                "status": "enforce"
            },
            {
                "pid": "10692",
                "status": "enforce"
            },
            {
                "pid": "11006",
                "status": "enforce"
            },
            {
                "pid": "11072",
                "status": "enforce"
            },
            {
                "pid": "11114",
                "status": "enforce"
            },
            {
                "pid": "11148",
                "status": "enforce"
            },
            {
                "pid": "11814",
                "status": "enforce"
            },
            {
                "pid": "11885",
                "status": "enforce"
            },
            {
                "pid": "11926",
                "status": "enforce"
            },
            {
                "pid": "11963",
                "status": "enforce"
            },
            {
                "pid": "14123",
                "status": "enforce"
            },
            {
                "pid": "14196",
                "status": "enforce"
            },
            {
                "pid": "14217",
                "status": "enforce"
            },
            {
                "pid": "14256",
                "status": "enforce"
            },
            {
                "pid": "15358",
                "status": "enforce"
            },
            {
                "pid": "15438",
                "status": "enforce"
            },
            {
                "pid": "15481",
                "status": "enforce"
            },
            {
                "pid": "15519",
                "status": "enforce"
            },
            {
                "pid": "105463",
                "status": "enforce"
            },
            {
                "pid": "105609",
                "status": "enforce"
            },
            {
                "pid": "107465",
                "status": "enforce"
            },
            {
                "pid": "107519",
                "status": "enforce"
            },
            {
                "pid": "108999",
                "status": "enforce"
            },
            {
                "pid": "109023",
                "status": "enforce"
            },
            {
                "pid": "109096",
                "status": "enforce"
            },
            {
                "pid": "109251",
                "status": "enforce"
            },
            {
                "pid": "109362",
                "status": "enforce"
            },
            {
                "pid": "117486",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:56.564275</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1636 chars]e"}}' != '{"pr[333 chars]", "/sbin/dhclient": "enforce", "/usr/bin/prom[1583 chars]e"}}'
Diff is 4795 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:56.564445</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.564594</td>
    <td>0.44</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.564584</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.564589</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:56.564592</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.564618</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:36:56.762916</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:56.762959</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:36:56.762967</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.763035</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.763075</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.763080</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:56.801448</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.801498</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:57.003433</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/dhclient": [
            {
                "pid": "4737",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "168747",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "161259",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "161266",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "161239",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "161254",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "12012",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "171045",
                "status": "complain"
            },
            {
                "pid": "171948",
                "status": "complain"
            },
            {
                "pid": "171953",
                "status": "complain"
            },
            {
                "pid": "171958",
                "status": "complain"
            },
            {
                "pid": "171962",
                "status": "complain"
            },
            {
                "pid": "171966",
                "status": "complain"
            },
            {
                "pid": "171971",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "82789",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "80240",
                "status": "complain"
            },
            {
                "pid": "80296",
                "status": "complain"
            },
            {
                "pid": "80373",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "84151",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "177102",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "196457",
                "status": "enforce"
            },
            {
                "pid": "196471",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "10528",
                "status": "enforce"
            },
            {
                "pid": "10554",
                "status": "enforce"
            },
            {
                "pid": "10692",
                "status": "enforce"
            },
            {
                "pid": "11006",
                "status": "enforce"
            },
            {
                "pid": "11072",
                "status": "enforce"
            },
            {
                "pid": "11114",
                "status": "enforce"
            },
            {
                "pid": "11148",
                "status": "enforce"
            },
            {
                "pid": "11814",
                "status": "enforce"
            },
            {
                "pid": "11885",
                "status": "enforce"
            },
            {
                "pid": "11926",
                "status": "enforce"
            },
            {
                "pid": "11963",
                "status": "enforce"
            },
            {
                "pid": "14123",
                "status": "enforce"
            },
            {
                "pid": "14196",
                "status": "enforce"
            },
            {
                "pid": "14217",
                "status": "enforce"
            },
            {
                "pid": "14256",
                "status": "enforce"
            },
            {
                "pid": "15358",
                "status": "enforce"
            },
            {
                "pid": "15438",
                "status": "enforce"
            },
            {
                "pid": "15481",
                "status": "enforce"
            },
            {
                "pid": "15519",
                "status": "enforce"
            },
            {
                "pid": "105463",
                "status": "enforce"
            },
            {
                "pid": "105609",
                "status": "enforce"
            },
            {
                "pid": "107465",
                "status": "enforce"
            },
            {
                "pid": "107519",
                "status": "enforce"
            },
            {
                "pid": "108999",
                "status": "enforce"
            },
            {
                "pid": "109023",
                "status": "enforce"
            },
            {
                "pid": "109096",
                "status": "enforce"
            },
            {
                "pid": "109251",
                "status": "enforce"
            },
            {
                "pid": "109362",
                "status": "enforce"
            },
            {
                "pid": "117486",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:57.008899</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1636 chars]e"}}' != '{"pr[333 chars]", "/sbin/dhclient": "enforce", "/usr/bin/prom[1583 chars]e"}}'
Diff is 4795 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:57.009055</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.116575</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.116561</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.116569</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:57.116572</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.116623</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:57.116649</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.171286</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:36:57.174278</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
lxd
input
crontab
messagebus
ssh
admin
netdev
uuidd
syslog
sysop
nslcd
_lldpd
docker
ssl-cert
postfix
postdrop
tss
frrvty
frr
vault
prometheus
systemd-timesync
libvirt
sugroup
sysgt
no_user
'
<i>2024-12-17 17:36:57.174566</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.174804</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.174791</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.174798</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:57.174801</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.174882</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:57.174918</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.229031</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:36:57.231770</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd::/var/lib/lxd/:/bin/false
messagebus::/nonexistent:/usr/sbin/nologin
sshd::/run/sshd:/usr/sbin/nologin
uuidd::/run/uuidd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
nslcd:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd::/var/run/lldpd:/usr/sbin/nologin
strongswan::/var/lib/strongswan:/usr/sbin/nologin
postfix::/var/spool/postfix:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
genctl::/home/genctl:/usr/sbin/nologin
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:36:57.232135</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.330998</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.330983</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.330992</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:57.330995</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.331075</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.331107</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.331125</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:36:57.331188</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.331200</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:36:57.331615</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.331631</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:36:57.331672</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.331684</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.331695</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:36:57.331751</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.331762</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.331774</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:36:57.332414</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.332430</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:36:57.332543</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.332556</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release5 : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release5
<i>2024-12-17 17:36:57.356623</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:36:57.359590</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root   0 Dec 17 17:36 cron.allow
drwxr-x--- 2 root root  60 Dec 17 17:36 cron.d
drwxr-x--- 2 root root 300 Dec 17 17:36 cron.daily
drwxr-x--- 2 root root 180 Dec 17 17:36 cron.hourly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.monthly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.weekly
-rw-r----- 1 root root 815 Dec 17 17:36 crontab
'
<i>2024-12-17 17:36:57.359634</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:36:57.362848</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.362888</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:36:57.362940</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.363217</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.363203</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.363209</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:57.363213</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.363245</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:36:57.365834</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
'
<i>2024-12-17 17:36:57.365879</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:36:57.368344</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.368436</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release5/edge : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/edge
<i>2024-12-17 17:36:57.368467</i> <b style="color:rgb(0 133 115);">[INFO]</b> shell_artifacts/cronjobs/crontab_data/release5/edge personality folder not present for comparison
<i>2024-12-17 17:36:57.368509</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.368691</td>
    <td>7.15</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.368678</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.368685</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:36:57.368688</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.368713</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:36:57.371477</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.371517</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:36:57.372610</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.372640</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:36:59.386089</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:59.386145</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:36:59.386216</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.386224</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.386231</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:02.503061</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
.
good
'
<i>2024-12-17 17:37:02.503125</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:37:02.503139</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:37:02.505738</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:02.505773</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:04.519343</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:04.519498</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:04.680701</td>
    <td>0.3</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:04.680686</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:04.680694</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:37:04.680698</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:04.680745</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.680750</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.680753</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:04.981668</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

{"pid":2791,"time":1734457024791,"tid":1,"msg":"Warning -- could not open /usr/share/zoneinfo. Set the NESSUS_TZ_DIR env. variable","severity":"INFO"}
Linked to: nmnode2-03-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:37:04.981787</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.142918</td>
    <td>0.11</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.142903</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.142912</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:37:05.142915</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.142957</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.142962</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.142964</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.251025</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.251199</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.251399</td>
    <td>0.13</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.251386</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.251393</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:37:05.251396</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.251462</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.251469</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.251472</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.385937</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.386074</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.541653</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.541638</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.541646</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:37:05.541650</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.541704</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.541708</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.541713</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.547665</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:37:05.547823</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.548027</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.548015</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.548022</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:37:05.548025</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.548112</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.548119</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.548123</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.553708</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:37:05.553860</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.554035</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.554022</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.554029</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:37:05.554032</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.554093</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.554100</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.554103</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014279_5681/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.559662</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:37:05.559796</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.727757</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s20 (edge)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.727743</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.727751</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:49:59 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:49 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:09:15 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:00 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:16 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:08 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:58 UTC, STATUS=success)

<i>2024-12-17 17:37:05.727754</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.727784</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:37:05.730338</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.2tZD6rXoMxnnLaD
'
<i>2024-12-17 17:37:05.730374</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.2tZD6rXoMxnnLaD | grep "publickey ssh-rsa"
<i>2024-12-17 17:37:05.732164</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:37:05.732275</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:54.922799</td>
    <td>1.53</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:54.922785</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:54.922793</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:54.922796</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:54.922855</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.922861</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.922865</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:56.450701</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 12 packets, 764 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     858K  109M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    9043K   12G KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3     858K  109M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4    9043K   12G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5      11M   13G HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    1113K   67M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    1113K   67M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3    9567K 1122M KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4      11M 1324M HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      53M 5809M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2     255M  115G KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3      53M 5808M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4      53M 5808M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5      53M 5808M DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
6      53M 5808M DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
7        0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
8        0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0           
9        0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0           
10       0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0           
11       0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
12     53M 5808M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 2 packets, 144 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      682  345K KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      617  341K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      682  345K KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      617  341K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5      993  502K HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     2395  176K KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4     2517  183K HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2     623K   38M KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     623K   38M HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION                                                                  
  acpid.service                        loaded    inactive dead    ACPI event daemon                                                            
# am-utils.service                     not-found inactive dead    am-utils.service                                                             
# apache2.service                      not-found inactive dead    apache2.service                                                              
  apparmor.service                     loaded    active   exited  AppArmor initialization                                                      
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities                                       
# apt-daily.service                    masked    inactive dead    apt-daily.service                                                            
# atd.service                          not-found inactive dead    atd.service                                                                  
  auditd.service                       loaded    active   running Security Auditing Service                                                    
# autofs.service                       not-found inactive dead    autofs.service                                                               
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats                      
  blk-availability.service             loaded    active   exited  Availability of block devices                                                
# citadel.service                      not-found inactive dead    citadel.service                                                              
  cloudnet-gobgp.service               loaded    inactive dead    gobgpd service                                                               
  containerd.service                   loaded    active   running containerd container runtime                                                 
# courier-ldap.service                 not-found inactive dead    courier-ldap.service                                                         
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service                                                      
# courier-mta.service                  not-found inactive dead    courier-mta.service                                                          
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service                                                      
# courier-pop.service                  not-found inactive dead    courier-pop.service                                                          
  cron.service                         loaded    active   running Regular background program processing daemon                                 
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service                                                          
  dbus.service                         loaded    active   running D-Bus System Message Bus                                                     
# display-manager.service              not-found inactive dead    display-manager.service                                                      
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon                                                   
  docker.service                       loaded    active   running Docker Application Container Engine                                          
# dovecot.service                      not-found inactive dead    dovecot.service                                                              
  ebtables.service                     loaded    active   exited  ebtables ruleset management                                                  
  emergency.service                    loaded    inactive dead    Emergency Shell                                                              
# exim4.service                        not-found inactive dead    exim4.service                                                                
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service                                    
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.      
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor                                                    
# fcoe.service                         not-found inactive dead    fcoe.service                                                                 
# firewalld.service                    not-found inactive dead    firewalld.service                                                            
  frr.service                          loaded    active   running FRRouting                                                                    
  fstrim.service                       loaded    inactive dead    Discard unused blocks                                                        
# gdm3.service                         not-found inactive dead    gdm3.service                                                                 
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available                      
  getty@tty1.service                   loaded    active   running Getty on tty1                                                                
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes                                    
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service                                                 
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service                                                          
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service                                                          
  hmonagent-mlx.service                loaded    active   running Genesis Fabric-3 Health Monitor Agent                                        
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device          
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service                                                       
# iscsi.service                        not-found inactive dead    iscsi.service                                                                
# iscsid.service                       not-found inactive dead    iscsid.service                                                               
# kdm.service                          not-found inactive dead    kdm.service                                                                  
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service                                            
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec                                            
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system                           
# keylime_agent.service                masked    inactive dead    keylime_agent.service                                                        
  kmod-static-nodes.service            loaded    active   exited  Create list of required static device nodes for the current kernel           
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service                                                   
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service                                                             
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster                                                 
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent                                           
  lldpd.service                        loaded    active   running LLDP daemon                                                                  
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service                                                      
  lvm2-lvmetad.service                 loaded    active   running LVM2 metadata daemon                                                         
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon                                                             
  lvm2-monitor.service                 loaded    active   exited  Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service                                                 
# masqmail.service                     not-found inactive dead    masqmail.service                                                             
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.                      
  motd-news.service                    loaded    inactive dead    Message of the Day                                                           
  mst.service                          loaded    active   exited  LSB: mst                                                                     
  nessusagent.service                  loaded    active   running The Nessus Client Agent                                                      
# network.service                      not-found inactive dead    network.service                                                              
  networking.service                   loaded    inactive dead    Raise network interfaces                                                     
# nfs-blkmap.service                   not-found inactive dead    nfs-blkmap.service                                                           
  nfs-config.service                   loaded    inactive dead    Preprocess NFS configuration                                                 
# nfs-server.service                   not-found inactive dead    nfs-server.service                                                           
  nfs-utils.service                    loaded    active   exited  NFS server and client services                                               
  nftables.service                     loaded    active   exited  nftables                                                                     
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon                                                  
# nullmailer.service                   not-found inactive dead    nullmailer.service                                                           
  ondemand.service                     loaded    inactive dead    Set the CPU Frequency Scaling governor                                       
  osqueryd.service                     loaded    active   running The osquery Daemon                                                           
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service                                                   
# plymouth-start.service               not-found inactive dead    plymouth-start.service                                                       
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics                                      
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility                                                  
  rescue.service                       loaded    inactive dead    Rescue Shell                                                                 
  rpc-gssd.service                     loaded    inactive dead    RPC security service for NFS client and server                               
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart                                                
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.                                      
  rpcbind.service                      loaded    inactive dead    RPC bind portmap service                                                     
  rsync.service                        loaded    inactive dead    fast remote file copy program daemon                                         
  rsyslog.service                      loaded    active   running System Logging Service                                                       
# sendmail.service                     not-found inactive dead    sendmail.service                                                             
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0                                                        
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1                                                        
# set-hostname.service                 not-found inactive dead    set-hostname.service                                                         
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service                                                           
  skydive.service                      loaded    active   running Skydive                                                                      
# slapd.service                        not-found inactive dead    slapd.service                                                                
# slim.service                         not-found inactive dead    slim.service                                                                 
  ssh.service                          loaded    active   running OpenBSD Secure Shell server                                                  
  strongswan.service                   loaded    active   running strongSwan IPsec IKEv1/IKEv2 daemon using ipsec.conf                         
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console                                        
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall                                            
  systemd-binfmt.service               loaded    inactive dead    Set Up Additional Binary Formats                                             
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device                                             
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status                                    
  systemd-hwdb-update.service          loaded    inactive dead    Rebuild Hardware Database                                                    
  systemd-initctl.service              loaded    inactive dead    /dev/initctl Compatibility Daemon                                            
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage                                          
  systemd-journald.service             loaded    active   running Journal Service                                                              
  systemd-logind.service               loaded    active   running Login Service                                                                
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk                                        
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules                                                          
  systemd-networkd-wait-online.service loaded    active   exited  Wait for Network to be Configured                                            
  systemd-networkd.service             loaded    active   running Network Service                                                              
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed                                                        
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems                                         
  systemd-resolved.service             loaded    active   running Network Name Resolution                                                      
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables                                                       
# systemd-sysusers.service             not-found inactive dead    systemd-sysusers.service                                                     
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization                                                 
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories                                             
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev                                           
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories                                        
  systemd-udev-trigger.service         loaded    active   exited  udev Coldplug all Devices                                                    
  systemd-udevd.service                loaded    active   running udev Kernel Device Manager                                                   
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service                                                  
  systemd-update-utmp-runlevel.service loaded    inactive dead    Update UTMP about System Runlevel Changes                                    
  systemd-update-utmp.service          loaded    active   exited  Update UTMP about System Boot/Shutdown                                       
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions                                                         
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service                                               
  taniumclient.service                 loaded    active   running Tanium Client                                                                
  user@1000.service                    loaded    active   running User Manager for UID 1000                                                    
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent                                      
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent                                       
  vagentx.service                      loaded    active   running service wrapper around vault agent                                           
# wdm.service                          not-found inactive dead    wdm.service                                                                  
# xdm.service                          not-found inactive dead    xdm.service                                                                  

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.

138 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State   Recv-Q  Send-Q         Local Address:Port      Peer Address:Port                                                                                  
udp   UNCONN  0       0                 11.51.28.2:50052          0.0.0.0:*      users:(("fabcon_server",pid=153935,fd=14))                                     
udp   UNCONN  0       0              127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=93359,fd=12))                                    
udp   UNCONN  0       0                    0.0.0.0:500            0.0.0.0:*      users:(("charon",pid=12056,fd=14))                                             
udp   UNCONN  0       0                  127.0.0.1:720            0.0.0.0:*      users:(("rpc.statd",pid=143856,fd=5))                                          
udp   UNCONN  0       0                    0.0.0.0:4500           0.0.0.0:*      users:(("charon",pid=12056,fd=15))                                             
udp   UNCONN  0       0                    0.0.0.0:4789           0.0.0.0:*                                                                                     
udp   UNCONN  0       0                    0.0.0.0:16575          0.0.0.0:*      users:(("rpc.statd",pid=143856,fd=8))                                          
udp   UNCONN  0       0                       [::]:55173             [::]:*      users:(("rpc.statd",pid=143856,fd=10))                                         
udp   UNCONN  0       0                          *:500                  *:*      users:(("charon",pid=12056,fd=12))                                             
udp   UNCONN  0       0                          *:4500                 *:*      users:(("charon",pid=12056,fd=13))                                             
tcp   LISTEN  0       16384              127.0.0.1:27519          0.0.0.0:*      users:(("containerd",pid=63864,fd=15))                                         
tcp   LISTEN  0       1024              11.51.28.2:17472          0.0.0.0:*      users:(("TaniumClient",pid=142987,fd=65))                                      
tcp   LISTEN  0       1024               127.0.0.1:17473          0.0.0.0:*      users:(("TaniumClient",pid=142987,fd=67))                                      
tcp   LISTEN  0       16384              127.0.0.1:50055          0.0.0.0:*      users:(("fabcon_server",pid=153935,fd=18))                                     
tcp   LISTEN  0       128                  0.0.0.0:64967          0.0.0.0:*      users:(("rpc.statd",pid=143856,fd=9))                                          
tcp   LISTEN  0       16384              127.0.0.1:10248          0.0.0.0:*      users:(("kubelet",pid=93605,fd=14))                                            
tcp   LISTEN  0       16384              127.0.0.1:10249          0.0.0.0:*      users:(("kube-proxy",pid=76283,fd=8))                                          
tcp   LISTEN  0       3                  127.0.0.1:2601           0.0.0.0:*      users:(("zebra",pid=182908,fd=27))                                             
tcp   LISTEN  0       16384              127.0.0.1:50059          0.0.0.0:*      users:(("fabcon_server",pid=153935,fd=17))                                     
tcp   LISTEN  0       16384              127.0.0.1:9100           0.0.0.0:*      users:(("prometheus-node",pid=152028,fd=3))                                    
tcp   LISTEN  0       3                  127.0.0.1:2605           0.0.0.0:*      users:(("bgpd",pid=182913,fd=18))                                              
tcp   LISTEN  0       128                  0.0.0.0:179            0.0.0.0:*      users:(("bgpd",pid=182913,fd=22))                                              
tcp   LISTEN  0       128            127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=93359,fd=13))                                    
tcp   LISTEN  0       128                  0.0.0.0:22             0.0.0.0:*      users:(("sshd",pid=159607,fd=3))                                               
tcp   LISTEN  0       3                  127.0.0.1:2616           0.0.0.0:*      users:(("staticd",pid=182921,fd=11))                                           
tcp   LISTEN  0       128                     [::]:21697             [::]:*      users:(("rpc.statd",pid=143856,fd=11))                                         
tcp   LISTEN  0       16384                      *:50051                *:*      users:(("fabcon_server",pid=153935,fd=19))                                     
tcp   LISTEN  0       16384                      *:50057                *:*      users:(("fabcon_server",pid=153935,fd=22))                                     
tcp   LISTEN  0       16384                      *:10250                *:*      users:(("kubelet",pid=93605,fd=11))                                            
tcp   LISTEN  0       16384                      *:10256                *:*      users:(("kube-proxy",pid=76283,fd=18))                                         
tcp   LISTEN  0       128       [::ffff:127.0.0.1]:10514                *:*      users:(("iobricksd",pid=57977,fd=47))                                          
tcp   LISTEN  0       128                     [::]:179               [::]:*      users:(("bgpd",pid=182913,fd=23))                                              
tcp   LISTEN  0       128                     [::]:22                [::]:*      users:(("sshd",pid=159607,fd=4))                                               

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==
#	$OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/bin:/bin:/usr/sbin:/sbin

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# PasswordAuthentication.  Depending on your PAM configuration,
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#UseLogin no
#Compression delayed
#UseDNS no
#PidFile /var/run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:

#includedir /etc/sudoers.d
Defaults use_pty
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
lxd:x:104:
input:x:105:
crontab:x:106:
messagebus:x:107:
ssh:x:108:
admin:x:110:
netdev:x:111:
uuidd:x:109:
syslog:x:112:
sysop:x:1000:
nslcd:x:113:
_lldpd:x:114:
docker:x:999:
ssl-cert:x:115:
postfix:x:116:
postdrop:x:117:
tss:x:118:
frrvty:x:119:frr
frr:x:120:
vault:x:998:
prometheus:x:62700:
systemd-timesync:x:997:
libvirt:x:200:
sugroup:x:1001:
sysgt:x:1002:
no_user:x:996:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_tally2.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth  [success=2 default=ignore] pam_unix.so nullok_secure
auth  [success=1 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth  required                   pam_deny.so
auth  required                   pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900
auth  required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so remember=5
password [success=2 default=ignore] pam_unix.so obscure use_authtok try_first_pass sha512
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

session optional /usr/lib/pam_osquery.so

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows root logins except on tty\'s listed in /etc/securetty
# (Replaces the `CONSOLE\' setting from login.defs)
#
# With the default control of this module:
#   [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die]
# root will not be prompted for a password on insecure lines.
# if an invalid username is entered, a password is prompted (but login
# will eventually be rejected)
#
# You can change it to a "requisite" module if you think root may mis-type
# her login and should not be prompted for a password in that case. But
# this will leave the system as vulnerable to user enumeration attacks.
#
# You can change it to a "required" module if you think it permits to
# guess valid user names of your system (invalid user names are considered
# as possibly being root on insecure lines), but root passwords may be
# communicated over insecure lines.
auth [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die] pam_securetty.so

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_04_15_05 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group root
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "root" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/sudo <==
#%PAM-1.0

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/systemd-user <==
# This file is part of systemd.
#
# Used by systemd --user instances.

@include common-account

session  required pam_selinux.so close
session  required pam_selinux.so nottys open
session  required pam_loginuid.so
session  required pam_limits.so
@include common-session-noninteractive
session optional pam_systemd.so

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd:x:103:65534::/var/lib/lxd/:/bin/false
messagebus:x:105:107::/nonexistent:/usr/sbin/nologin
sshd:x:106:65534::/run/sshd:/usr/sbin/nologin
uuidd:x:107:109::/run/uuidd:/usr/sbin/nologin
syslog:x:109:112::/home/syslog:/usr/sbin/nologin
sysop:x:1000:1000::/home/sysop:/bin/bash
nslcd:x:104:113:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd:x:108:114::/var/run/lldpd:/usr/sbin/nologin
strongswan:x:110:65534::/var/lib/strongswan:/usr/sbin/nologin
postfix:x:111:116::/var/spool/postfix:/usr/sbin/nologin
statd:x:112:65534::/var/lib/nfs:/usr/sbin/nologin
tss:x:113:118:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:x:114:118:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:x:115:120:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:998::/home/vault:/bin/false
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:x:998:997:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt:x:1001:1002::/home/sysgt:/bin/bash
genctl:x:60000:200::/home/genctl:/usr/sbin/nologin
no_user:x:65535:996:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
mail.*				-/var/log/mail.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.28.12504.0aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        at-log-forwarder-d774985c7-4hlkh                                  2/2     Running     0             25h     11.51.28.34    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        bm-server-controller-58b45c965-mp9qx                              2/2     Running     0             25h     11.51.28.112   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        bm-server-manager-7d46c8f749-l5lrn                                2/2     Running     2 (25h ago)   25h     11.51.28.51    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        bm-smartnic-update-check-28907592-t5cg4                           0/1     Completed   0             24m     11.51.28.197   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        bm-smartnic-update-check-28907604-74nnz                           0/1     Completed   0             12m     11.51.28.201   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        bm-smartnic-update-check-28907616-spmmv                           0/1     Completed   0             55s     11.51.28.81    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        bss-integration-server-5764c6445b-zf5q9                           2/2     Running     0             25h     11.51.28.33    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        capacity-pool-controller-6bb8fb7c57-lj2c5                         2/2     Running     2 (25h ago)   25h     11.51.28.49    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        cluster-allocation-controller-86d5b4c4ff-jlrwf                    2/2     Running     1 (25h ago)   25h     11.51.28.110   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        compute-action-controller-74d89544b7-chf2x                        2/2     Running     1 (25h ago)   25h     11.51.28.60    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        compute-deployment-orchestrator-bbbdffdc8-94ljc                   2/2     Running     1 (25h ago)   25h     11.51.28.113   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        compute-node-controller-5f6d794dc9-6j7x9                          2/2     Running     1 (25h ago)   25h     11.51.28.62    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        console-proxy-deployment-6cb7f466c8-t4m2k                         3/3     Running     2 (25h ago)   25h     11.51.28.13    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        cos-action-controller-599b9bd85f-lpbdq                            2/2     Running     0             8h      11.51.28.73    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        cos-bucket-firewall-controller-7f558999f4-qqpst                   2/2     Running     0             8h      11.51.28.96    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        dedicated-node-controller-69cdf954f5-dg9hc                        2/2     Running     1 (25h ago)   25h     11.51.28.56    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        dedicated-node-migration-controller-5f5944bd59-jtcs8              2/2     Running     1 (25h ago)   25h     11.51.28.53    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        diagnostics-rest-server-59cb8467f-2xnv8                           2/2     Running     0             25h     11.51.28.57    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        etcd-backup-operator-5dbfb9f9db-v6rnv                             2/2     Running     0             20h     11.51.28.132   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        etcd-operator-695bcfb86c-gl27k                                    2/2     Running     0             20h     11.51.28.134   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        etcd-restore-operator-557f778956-r9wdp                            2/2     Running     0             20h     11.51.28.133   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        export-policy-controller-6cb5bf758-54mhl                          2/2     Running     0             8h      11.51.28.100   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        export-policy-rule-controller-8f99869c5-rwwkt                     2/2     Running     0             8h      11.51.28.86    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fast-restore-snapshot-controller-574f848cdd-48tx9                 2/2     Running     0             8h      11.51.28.104   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        firmware-service-745f55c7-89vlw                                   2/2     Running     0             25h     11.51.28.42    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fleetman-bmmon-cf964dc98-cqvdl                                    2/2     Running     0             25h     11.51.28.47    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fleetman-etcdwatch-687677c56c-r65h6                               2/2     Running     0             25h     11.51.28.44    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fleetman-guardian-994ccc495-n47j8                                 2/2     Running     0             25h     11.51.28.45    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fleetman-metrics-f669f5f94-p7wsh                                  2/2     Running     0             25h     11.51.28.48    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fleetman-rest-server-79666b84d5-b8qq9                             2/2     Running     0             25h     11.51.28.46    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fleetman-rest-server-79666b84d5-gfcr8                             2/2     Running     0             25h     11.51.28.43    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fluentbit-log-aggregator-deploy-5b45f6c557-l2sm8                  1/1     Running     0             25h     11.51.28.31    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fluentbit-log-aggregator-deploy-5b45f6c557-mqvh5                  1/1     Running     0             25h     11.51.28.30    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fluentbit-logs-mr82p                                              4/4     Running     0             25h     11.51.28.66    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fluentd-qradar-aggregator-deploy-f844dd7c4-84ll7                  1/1     Running     0             25h     11.51.28.28    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fluentd-qradar-aggregator-deploy-f844dd7c4-szgzf                  1/1     Running     0             25h     11.51.28.27    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        fluentd-qradar-ds-5vqjp                                           1/1     Running     0             25h     11.51.28.24    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        hypersync-integration-server-667c47f9fb-8bk7h                     2/2     Running     0             25h     11.51.28.37    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        iam-rest-server-79c45f567d-ckcl4                                  2/2     Running     0             25h     11.51.28.36    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        image-volume-controller-8f5c8f6d-fg4c7                            2/2     Running     1 (25h ago)   25h     11.51.28.25    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        instance-spec-projection-controller-7bf984854d-sv7tq              3/3     Running     0             7h1m    11.51.28.7     dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        kdc-ingress-controller-7b8d9f754d-jlgmv                           1/1     Running     0             25h     11.51.28.65    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        kerberos-kdc-master-5484459f6f-mbwvg                              2/2     Running     0             25h     11.51.28.12    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        keylore-7cbff5bb95-ctv9b                                          2/2     Running     0             25h     11.51.28.9     dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        keylore-7cbff5bb95-q2z2r                                          2/2     Running     0             25h     11.51.28.8     dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        kmip-controller-1                                                 2/2     Running     0             8h      11.51.28.94    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        local-disk-controller-78474d4cdb-hbfhg                            2/2     Running     1 (25h ago)   25h     11.51.28.58    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        netapp-discover-7649d466f9-fxclv                                  2/2     Running     0             8h      11.51.28.71    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        netapp-volume-provisioner-9bb5694c-lr4nt                          2/2     Running     0             8h      11.51.28.89    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        network-manager-757658cc57-d4qp6                                  2/2     Running     3 (25h ago)   25h     11.51.28.38    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        nginx-ingress-controller-57665fdbdb-mpgmn                         3/3     Running     0             22h     11.51.28.116   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        operator-agent-59bfb8f97b-b276w                                   3/3     Running     0             25h     11.51.28.23    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-data-zonal-collector-28907550-z9b8w                           0/1     Completed   0             66m     11.51.28.191   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-data-zonal-collector-28907580-jcqdl                           0/1     Completed   0             36m     11.51.28.196   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-data-zonal-collector-28907610-2kbng                           0/1     Completed   0             6m55s   11.51.28.200   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-data-zonal-servscheduler-collector-28907565-5qgwz             0/1     Completed   0             51m     11.51.28.193   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-data-zonal-servscheduler-collector-28907595-6wcgs             0/1     Completed   0             21m     11.51.28.199   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-data-zonal-vmscheduler-collector-28907565-47cxs               0/1     Completed   0             51m     11.51.28.192   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-data-zonal-vmscheduler-collector-28907595-m62lw               0/1     Completed   0             21m     11.51.28.198   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-node-device-status-projection-controller-7f8c96cddc-89x92     2/2     Running     1 (25h ago)   25h     11.51.28.22    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-node-status-projection-controller-74974d4786-zqg49            2/2     Running     1 (25h ago)   25h     11.51.28.21    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        ops-vm-projection-controller-6dd5ffdbf4-qqh4t                     2/2     Running     2 (25h ago)   25h     11.51.28.20    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        pci-device-controller-76549ccf8-6trnm                             2/2     Running     1 (25h ago)   25h     11.51.28.59    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        placement-group-controller-5cdb7f7565-hpsbf                       2/2     Running     1 (25h ago)   25h     11.51.28.54    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        sdp-worker-6cd5db6758-v6h7n                                       2/2     Running     0             25h     11.51.28.114   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        server-node-controller-5778f7f758-dpc8m                           2/2     Running     1 (25h ago)   25h     11.51.28.61    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        share-mount-target-controller-f59fc465c-g66ts                     2/2     Running     0             8h      11.51.28.83    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        share-replica-controller-5fff8c996f-s5r8w                         2/2     Running     0             8h      11.51.28.79    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        share-replica-data-collector-854ffd999c-wrrd8                     2/2     Running     0             8h      11.51.28.93    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        share-snapshot-controller-5c986d7d47-v98vq                        2/2     Running     0             8h      11.51.28.106   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        smartnic-store-c74b4f4dc-gsxdp                                    2/2     Running     0             25h     11.51.28.39    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        snapshot-group-controller-7b868c56bc-9sh89                        2/2     Running     0             8h      11.51.28.75    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        snapshot-job-request-controller-5b8d7c697c-qskbv                  2/2     Running     0             8h      11.51.28.105   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        storage-device-chain-controller-5c869fc9f4-wj6h6                  2/2     Running     0             8h      11.51.28.82    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        storage-layer-controller-5c87d6f7d9-ft8km                         2/2     Running     0             8h      11.51.28.74    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        storage-layer-creation-controller-6c564c9fc9-jx4c4                2/2     Running     0             8h      11.51.28.80    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        storage-snapshot-controller-697d8bff77-jzmlr                      2/2     Running     0             8h      11.51.28.95    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        sysdig-customer-metrics-forwarder-7d44889db4-4fx8g                2/2     Running     0             25h     11.51.28.40    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        sysman-etcd-cluster-vwgz49j22j                                    3/3     Running     0             25h     11.51.28.32    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        virtual-disk-controller-57fd4d4b7f-f87vk                          2/2     Running     1 (25h ago)   25h     11.51.28.50    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        virtual-nic-controller-699d6cdf58-f9wwm                           2/2     Running     0             25h     11.51.28.111   dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        vm-instance-controller-787845d846-n6wn6                           2/2     Running     1 (25h ago)   25h     11.51.28.64    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        vm-migration-controller-58b7bd766-frfp8                           2/2     Running     1 (25h ago)   25h     11.51.28.52    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        vm-remediation-controller-7ffd446fb9-rc92s                        2/2     Running     1 (25h ago)   25h     11.51.28.55    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        vm-scheduler-65b757d879-l7xjw                                     2/2     Running     1 (25h ago)   25h     11.51.28.63    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        volume-controller-5dcbc7f49f-pr5sc                                2/2     Running     0             8h      11.51.28.78    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        vpc-projection-controller-745db6cb7b-mx8p2                        3/3     Running     0             7h1m    11.51.28.35    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        z-forwarder-manager-64f8556f54-xtvz6                              1/1     Running     3 (25h ago)   25h     11.51.28.14    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        zonal-image-controller-cf874c767-vjfnf                            2/2     Running     0             25h     11.51.28.26    dal1-qz2-sr2-rk204-s28   <none>           <none>
genctl        zonal-image-export-job-controller-c796dfc64-47pdj                 2/2     Running     0             25h     11.51.28.29    dal1-qz2-sr2-rk204-s28   <none>           <none>
kube-system   coredns-5756cdd955-b5gl6                                          1/1     Running     0             25h     11.51.28.4     dal1-qz2-sr2-rk204-s28   <none>           <none>
kube-system   coredns-5756cdd955-cdkwv                                          1/1     Running     0             25h     11.51.28.6     dal1-qz2-sr2-rk204-s28   <none>           <none>
kube-system   kube-proxy-4mfss                                                  1/1     Running     0             25h     10.22.64.83    dal1-qz2-sr2-rk204-s28   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
46 profiles are loaded.
28 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /sbin/dhclient
   /usr/bin/prometheus-node-exporter
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/lib/ipsec/charon
   /usr/lib/ipsec/stroke
   /usr/sbin/canonical-livepatchd
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /usr/sbin/swanctl
   /usr/sbin/tcpdump
   cri-containerd.apparmor.d
   docker-default
   fluentbit-logs
   genctl-ingress-controller
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
18 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/hmonagent
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
290 processes have profiles defined.
275 processes are in enforce mode.
   /sbin/dhclient (7678) 
   /usr/bin/prometheus-node-exporter (152028) 
   /usr/lib/ipsec/charon (12056) 
   /usr/sbin/sshd (159607) 
   /usr/sbin/sshd//sysop (55095) 
   /usr/sbin/sshd//sysop (55108) 
   cri-containerd.apparmor.d (4874) 
   cri-containerd.apparmor.d (5251) 
   cri-containerd.apparmor.d (7140) 
   cri-containerd.apparmor.d (7303) 
   cri-containerd.apparmor.d (7304) 
   cri-containerd.apparmor.d (7305) 
   cri-containerd.apparmor.d (19019) 
   cri-containerd.apparmor.d (19300) 
   cri-containerd.apparmor.d (19460) 
   cri-containerd.apparmor.d (19816) 
   cri-containerd.apparmor.d (24699) 
   cri-containerd.apparmor.d (24713) 
   cri-containerd.apparmor.d (24722) 
   cri-containerd.apparmor.d (24832) 
   cri-containerd.apparmor.d (25078) 
   cri-containerd.apparmor.d (25079) 
   cri-containerd.apparmor.d (25083) 
   cri-containerd.apparmor.d (25201) 
   cri-containerd.apparmor.d (26305) 
   cri-containerd.apparmor.d (26346) 
   cri-containerd.apparmor.d (26520) 
   cri-containerd.apparmor.d (26666) 
   cri-containerd.apparmor.d (27694) 
   cri-containerd.apparmor.d (27827) 
   cri-containerd.apparmor.d (27886) 
   cri-containerd.apparmor.d (27908) 
   cri-containerd.apparmor.d (28051) 
   cri-containerd.apparmor.d (28139) 
   cri-containerd.apparmor.d (29601) 
   cri-containerd.apparmor.d (30020) 
   cri-containerd.apparmor.d (30135) 
   cri-containerd.apparmor.d (30332) 
   cri-containerd.apparmor.d (30387) 
   cri-containerd.apparmor.d (30452) 
   cri-containerd.apparmor.d (30733) 
   cri-containerd.apparmor.d (30770) 
   cri-containerd.apparmor.d (30824) 
   cri-containerd.apparmor.d (30902) 
   cri-containerd.apparmor.d (30997) 
   cri-containerd.apparmor.d (31024) 
   cri-containerd.apparmor.d (31456) 
   cri-containerd.apparmor.d (31751) 
   cri-containerd.apparmor.d (31775) 
   cri-containerd.apparmor.d (31979) 
   cri-containerd.apparmor.d (32040) 
   cri-containerd.apparmor.d (32096) 
   cri-containerd.apparmor.d (32115) 
   cri-containerd.apparmor.d (32189) 
   cri-containerd.apparmor.d (32241) 
   cri-containerd.apparmor.d (32298) 
   cri-containerd.apparmor.d (32370) 
   cri-containerd.apparmor.d (32513) 
   cri-containerd.apparmor.d (33194) 
   cri-containerd.apparmor.d (33225) 
   cri-containerd.apparmor.d (33706) 
   cri-containerd.apparmor.d (35034) 
   cri-containerd.apparmor.d (35413) 
   cri-containerd.apparmor.d (36946) 
   cri-containerd.apparmor.d (46915) 
   cri-containerd.apparmor.d (51255) 
   cri-containerd.apparmor.d (53250) 
   cri-containerd.apparmor.d (54053) 
   cri-containerd.apparmor.d (54360) 
   cri-containerd.apparmor.d (54361) 
   cri-containerd.apparmor.d (54699) 
   cri-containerd.apparmor.d (54700) 
   cri-containerd.apparmor.d (57360) 
   cri-containerd.apparmor.d (88005) 
   cri-containerd.apparmor.d (88041) 
   cri-containerd.apparmor.d (88092) 
   cri-containerd.apparmor.d (88685) 
   cri-containerd.apparmor.d (88788) 
   cri-containerd.apparmor.d (88933) 
   cri-containerd.apparmor.d (89998) 
   cri-containerd.apparmor.d (89999) 
   cri-containerd.apparmor.d (90000) 
   cri-containerd.apparmor.d (90001) 
   cri-containerd.apparmor.d (90002) 
   cri-containerd.apparmor.d (92903) 
   cri-containerd.apparmor.d (94490) 
   cri-containerd.apparmor.d (102149) 
   cri-containerd.apparmor.d (102178) 
   cri-containerd.apparmor.d (102376) 
   cri-containerd.apparmor.d (102445) 
   cri-containerd.apparmor.d (103028) 
   cri-containerd.apparmor.d (103203) 
   cri-containerd.apparmor.d (103265) 
   cri-containerd.apparmor.d (103524) 
   cri-containerd.apparmor.d (103532) 
   cri-containerd.apparmor.d (103676) 
   cri-containerd.apparmor.d (103698) 
   cri-containerd.apparmor.d (103932) 
   cri-containerd.apparmor.d (104048) 
   cri-containerd.apparmor.d (104343) 
   cri-containerd.apparmor.d (104678) 
   cri-containerd.apparmor.d (104806) 
   cri-containerd.apparmor.d (104902) 
   cri-containerd.apparmor.d (105086) 
   cri-containerd.apparmor.d (105130) 
   cri-containerd.apparmor.d (106070) 
   cri-containerd.apparmor.d (106092) 
   cri-containerd.apparmor.d (106184) 
   cri-containerd.apparmor.d (106378) 
   cri-containerd.apparmor.d (106386) 
   cri-containerd.apparmor.d (106430) 
   cri-containerd.apparmor.d (106454) 
   cri-containerd.apparmor.d (106473) 
   cri-containerd.apparmor.d (106727) 
   cri-containerd.apparmor.d (106971) 
   cri-containerd.apparmor.d (106983) 
   cri-containerd.apparmor.d (106991) 
   cri-containerd.apparmor.d (107019) 
   cri-containerd.apparmor.d (107051) 
   cri-containerd.apparmor.d (107052) 
   cri-containerd.apparmor.d (107147) 
   cri-containerd.apparmor.d (107317) 
   cri-containerd.apparmor.d (107383) 
   cri-containerd.apparmor.d (107430) 
   cri-containerd.apparmor.d (107488) 
   cri-containerd.apparmor.d (107637) 
   cri-containerd.apparmor.d (107802) 
   cri-containerd.apparmor.d (107839) 
   cri-containerd.apparmor.d (107910) 
   cri-containerd.apparmor.d (107998) 
   cri-containerd.apparmor.d (108141) 
   cri-containerd.apparmor.d (108263) 
   cri-containerd.apparmor.d (108456) 
   cri-containerd.apparmor.d (108606) 
   cri-containerd.apparmor.d (110434) 
   cri-containerd.apparmor.d (110487) 
   cri-containerd.apparmor.d (110624) 
   cri-containerd.apparmor.d (127110) 
   cri-containerd.apparmor.d (127197) 
   cri-containerd.apparmor.d (127247) 
   cri-containerd.apparmor.d (127557) 
   cri-containerd.apparmor.d (127573) 
   cri-containerd.apparmor.d (127714) 
   cri-containerd.apparmor.d (127734) 
   cri-containerd.apparmor.d (127781) 
   cri-containerd.apparmor.d (127808) 
   cri-containerd.apparmor.d (130074) 
   cri-containerd.apparmor.d (130108) 
   cri-containerd.apparmor.d (130400) 
   cri-containerd.apparmor.d (130637) 
   cri-containerd.apparmor.d (130681) 
   cri-containerd.apparmor.d (130856) 
   cri-containerd.apparmor.d (131298) 
   cri-containerd.apparmor.d (131401) 
   cri-containerd.apparmor.d (154657) 
   cri-containerd.apparmor.d (154681) 
   cri-containerd.apparmor.d (154736) 
   cri-containerd.apparmor.d (154737) 
   cri-containerd.apparmor.d (154738) 
   cri-containerd.apparmor.d (154740) 
   cri-containerd.apparmor.d (154746) 
   cri-containerd.apparmor.d (154747) 
   cri-containerd.apparmor.d (154752) 
   cri-containerd.apparmor.d (154755) 
   cri-containerd.apparmor.d (154766) 
   cri-containerd.apparmor.d (154772) 
   cri-containerd.apparmor.d (155150) 
   cri-containerd.apparmor.d (155185) 
   cri-containerd.apparmor.d (155262) 
   cri-containerd.apparmor.d (155295) 
   cri-containerd.apparmor.d (155336) 
   cri-containerd.apparmor.d (155367) 
   cri-containerd.apparmor.d (165388) 
   cri-containerd.apparmor.d (167498) 
   cri-containerd.apparmor.d (167643) 
   cri-containerd.apparmor.d (168309) 
   cri-containerd.apparmor.d (168335) 
   cri-containerd.apparmor.d (168534) 
   cri-containerd.apparmor.d (168535) 
   cri-containerd.apparmor.d (169102) 
   cri-containerd.apparmor.d (169174) 
   cri-containerd.apparmor.d (169339) 
   cri-containerd.apparmor.d (169357) 
   cri-containerd.apparmor.d (169408) 
   cri-containerd.apparmor.d (169427) 
   cri-containerd.apparmor.d (169673) 
   cri-containerd.apparmor.d (169822) 
   cri-containerd.apparmor.d (170069) 
   cri-containerd.apparmor.d (170115) 
   cri-containerd.apparmor.d (170233) 
   cri-containerd.apparmor.d (170252) 
   cri-containerd.apparmor.d (170574) 
   cri-containerd.apparmor.d (170895) 
   cri-containerd.apparmor.d (171198) 
   cri-containerd.apparmor.d (171396) 
   cri-containerd.apparmor.d (171527) 
   cri-containerd.apparmor.d (171697) 
   cri-containerd.apparmor.d (172195) 
   cri-containerd.apparmor.d (172389) 
   cri-containerd.apparmor.d (173465) 
   cri-containerd.apparmor.d (173722) 
   cri-containerd.apparmor.d (173963) 
   cri-containerd.apparmor.d (174561) 
   cri-containerd.apparmor.d (174579) 
   cri-containerd.apparmor.d (174731) 
   cri-containerd.apparmor.d (174753) 
   cri-containerd.apparmor.d (175078) 
   cri-containerd.apparmor.d (175096) 
   cri-containerd.apparmor.d (175205) 
   cri-containerd.apparmor.d (175287) 
   cri-containerd.apparmor.d (175954) 
   cri-containerd.apparmor.d (175969) 
   cri-containerd.apparmor.d (176028) 
   cri-containerd.apparmor.d (177795) 
   cri-containerd.apparmor.d (178422) 
   cri-containerd.apparmor.d (178657) 
   cri-containerd.apparmor.d (179192) 
   cri-containerd.apparmor.d (179455) 
   cri-containerd.apparmor.d (179817) 
   cri-containerd.apparmor.d (180141) 
   cri-containerd.apparmor.d (180346) 
   cri-containerd.apparmor.d (180679) 
   cri-containerd.apparmor.d (180965) 
   cri-containerd.apparmor.d (181112) 
   cri-containerd.apparmor.d (181900) 
   cri-containerd.apparmor.d (181980) 
   cri-containerd.apparmor.d (182340) 
   cri-containerd.apparmor.d (182385) 
   cri-containerd.apparmor.d (182562) 
   cri-containerd.apparmor.d (182587) 
   cri-containerd.apparmor.d (182675) 
   cri-containerd.apparmor.d (182746) 
   cri-containerd.apparmor.d (183023) 
   cri-containerd.apparmor.d (183126) 
   cri-containerd.apparmor.d (183150) 
   cri-containerd.apparmor.d (183379) 
   cri-containerd.apparmor.d (183403) 
   cri-containerd.apparmor.d (184433) 
   cri-containerd.apparmor.d (184761) 
   cri-containerd.apparmor.d (185032) 
   cri-containerd.apparmor.d (185579) 
   cri-containerd.apparmor.d (185657) 
   cri-containerd.apparmor.d (185670) 
   cri-containerd.apparmor.d (185679) 
   cri-containerd.apparmor.d (185807) 
   cri-containerd.apparmor.d (185887) 
   cri-containerd.apparmor.d (185888) 
   cri-containerd.apparmor.d (185892) 
   cri-containerd.apparmor.d (186157) 
   cri-containerd.apparmor.d (186167) 
   cri-containerd.apparmor.d (186175) 
   cri-containerd.apparmor.d (186222) 
   cri-containerd.apparmor.d (186223) 
   cri-containerd.apparmor.d (186224) 
   cri-containerd.apparmor.d (186475) 
   cri-containerd.apparmor.d (186485) 
   cri-containerd.apparmor.d (186526) 
   cri-containerd.apparmor.d (186527) 
   cri-containerd.apparmor.d (186732) 
   cri-containerd.apparmor.d (186753) 
   cri-containerd.apparmor.d (186778) 
   cri-containerd.apparmor.d (186798) 
   cri-containerd.apparmor.d (186961) 
   cri-containerd.apparmor.d (187045) 
   cri-containerd.apparmor.d (188233) 
   cri-containerd.apparmor.d (188571) 
   cri-containerd.apparmor.d (190114) 
   cri-containerd.apparmor.d (190135) 
   cri-containerd.apparmor.d (190329) 
   cri-containerd.apparmor.d (190330) 
   cri-containerd.apparmor.d (192317) 
   cri-containerd.apparmor.d (192936) 
   cri-containerd.apparmor.d (193855) 
   cri-containerd.apparmor.d (194544) 
   cri-containerd.apparmor.d (195298) 
15 processes are in complain mode.
   /usr/lib/frr/bgpd (182913) 
   /usr/lib/frr/staticd (182921) 
   /usr/lib/frr/watchfrr (182893) 
   /usr/lib/frr/zebra (182908) 
   /usr/local/fabcon/fabcon_server (153935) 
   /usr/local/fabcon/fabcon_server (154946) 
   /usr/local/fabcon/fabcon_server (154960) 
   /usr/local/fabcon/fabcon_server (154965) 
   /usr/local/fabcon/fabcon_server (154970) 
   /usr/local/fabcon/fabcon_server (154982) 
   /usr/local/iobricks/iobricksd (57977) 
   /usr/local/skydive/skydive (55948) 
   /usr/local/skydive/skydive (55998) 
   /usr/local/skydive/skydive (56064) 
   /usr/sbin/hmonagent (59264) 
0 processes are unconfined but have a profile defined.
'
<i>2024-12-17 17:36:56.450961</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.574085</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.574070</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.574078</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:56.574082</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.574114</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:36:56.575091</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:36:56.575194</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.575361</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.575350</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.575355</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:56.575358</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.575387</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'control'}
<i>2024-12-17 17:36:56.575410</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.814964</td>
    <td>0.33</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.814950</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.814958</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:56.814961</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.814995</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.815024</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.815048</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.815052</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:56.857152</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.857323</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:57.139174</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/dhclient": [
            {
                "pid": "7678",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "152028",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "182913",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "182921",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "182893",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "182908",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "12056",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "153935",
                "status": "complain"
            },
            {
                "pid": "154946",
                "status": "complain"
            },
            {
                "pid": "154960",
                "status": "complain"
            },
            {
                "pid": "154965",
                "status": "complain"
            },
            {
                "pid": "154970",
                "status": "complain"
            },
            {
                "pid": "154982",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "57977",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "55948",
                "status": "complain"
            },
            {
                "pid": "55998",
                "status": "complain"
            },
            {
                "pid": "56064",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "59264",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "159607",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "55095",
                "status": "enforce"
            },
            {
                "pid": "55108",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "4874",
                "status": "enforce"
            },
            {
                "pid": "5251",
                "status": "enforce"
            },
            {
                "pid": "7140",
                "status": "enforce"
            },
            {
                "pid": "7303",
                "status": "enforce"
            },
            {
                "pid": "7304",
                "status": "enforce"
            },
            {
                "pid": "7305",
                "status": "enforce"
            },
            {
                "pid": "19019",
                "status": "enforce"
            },
            {
                "pid": "19300",
                "status": "enforce"
            },
            {
                "pid": "19460",
                "status": "enforce"
            },
            {
                "pid": "19816",
                "status": "enforce"
            },
            {
                "pid": "24699",
                "status": "enforce"
            },
            {
                "pid": "24713",
                "status": "enforce"
            },
            {
                "pid": "24722",
                "status": "enforce"
            },
            {
                "pid": "24832",
                "status": "enforce"
            },
            {
                "pid": "25078",
                "status": "enforce"
            },
            {
                "pid": "25079",
                "status": "enforce"
            },
            {
                "pid": "25083",
                "status": "enforce"
            },
            {
                "pid": "25201",
                "status": "enforce"
            },
            {
                "pid": "26305",
                "status": "enforce"
            },
            {
                "pid": "26346",
                "status": "enforce"
            },
            {
                "pid": "26520",
                "status": "enforce"
            },
            {
                "pid": "26666",
                "status": "enforce"
            },
            {
                "pid": "27694",
                "status": "enforce"
            },
            {
                "pid": "27827",
                "status": "enforce"
            },
            {
                "pid": "27886",
                "status": "enforce"
            },
            {
                "pid": "27908",
                "status": "enforce"
            },
            {
                "pid": "28051",
                "status": "enforce"
            },
            {
                "pid": "28139",
                "status": "enforce"
            },
            {
                "pid": "29601",
                "status": "enforce"
            },
            {
                "pid": "30020",
                "status": "enforce"
            },
            {
                "pid": "30135",
                "status": "enforce"
            },
            {
                "pid": "30332",
                "status": "enforce"
            },
            {
                "pid": "30387",
                "status": "enforce"
            },
            {
                "pid": "30452",
                "status": "enforce"
            },
            {
                "pid": "30733",
                "status": "enforce"
            },
            {
                "pid": "30770",
                "status": "enforce"
            },
            {
                "pid": "30824",
                "status": "enforce"
            },
            {
                "pid": "30902",
                "status": "enforce"
            },
            {
                "pid": "30997",
                "status": "enforce"
            },
            {
                "pid": "31024",
                "status": "enforce"
            },
            {
                "pid": "31456",
                "status": "enforce"
            },
            {
                "pid": "31751",
                "status": "enforce"
            },
            {
                "pid": "31775",
                "status": "enforce"
            },
            {
                "pid": "31979",
                "status": "enforce"
            },
            {
                "pid": "32040",
                "status": "enforce"
            },
            {
                "pid": "32096",
                "status": "enforce"
            },
            {
                "pid": "32115",
                "status": "enforce"
            },
            {
                "pid": "32189",
                "status": "enforce"
            },
            {
                "pid": "32241",
                "status": "enforce"
            },
            {
                "pid": "32298",
                "status": "enforce"
            },
            {
                "pid": "32370",
                "status": "enforce"
            },
            {
                "pid": "32513",
                "status": "enforce"
            },
            {
                "pid": "33194",
                "status": "enforce"
            },
            {
                "pid": "33225",
                "status": "enforce"
            },
            {
                "pid": "33706",
                "status": "enforce"
            },
            {
                "pid": "35034",
                "status": "enforce"
            },
            {
                "pid": "35413",
                "status": "enforce"
            },
            {
                "pid": "36946",
                "status": "enforce"
            },
            {
                "pid": "46915",
                "status": "enforce"
            },
            {
                "pid": "51255",
                "status": "enforce"
            },
            {
                "pid": "53250",
                "status": "enforce"
            },
            {
                "pid": "54053",
                "status": "enforce"
            },
            {
                "pid": "54360",
                "status": "enforce"
            },
            {
                "pid": "54361",
                "status": "enforce"
            },
            {
                "pid": "54699",
                "status": "enforce"
            },
            {
                "pid": "54700",
                "status": "enforce"
            },
            {
                "pid": "57360",
                "status": "enforce"
            },
            {
                "pid": "88005",
                "status": "enforce"
            },
            {
                "pid": "88041",
                "status": "enforce"
            },
            {
                "pid": "88092",
                "status": "enforce"
            },
            {
                "pid": "88685",
                "status": "enforce"
            },
            {
                "pid": "88788",
                "status": "enforce"
            },
            {
                "pid": "88933",
                "status": "enforce"
            },
            {
                "pid": "89998",
                "status": "enforce"
            },
            {
                "pid": "89999",
                "status": "enforce"
            },
            {
                "pid": "90000",
                "status": "enforce"
            },
            {
                "pid": "90001",
                "status": "enforce"
            },
            {
                "pid": "90002",
                "status": "enforce"
            },
            {
                "pid": "92903",
                "status": "enforce"
            },
            {
                "pid": "94490",
                "status": "enforce"
            },
            {
                "pid": "102149",
                "status": "enforce"
            },
            {
                "pid": "102178",
                "status": "enforce"
            },
            {
                "pid": "102376",
                "status": "enforce"
            },
            {
                "pid": "102445",
                "status": "enforce"
            },
            {
                "pid": "103028",
                "status": "enforce"
            },
            {
                "pid": "103203",
                "status": "enforce"
            },
            {
                "pid": "103265",
                "status": "enforce"
            },
            {
                "pid": "103524",
                "status": "enforce"
            },
            {
                "pid": "103532",
                "status": "enforce"
            },
            {
                "pid": "103676",
                "status": "enforce"
            },
            {
                "pid": "103698",
                "status": "enforce"
            },
            {
                "pid": "103932",
                "status": "enforce"
            },
            {
                "pid": "104048",
                "status": "enforce"
            },
            {
                "pid": "104343",
                "status": "enforce"
            },
            {
                "pid": "104678",
                "status": "enforce"
            },
            {
                "pid": "104806",
                "status": "enforce"
            },
            {
                "pid": "104902",
                "status": "enforce"
            },
            {
                "pid": "105086",
                "status": "enforce"
            },
            {
                "pid": "105130",
                "status": "enforce"
            },
            {
                "pid": "106070",
                "status": "enforce"
            },
            {
                "pid": "106092",
                "status": "enforce"
            },
            {
                "pid": "106184",
                "status": "enforce"
            },
            {
                "pid": "106378",
                "status": "enforce"
            },
            {
                "pid": "106386",
                "status": "enforce"
            },
            {
                "pid": "106430",
                "status": "enforce"
            },
            {
                "pid": "106454",
                "status": "enforce"
            },
            {
                "pid": "106473",
                "status": "enforce"
            },
            {
                "pid": "106727",
                "status": "enforce"
            },
            {
                "pid": "106971",
                "status": "enforce"
            },
            {
                "pid": "106983",
                "status": "enforce"
            },
            {
                "pid": "106991",
                "status": "enforce"
            },
            {
                "pid": "107019",
                "status": "enforce"
            },
            {
                "pid": "107051",
                "status": "enforce"
            },
            {
                "pid": "107052",
                "status": "enforce"
            },
            {
                "pid": "107147",
                "status": "enforce"
            },
            {
                "pid": "107317",
                "status": "enforce"
            },
            {
                "pid": "107383",
                "status": "enforce"
            },
            {
                "pid": "107430",
                "status": "enforce"
            },
            {
                "pid": "107488",
                "status": "enforce"
            },
            {
                "pid": "107637",
                "status": "enforce"
            },
            {
                "pid": "107802",
                "status": "enforce"
            },
            {
                "pid": "107839",
                "status": "enforce"
            },
            {
                "pid": "107910",
                "status": "enforce"
            },
            {
                "pid": "107998",
                "status": "enforce"
            },
            {
                "pid": "108141",
                "status": "enforce"
            },
            {
                "pid": "108263",
                "status": "enforce"
            },
            {
                "pid": "108456",
                "status": "enforce"
            },
            {
                "pid": "108606",
                "status": "enforce"
            },
            {
                "pid": "110434",
                "status": "enforce"
            },
            {
                "pid": "110487",
                "status": "enforce"
            },
            {
                "pid": "110624",
                "status": "enforce"
            },
            {
                "pid": "127110",
                "status": "enforce"
            },
            {
                "pid": "127197",
                "status": "enforce"
            },
            {
                "pid": "127247",
                "status": "enforce"
            },
            {
                "pid": "127557",
                "status": "enforce"
            },
            {
                "pid": "127573",
                "status": "enforce"
            },
            {
                "pid": "127714",
                "status": "enforce"
            },
            {
                "pid": "127734",
                "status": "enforce"
            },
            {
                "pid": "127781",
                "status": "enforce"
            },
            {
                "pid": "127808",
                "status": "enforce"
            },
            {
                "pid": "130074",
                "status": "enforce"
            },
            {
                "pid": "130108",
                "status": "enforce"
            },
            {
                "pid": "130400",
                "status": "enforce"
            },
            {
                "pid": "130637",
                "status": "enforce"
            },
            {
                "pid": "130681",
                "status": "enforce"
            },
            {
                "pid": "130856",
                "status": "enforce"
            },
            {
                "pid": "131298",
                "status": "enforce"
            },
            {
                "pid": "131401",
                "status": "enforce"
            },
            {
                "pid": "154657",
                "status": "enforce"
            },
            {
                "pid": "154681",
                "status": "enforce"
            },
            {
                "pid": "154736",
                "status": "enforce"
            },
            {
                "pid": "154737",
                "status": "enforce"
            },
            {
                "pid": "154738",
                "status": "enforce"
            },
            {
                "pid": "154740",
                "status": "enforce"
            },
            {
                "pid": "154746",
                "status": "enforce"
            },
            {
                "pid": "154747",
                "status": "enforce"
            },
            {
                "pid": "154752",
                "status": "enforce"
            },
            {
                "pid": "154755",
                "status": "enforce"
            },
            {
                "pid": "154766",
                "status": "enforce"
            },
            {
                "pid": "154772",
                "status": "enforce"
            },
            {
                "pid": "155150",
                "status": "enforce"
            },
            {
                "pid": "155185",
                "status": "enforce"
            },
            {
                "pid": "155262",
                "status": "enforce"
            },
            {
                "pid": "155295",
                "status": "enforce"
            },
            {
                "pid": "155336",
                "status": "enforce"
            },
            {
                "pid": "155367",
                "status": "enforce"
            },
            {
                "pid": "165388",
                "status": "enforce"
            },
            {
                "pid": "167498",
                "status": "enforce"
            },
            {
                "pid": "167643",
                "status": "enforce"
            },
            {
                "pid": "168309",
                "status": "enforce"
            },
            {
                "pid": "168335",
                "status": "enforce"
            },
            {
                "pid": "168534",
                "status": "enforce"
            },
            {
                "pid": "168535",
                "status": "enforce"
            },
            {
                "pid": "169102",
                "status": "enforce"
            },
            {
                "pid": "169174",
                "status": "enforce"
            },
            {
                "pid": "169339",
                "status": "enforce"
            },
            {
                "pid": "169357",
                "status": "enforce"
            },
            {
                "pid": "169408",
                "status": "enforce"
            },
            {
                "pid": "169427",
                "status": "enforce"
            },
            {
                "pid": "169673",
                "status": "enforce"
            },
            {
                "pid": "169822",
                "status": "enforce"
            },
            {
                "pid": "170069",
                "status": "enforce"
            },
            {
                "pid": "170115",
                "status": "enforce"
            },
            {
                "pid": "170233",
                "status": "enforce"
            },
            {
                "pid": "170252",
                "status": "enforce"
            },
            {
                "pid": "170574",
                "status": "enforce"
            },
            {
                "pid": "170895",
                "status": "enforce"
            },
            {
                "pid": "171198",
                "status": "enforce"
            },
            {
                "pid": "171396",
                "status": "enforce"
            },
            {
                "pid": "171527",
                "status": "enforce"
            },
            {
                "pid": "171697",
                "status": "enforce"
            },
            {
                "pid": "172195",
                "status": "enforce"
            },
            {
                "pid": "172389",
                "status": "enforce"
            },
            {
                "pid": "173465",
                "status": "enforce"
            },
            {
                "pid": "173722",
                "status": "enforce"
            },
            {
                "pid": "173963",
                "status": "enforce"
            },
            {
                "pid": "174561",
                "status": "enforce"
            },
            {
                "pid": "174579",
                "status": "enforce"
            },
            {
                "pid": "174731",
                "status": "enforce"
            },
            {
                "pid": "174753",
                "status": "enforce"
            },
            {
                "pid": "175078",
                "status": "enforce"
            },
            {
                "pid": "175096",
                "status": "enforce"
            },
            {
                "pid": "175205",
                "status": "enforce"
            },
            {
                "pid": "175287",
                "status": "enforce"
            },
            {
                "pid": "175954",
                "status": "enforce"
            },
            {
                "pid": "175969",
                "status": "enforce"
            },
            {
                "pid": "176028",
                "status": "enforce"
            },
            {
                "pid": "177795",
                "status": "enforce"
            },
            {
                "pid": "178422",
                "status": "enforce"
            },
            {
                "pid": "178657",
                "status": "enforce"
            },
            {
                "pid": "179192",
                "status": "enforce"
            },
            {
                "pid": "179455",
                "status": "enforce"
            },
            {
                "pid": "179817",
                "status": "enforce"
            },
            {
                "pid": "180141",
                "status": "enforce"
            },
            {
                "pid": "180346",
                "status": "enforce"
            },
            {
                "pid": "180679",
                "status": "enforce"
            },
            {
                "pid": "180965",
                "status": "enforce"
            },
            {
                "pid": "181112",
                "status": "enforce"
            },
            {
                "pid": "181900",
                "status": "enforce"
            },
            {
                "pid": "181980",
                "status": "enforce"
            },
            {
                "pid": "182340",
                "status": "enforce"
            },
            {
                "pid": "182385",
                "status": "enforce"
            },
            {
                "pid": "182562",
                "status": "enforce"
            },
            {
                "pid": "182587",
                "status": "enforce"
            },
            {
                "pid": "182675",
                "status": "enforce"
            },
            {
                "pid": "182746",
                "status": "enforce"
            },
            {
                "pid": "183023",
                "status": "enforce"
            },
            {
                "pid": "183126",
                "status": "enforce"
            },
            {
                "pid": "183150",
                "status": "enforce"
            },
            {
                "pid": "183379",
                "status": "enforce"
            },
            {
                "pid": "183403",
                "status": "enforce"
            },
            {
                "pid": "184433",
                "status": "enforce"
            },
            {
                "pid": "184761",
                "status": "enforce"
            },
            {
                "pid": "185032",
                "status": "enforce"
            },
            {
                "pid": "185579",
                "status": "enforce"
            },
            {
                "pid": "185657",
                "status": "enforce"
            },
            {
                "pid": "185670",
                "status": "enforce"
            },
            {
                "pid": "185679",
                "status": "enforce"
            },
            {
                "pid": "185807",
                "status": "enforce"
            },
            {
                "pid": "185887",
                "status": "enforce"
            },
            {
                "pid": "185888",
                "status": "enforce"
            },
            {
                "pid": "185892",
                "status": "enforce"
            },
            {
                "pid": "186157",
                "status": "enforce"
            },
            {
                "pid": "186167",
                "status": "enforce"
            },
            {
                "pid": "186175",
                "status": "enforce"
            },
            {
                "pid": "186222",
                "status": "enforce"
            },
            {
                "pid": "186223",
                "status": "enforce"
            },
            {
                "pid": "186224",
                "status": "enforce"
            },
            {
                "pid": "186475",
                "status": "enforce"
            },
            {
                "pid": "186485",
                "status": "enforce"
            },
            {
                "pid": "186526",
                "status": "enforce"
            },
            {
                "pid": "186527",
                "status": "enforce"
            },
            {
                "pid": "186732",
                "status": "enforce"
            },
            {
                "pid": "186753",
                "status": "enforce"
            },
            {
                "pid": "186778",
                "status": "enforce"
            },
            {
                "pid": "186798",
                "status": "enforce"
            },
            {
                "pid": "186961",
                "status": "enforce"
            },
            {
                "pid": "187045",
                "status": "enforce"
            },
            {
                "pid": "188233",
                "status": "enforce"
            },
            {
                "pid": "188571",
                "status": "enforce"
            },
            {
                "pid": "190114",
                "status": "enforce"
            },
            {
                "pid": "190135",
                "status": "enforce"
            },
            {
                "pid": "190329",
                "status": "enforce"
            },
            {
                "pid": "190330",
                "status": "enforce"
            },
            {
                "pid": "192317",
                "status": "enforce"
            },
            {
                "pid": "192936",
                "status": "enforce"
            },
            {
                "pid": "193855",
                "status": "enforce"
            },
            {
                "pid": "194544",
                "status": "enforce"
            },
            {
                "pid": "195298",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:57.145806</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1636 chars]e"}}' != '{"pr[333 chars]", "/sbin/dhclient": "enforce", "/usr/bin/prom[1583 chars]e"}}'
Diff is 4795 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:57.145979</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:57.146182</td>
    <td>0.54</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.146170</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.146177</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:57.146180</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.146210</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:36:57.360594</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.360637</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:36:57.360645</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:57.360712</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:57.360750</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:57.360755</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:57.399014</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:57.399061</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:57.677184</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/dhclient": [
            {
                "pid": "7678",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "152028",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "182913",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "182921",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "182893",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "182908",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "12056",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "153935",
                "status": "complain"
            },
            {
                "pid": "154946",
                "status": "complain"
            },
            {
                "pid": "154960",
                "status": "complain"
            },
            {
                "pid": "154965",
                "status": "complain"
            },
            {
                "pid": "154970",
                "status": "complain"
            },
            {
                "pid": "154982",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "57977",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "55948",
                "status": "complain"
            },
            {
                "pid": "55998",
                "status": "complain"
            },
            {
                "pid": "56064",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "59264",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "159607",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "55095",
                "status": "enforce"
            },
            {
                "pid": "55108",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "4874",
                "status": "enforce"
            },
            {
                "pid": "5251",
                "status": "enforce"
            },
            {
                "pid": "7140",
                "status": "enforce"
            },
            {
                "pid": "7303",
                "status": "enforce"
            },
            {
                "pid": "7304",
                "status": "enforce"
            },
            {
                "pid": "7305",
                "status": "enforce"
            },
            {
                "pid": "19019",
                "status": "enforce"
            },
            {
                "pid": "19300",
                "status": "enforce"
            },
            {
                "pid": "19460",
                "status": "enforce"
            },
            {
                "pid": "19816",
                "status": "enforce"
            },
            {
                "pid": "24699",
                "status": "enforce"
            },
            {
                "pid": "24713",
                "status": "enforce"
            },
            {
                "pid": "24722",
                "status": "enforce"
            },
            {
                "pid": "24832",
                "status": "enforce"
            },
            {
                "pid": "25078",
                "status": "enforce"
            },
            {
                "pid": "25079",
                "status": "enforce"
            },
            {
                "pid": "25083",
                "status": "enforce"
            },
            {
                "pid": "25201",
                "status": "enforce"
            },
            {
                "pid": "26305",
                "status": "enforce"
            },
            {
                "pid": "26346",
                "status": "enforce"
            },
            {
                "pid": "26520",
                "status": "enforce"
            },
            {
                "pid": "26666",
                "status": "enforce"
            },
            {
                "pid": "27694",
                "status": "enforce"
            },
            {
                "pid": "27827",
                "status": "enforce"
            },
            {
                "pid": "27886",
                "status": "enforce"
            },
            {
                "pid": "27908",
                "status": "enforce"
            },
            {
                "pid": "28051",
                "status": "enforce"
            },
            {
                "pid": "28139",
                "status": "enforce"
            },
            {
                "pid": "29601",
                "status": "enforce"
            },
            {
                "pid": "30020",
                "status": "enforce"
            },
            {
                "pid": "30135",
                "status": "enforce"
            },
            {
                "pid": "30332",
                "status": "enforce"
            },
            {
                "pid": "30387",
                "status": "enforce"
            },
            {
                "pid": "30452",
                "status": "enforce"
            },
            {
                "pid": "30733",
                "status": "enforce"
            },
            {
                "pid": "30770",
                "status": "enforce"
            },
            {
                "pid": "30824",
                "status": "enforce"
            },
            {
                "pid": "30902",
                "status": "enforce"
            },
            {
                "pid": "30997",
                "status": "enforce"
            },
            {
                "pid": "31024",
                "status": "enforce"
            },
            {
                "pid": "31456",
                "status": "enforce"
            },
            {
                "pid": "31751",
                "status": "enforce"
            },
            {
                "pid": "31775",
                "status": "enforce"
            },
            {
                "pid": "31979",
                "status": "enforce"
            },
            {
                "pid": "32040",
                "status": "enforce"
            },
            {
                "pid": "32096",
                "status": "enforce"
            },
            {
                "pid": "32115",
                "status": "enforce"
            },
            {
                "pid": "32189",
                "status": "enforce"
            },
            {
                "pid": "32241",
                "status": "enforce"
            },
            {
                "pid": "32298",
                "status": "enforce"
            },
            {
                "pid": "32370",
                "status": "enforce"
            },
            {
                "pid": "32513",
                "status": "enforce"
            },
            {
                "pid": "33194",
                "status": "enforce"
            },
            {
                "pid": "33225",
                "status": "enforce"
            },
            {
                "pid": "33706",
                "status": "enforce"
            },
            {
                "pid": "35034",
                "status": "enforce"
            },
            {
                "pid": "35413",
                "status": "enforce"
            },
            {
                "pid": "36946",
                "status": "enforce"
            },
            {
                "pid": "46915",
                "status": "enforce"
            },
            {
                "pid": "51255",
                "status": "enforce"
            },
            {
                "pid": "53250",
                "status": "enforce"
            },
            {
                "pid": "54053",
                "status": "enforce"
            },
            {
                "pid": "54360",
                "status": "enforce"
            },
            {
                "pid": "54361",
                "status": "enforce"
            },
            {
                "pid": "54699",
                "status": "enforce"
            },
            {
                "pid": "54700",
                "status": "enforce"
            },
            {
                "pid": "57360",
                "status": "enforce"
            },
            {
                "pid": "88005",
                "status": "enforce"
            },
            {
                "pid": "88041",
                "status": "enforce"
            },
            {
                "pid": "88092",
                "status": "enforce"
            },
            {
                "pid": "88685",
                "status": "enforce"
            },
            {
                "pid": "88788",
                "status": "enforce"
            },
            {
                "pid": "88933",
                "status": "enforce"
            },
            {
                "pid": "89998",
                "status": "enforce"
            },
            {
                "pid": "89999",
                "status": "enforce"
            },
            {
                "pid": "90000",
                "status": "enforce"
            },
            {
                "pid": "90001",
                "status": "enforce"
            },
            {
                "pid": "90002",
                "status": "enforce"
            },
            {
                "pid": "92903",
                "status": "enforce"
            },
            {
                "pid": "94490",
                "status": "enforce"
            },
            {
                "pid": "102149",
                "status": "enforce"
            },
            {
                "pid": "102178",
                "status": "enforce"
            },
            {
                "pid": "102376",
                "status": "enforce"
            },
            {
                "pid": "102445",
                "status": "enforce"
            },
            {
                "pid": "103028",
                "status": "enforce"
            },
            {
                "pid": "103203",
                "status": "enforce"
            },
            {
                "pid": "103265",
                "status": "enforce"
            },
            {
                "pid": "103524",
                "status": "enforce"
            },
            {
                "pid": "103532",
                "status": "enforce"
            },
            {
                "pid": "103676",
                "status": "enforce"
            },
            {
                "pid": "103698",
                "status": "enforce"
            },
            {
                "pid": "103932",
                "status": "enforce"
            },
            {
                "pid": "104048",
                "status": "enforce"
            },
            {
                "pid": "104343",
                "status": "enforce"
            },
            {
                "pid": "104678",
                "status": "enforce"
            },
            {
                "pid": "104806",
                "status": "enforce"
            },
            {
                "pid": "104902",
                "status": "enforce"
            },
            {
                "pid": "105086",
                "status": "enforce"
            },
            {
                "pid": "105130",
                "status": "enforce"
            },
            {
                "pid": "106070",
                "status": "enforce"
            },
            {
                "pid": "106092",
                "status": "enforce"
            },
            {
                "pid": "106184",
                "status": "enforce"
            },
            {
                "pid": "106378",
                "status": "enforce"
            },
            {
                "pid": "106386",
                "status": "enforce"
            },
            {
                "pid": "106430",
                "status": "enforce"
            },
            {
                "pid": "106454",
                "status": "enforce"
            },
            {
                "pid": "106473",
                "status": "enforce"
            },
            {
                "pid": "106727",
                "status": "enforce"
            },
            {
                "pid": "106971",
                "status": "enforce"
            },
            {
                "pid": "106983",
                "status": "enforce"
            },
            {
                "pid": "106991",
                "status": "enforce"
            },
            {
                "pid": "107019",
                "status": "enforce"
            },
            {
                "pid": "107051",
                "status": "enforce"
            },
            {
                "pid": "107052",
                "status": "enforce"
            },
            {
                "pid": "107147",
                "status": "enforce"
            },
            {
                "pid": "107317",
                "status": "enforce"
            },
            {
                "pid": "107383",
                "status": "enforce"
            },
            {
                "pid": "107430",
                "status": "enforce"
            },
            {
                "pid": "107488",
                "status": "enforce"
            },
            {
                "pid": "107637",
                "status": "enforce"
            },
            {
                "pid": "107802",
                "status": "enforce"
            },
            {
                "pid": "107839",
                "status": "enforce"
            },
            {
                "pid": "107910",
                "status": "enforce"
            },
            {
                "pid": "107998",
                "status": "enforce"
            },
            {
                "pid": "108141",
                "status": "enforce"
            },
            {
                "pid": "108263",
                "status": "enforce"
            },
            {
                "pid": "108456",
                "status": "enforce"
            },
            {
                "pid": "108606",
                "status": "enforce"
            },
            {
                "pid": "110434",
                "status": "enforce"
            },
            {
                "pid": "110487",
                "status": "enforce"
            },
            {
                "pid": "110624",
                "status": "enforce"
            },
            {
                "pid": "127110",
                "status": "enforce"
            },
            {
                "pid": "127197",
                "status": "enforce"
            },
            {
                "pid": "127247",
                "status": "enforce"
            },
            {
                "pid": "127557",
                "status": "enforce"
            },
            {
                "pid": "127573",
                "status": "enforce"
            },
            {
                "pid": "127714",
                "status": "enforce"
            },
            {
                "pid": "127734",
                "status": "enforce"
            },
            {
                "pid": "127781",
                "status": "enforce"
            },
            {
                "pid": "127808",
                "status": "enforce"
            },
            {
                "pid": "130074",
                "status": "enforce"
            },
            {
                "pid": "130108",
                "status": "enforce"
            },
            {
                "pid": "130400",
                "status": "enforce"
            },
            {
                "pid": "130637",
                "status": "enforce"
            },
            {
                "pid": "130681",
                "status": "enforce"
            },
            {
                "pid": "130856",
                "status": "enforce"
            },
            {
                "pid": "131298",
                "status": "enforce"
            },
            {
                "pid": "131401",
                "status": "enforce"
            },
            {
                "pid": "154657",
                "status": "enforce"
            },
            {
                "pid": "154681",
                "status": "enforce"
            },
            {
                "pid": "154736",
                "status": "enforce"
            },
            {
                "pid": "154737",
                "status": "enforce"
            },
            {
                "pid": "154738",
                "status": "enforce"
            },
            {
                "pid": "154740",
                "status": "enforce"
            },
            {
                "pid": "154746",
                "status": "enforce"
            },
            {
                "pid": "154747",
                "status": "enforce"
            },
            {
                "pid": "154752",
                "status": "enforce"
            },
            {
                "pid": "154755",
                "status": "enforce"
            },
            {
                "pid": "154766",
                "status": "enforce"
            },
            {
                "pid": "154772",
                "status": "enforce"
            },
            {
                "pid": "155150",
                "status": "enforce"
            },
            {
                "pid": "155185",
                "status": "enforce"
            },
            {
                "pid": "155262",
                "status": "enforce"
            },
            {
                "pid": "155295",
                "status": "enforce"
            },
            {
                "pid": "155336",
                "status": "enforce"
            },
            {
                "pid": "155367",
                "status": "enforce"
            },
            {
                "pid": "165388",
                "status": "enforce"
            },
            {
                "pid": "167498",
                "status": "enforce"
            },
            {
                "pid": "167643",
                "status": "enforce"
            },
            {
                "pid": "168309",
                "status": "enforce"
            },
            {
                "pid": "168335",
                "status": "enforce"
            },
            {
                "pid": "168534",
                "status": "enforce"
            },
            {
                "pid": "168535",
                "status": "enforce"
            },
            {
                "pid": "169102",
                "status": "enforce"
            },
            {
                "pid": "169174",
                "status": "enforce"
            },
            {
                "pid": "169339",
                "status": "enforce"
            },
            {
                "pid": "169357",
                "status": "enforce"
            },
            {
                "pid": "169408",
                "status": "enforce"
            },
            {
                "pid": "169427",
                "status": "enforce"
            },
            {
                "pid": "169673",
                "status": "enforce"
            },
            {
                "pid": "169822",
                "status": "enforce"
            },
            {
                "pid": "170069",
                "status": "enforce"
            },
            {
                "pid": "170115",
                "status": "enforce"
            },
            {
                "pid": "170233",
                "status": "enforce"
            },
            {
                "pid": "170252",
                "status": "enforce"
            },
            {
                "pid": "170574",
                "status": "enforce"
            },
            {
                "pid": "170895",
                "status": "enforce"
            },
            {
                "pid": "171198",
                "status": "enforce"
            },
            {
                "pid": "171396",
                "status": "enforce"
            },
            {
                "pid": "171527",
                "status": "enforce"
            },
            {
                "pid": "171697",
                "status": "enforce"
            },
            {
                "pid": "172195",
                "status": "enforce"
            },
            {
                "pid": "172389",
                "status": "enforce"
            },
            {
                "pid": "173465",
                "status": "enforce"
            },
            {
                "pid": "173722",
                "status": "enforce"
            },
            {
                "pid": "173963",
                "status": "enforce"
            },
            {
                "pid": "174561",
                "status": "enforce"
            },
            {
                "pid": "174579",
                "status": "enforce"
            },
            {
                "pid": "174731",
                "status": "enforce"
            },
            {
                "pid": "174753",
                "status": "enforce"
            },
            {
                "pid": "175078",
                "status": "enforce"
            },
            {
                "pid": "175096",
                "status": "enforce"
            },
            {
                "pid": "175205",
                "status": "enforce"
            },
            {
                "pid": "175287",
                "status": "enforce"
            },
            {
                "pid": "175954",
                "status": "enforce"
            },
            {
                "pid": "175969",
                "status": "enforce"
            },
            {
                "pid": "176028",
                "status": "enforce"
            },
            {
                "pid": "177795",
                "status": "enforce"
            },
            {
                "pid": "178422",
                "status": "enforce"
            },
            {
                "pid": "178657",
                "status": "enforce"
            },
            {
                "pid": "179192",
                "status": "enforce"
            },
            {
                "pid": "179455",
                "status": "enforce"
            },
            {
                "pid": "179817",
                "status": "enforce"
            },
            {
                "pid": "180141",
                "status": "enforce"
            },
            {
                "pid": "180346",
                "status": "enforce"
            },
            {
                "pid": "180679",
                "status": "enforce"
            },
            {
                "pid": "180965",
                "status": "enforce"
            },
            {
                "pid": "181112",
                "status": "enforce"
            },
            {
                "pid": "181900",
                "status": "enforce"
            },
            {
                "pid": "181980",
                "status": "enforce"
            },
            {
                "pid": "182340",
                "status": "enforce"
            },
            {
                "pid": "182385",
                "status": "enforce"
            },
            {
                "pid": "182562",
                "status": "enforce"
            },
            {
                "pid": "182587",
                "status": "enforce"
            },
            {
                "pid": "182675",
                "status": "enforce"
            },
            {
                "pid": "182746",
                "status": "enforce"
            },
            {
                "pid": "183023",
                "status": "enforce"
            },
            {
                "pid": "183126",
                "status": "enforce"
            },
            {
                "pid": "183150",
                "status": "enforce"
            },
            {
                "pid": "183379",
                "status": "enforce"
            },
            {
                "pid": "183403",
                "status": "enforce"
            },
            {
                "pid": "184433",
                "status": "enforce"
            },
            {
                "pid": "184761",
                "status": "enforce"
            },
            {
                "pid": "185032",
                "status": "enforce"
            },
            {
                "pid": "185579",
                "status": "enforce"
            },
            {
                "pid": "185657",
                "status": "enforce"
            },
            {
                "pid": "185670",
                "status": "enforce"
            },
            {
                "pid": "185679",
                "status": "enforce"
            },
            {
                "pid": "185807",
                "status": "enforce"
            },
            {
                "pid": "185887",
                "status": "enforce"
            },
            {
                "pid": "185888",
                "status": "enforce"
            },
            {
                "pid": "185892",
                "status": "enforce"
            },
            {
                "pid": "186157",
                "status": "enforce"
            },
            {
                "pid": "186167",
                "status": "enforce"
            },
            {
                "pid": "186175",
                "status": "enforce"
            },
            {
                "pid": "186222",
                "status": "enforce"
            },
            {
                "pid": "186223",
                "status": "enforce"
            },
            {
                "pid": "186224",
                "status": "enforce"
            },
            {
                "pid": "186475",
                "status": "enforce"
            },
            {
                "pid": "186485",
                "status": "enforce"
            },
            {
                "pid": "186526",
                "status": "enforce"
            },
            {
                "pid": "186527",
                "status": "enforce"
            },
            {
                "pid": "186732",
                "status": "enforce"
            },
            {
                "pid": "186753",
                "status": "enforce"
            },
            {
                "pid": "186778",
                "status": "enforce"
            },
            {
                "pid": "186798",
                "status": "enforce"
            },
            {
                "pid": "186961",
                "status": "enforce"
            },
            {
                "pid": "187045",
                "status": "enforce"
            },
            {
                "pid": "188233",
                "status": "enforce"
            },
            {
                "pid": "188571",
                "status": "enforce"
            },
            {
                "pid": "190114",
                "status": "enforce"
            },
            {
                "pid": "190135",
                "status": "enforce"
            },
            {
                "pid": "190329",
                "status": "enforce"
            },
            {
                "pid": "190330",
                "status": "enforce"
            },
            {
                "pid": "192317",
                "status": "enforce"
            },
            {
                "pid": "192936",
                "status": "enforce"
            },
            {
                "pid": "193855",
                "status": "enforce"
            },
            {
                "pid": "194544",
                "status": "enforce"
            },
            {
                "pid": "195298",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:57.682809</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1636 chars]e"}}' != '{"pr[333 chars]", "/sbin/dhclient": "enforce", "/usr/bin/prom[1583 chars]e"}}'
Diff is 4795 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:57.682955</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.808832</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.808819</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.808826</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:57.808829</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.808872</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:57.808898</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.861968</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:36:57.865108</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
lxd
input
crontab
messagebus
ssh
admin
netdev
uuidd
syslog
sysop
nslcd
_lldpd
docker
ssl-cert
postfix
postdrop
tss
frrvty
frr
vault
prometheus
systemd-timesync
libvirt
sugroup
sysgt
no_user
'
<i>2024-12-17 17:36:57.865355</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.865592</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.865579</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.865586</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:57.865589</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.865657</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:57.865692</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.916912</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:36:57.919667</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd::/var/lib/lxd/:/bin/false
messagebus::/nonexistent:/usr/sbin/nologin
sshd::/run/sshd:/usr/sbin/nologin
uuidd::/run/uuidd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
nslcd:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd::/var/run/lldpd:/usr/sbin/nologin
strongswan::/var/lib/strongswan:/usr/sbin/nologin
postfix::/var/spool/postfix:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
genctl::/home/genctl:/usr/sbin/nologin
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:36:57.919996</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:58.034234</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:58.034219</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:58.034229</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:58.034231</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:58.034311</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.034341</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.034358</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:36:58.034421</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.034434</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:36:58.034845</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.034861</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:36:58.034900</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.034912</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.034923</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:36:58.034976</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.034987</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.034998</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:36:58.035677</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.035695</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:36:58.035826</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.035840</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release5 : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release5
<i>2024-12-17 17:36:58.060485</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:36:58.063218</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root   0 Dec 17 17:36 cron.allow
drwxr-x--- 2 root root  60 Dec 17 17:36 cron.d
drwxr-x--- 2 root root 300 Dec 17 17:36 cron.daily
drwxr-x--- 2 root root 180 Dec 17 17:36 cron.hourly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.monthly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.weekly
-rw-r----- 1 root root 815 Dec 17 17:36 crontab
'
<i>2024-12-17 17:36:58.063263</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:36:58.066077</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:58.066118</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:36:58.066171</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:58.066445</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:58.066430</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:58.066437</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:58.066441</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:58.066472</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:36:58.068779</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
'
<i>2024-12-17 17:36:58.068824</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:36:58.070619</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:58.070687</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release5/control : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/control
<i>2024-12-17 17:36:58.070711</i> <b style="color:rgb(0 133 115);">[INFO]</b> shell_artifacts/cronjobs/crontab_data/release5/control personality folder not present for comparison
<i>2024-12-17 17:36:58.070753</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:58.070965</td>
    <td>7.16</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:58.070952</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:58.070958</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:36:58.070961</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:58.070991</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:36:58.073048</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:58.073081</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:36:58.074434</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:58.074477</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:00.089561</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:00.089616</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:37:00.089691</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:00.089699</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:00.089705</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:03.208449</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
.
good
'
<i>2024-12-17 17:37:03.208508</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:37:03.208523</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:37:03.211544</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:03.211583</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:05.226701</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:05.226865</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.346842</td>
    <td>0.15</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.346827</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.346836</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:37:05.346839</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.346886</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.346890</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.346893</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.496153</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

{"pid":56618,"time":1734457025393,"tid":1,"msg":"Warning -- could not open /usr/share/zoneinfo. Set the NESSUS_TZ_DIR env. variable","severity":"INFO"}
Linked to: nmnode2-04-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:37:05.496330</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.605288</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.605273</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.605282</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:37:05.605285</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.605328</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.605333</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.605336</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.651612</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.651795</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.652003</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.651990</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.651997</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:37:05.652000</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.652071</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.652078</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.652082</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.699963</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.700153</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.807848</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.807834</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.807842</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:37:05.807845</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.807891</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.807895</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.807898</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.813817</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:37:05.813973</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.814146</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.814136</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.814142</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:37:05.814144</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.814206</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.814212</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.814215</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.818954</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:37:05.819079</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.819225</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.819215</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.819221</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:37:05.819223</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.819286</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.819292</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.819295</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014288_4937/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.825280</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:37:05.825443</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.931999</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s28 (control)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.931984</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.931992</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:28 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:54:48 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:06 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:02 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:28 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:19 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:04:57 UTC, STATUS=success)

<i>2024-12-17 17:37:05.931996</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.932033</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:37:05.935066</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.5VYkMqdwKBHQg03
'
<i>2024-12-17 17:37:05.935111</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.5VYkMqdwKBHQg03 | grep "publickey ssh-rsa"
<i>2024-12-17 17:37:05.937453</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:37:05.937589</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:55.026390</td>
    <td>1.76</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:55.026376</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:55.026384</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:55.026386</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:55.026422</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:55.026426</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:55.026429</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:56.783924</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 26861 packets, 1659K bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     842K  108M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    7411K 9562M KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3     842K  108M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4    7411K 9562M KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5    7584K   10G HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 7429 packets, 446K bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     812K   49M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2     812K   49M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3    7734K  904M KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4    7882K  926M HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      64M 6756M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2     327M  187G KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3      64M 6755M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4      64M 6755M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5        0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
6      64M 6755M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 65 packets, 4680 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      682  345K KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      617  341K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      682  345K KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      617  341K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5      711  359K HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     1351 97716 KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4     1359 98164 HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2     308K   19M KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     308K   19M HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION
# am-utils.service                     not-found inactive dead    am-utils.service
# apache2.service                      not-found inactive dead    apache2.service
  apparmor.service                     loaded    active   exited  Load AppArmor profiles
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities
# apt-daily.service                    masked    inactive dead    apt-daily.service
# atd.service                          not-found inactive dead    atd.service
  auditd.service                       loaded    active   running Security Auditing Service
  auth-rpcgss-module.service           loaded    inactive dead    Kernel Module supporting RPCSEC_GSS
# autofs.service                       not-found inactive dead    autofs.service
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats
  blk-availability.service             loaded    active   exited  Availability of block devices
# citadel.service                      not-found inactive dead    citadel.service
  cloud-config.service                 loaded    inactive dead    Cloud-init: Config Stage
  cloud-final.service                  loaded    active   exited  Cloud-init: Final Stage
  cloud-init-hotplugd.service          loaded    inactive dead    Cloud-init: Hotplug Hook
  cloud-init-local.service             loaded    active   exited  Cloud-init: Local Stage (pre-network)
  cloud-init.service                   loaded    active   exited  Cloud-init: Network Stage
  cloudnet-gobgp.service               loaded    inactive dead    gobgpd service
# connman.service                      not-found inactive dead    connman.service
  containerd.service                   loaded    active   running containerd container runtime
# courier-ldap.service                 not-found inactive dead    courier-ldap.service
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service
# courier-mta.service                  not-found inactive dead    courier-mta.service
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service
# courier-pop.service                  not-found inactive dead    courier-pop.service
  cron.service                         loaded    active   running Regular background program processing daemon
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service
  dbus.service                         loaded    active   running D-Bus System Message Bus
# display-manager.service              not-found inactive dead    display-manager.service
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon
  dmesg.service                        loaded    inactive dead    Save initial kernel messages after boot
# dovecot.service                      not-found inactive dead    dovecot.service
  dpkg-db-backup.service               loaded    inactive dead    Daily dpkg database backup service
  e2scrub_all.service                  loaded    inactive dead    Online ext4 Metadata Check for All Filesystems
  e2scrub_reap.service                 loaded    inactive dead    Remove Stale Online ext4 Metadata Check Snapshots
  emergency.service                    loaded    inactive dead    Emergency Shell
# exim4.service                        not-found inactive dead    exim4.service
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor
# fcoe.service                         not-found inactive dead    fcoe.service
  finalrd.service                      loaded    active   exited  Create final runtime dir for shutdown pivot root
  fluent-bit-ops-logs.service          loaded    inactive dead    Fluent Bit agent forwarding ops logs to remote.
  fluent-bit-qradar.service            loaded    inactive dead    Fluent Bit agent forwarding audit logs to QRadar.
  frr.service                          loaded    active   running FRRouting
  fstrim.service                       loaded    inactive dead    Discard unused blocks on filesystems from /etc/fstab
# gdm3.service                         not-found inactive dead    gdm3.service
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available
  getty@tty1.service                   loaded    active   running Getty on tty1
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes
# gssproxy.service                     not-found inactive dead    gssproxy.service
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service
# hv_kvp_daemon.service                not-found inactive dead    hv_kvp_daemon.service
  ifupdown-pre.service                 loaded    inactive dead    Helper to synchronize boot up for ifupdown
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service
  iscsid.service                       loaded    inactive dead    iSCSI initiator daemon (iscsid)
# kdm.service                          not-found inactive dead    kdm.service
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system
  kmod-static-nodes.service            loaded    active   exited  Create List of Static Device Nodes
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent
  lldpd.service                        loaded    active   running LLDP daemon
# logrotate.service                    loaded    failed   failed  Rotate log files
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon
  lvm2-monitor.service                 loaded    active   exited  Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service
# masqmail.service                     not-found inactive dead    masqmail.service
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.
  modprobe@configfs.service            loaded    inactive dead    Load Kernel Module configfs
  modprobe@drm.service                 loaded    inactive dead    Load Kernel Module drm
  modprobe@efi_pstore.service          loaded    inactive dead    Load Kernel Module efi_pstore
  modprobe@fuse.service                loaded    inactive dead    Load Kernel Module fuse
  motd-news.service                    loaded    inactive dead    Message of the Day
  mst.service                          loaded    active   exited  LSB: mst
  nessusagent.service                  loaded    active   running The Nessus Client Agent
  netplan-ovs-cleanup.service          loaded    inactive dead    OpenVSwitch configuration for cleanup
# network.service                      not-found inactive dead    network.service
  networking.service                   loaded    inactive dead    Raise network interfaces
# NetworkManager.service               not-found inactive dead    NetworkManager.service
# nfs-server.service                   not-found inactive dead    nfs-server.service
  nfs-utils.service                    loaded    inactive dead    NFS server and client services
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon
# nullmailer.service                   not-found inactive dead    nullmailer.service
  open-iscsi.service                   loaded    inactive dead    Login to default iSCSI targets
  osqueryd.service                     loaded    active   running The osquery Daemon
# ovsdb-server.service                 not-found inactive dead    ovsdb-server.service
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service
# plymouth-start.service               not-found inactive dead    plymouth-start.service
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics
# rbdmap.service                       not-found inactive dead    rbdmap.service
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility
  rescue.service                       loaded    inactive dead    Rescue Shell
  rpc-gssd.service                     loaded    inactive dead    RPC security service for NFS client and server
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.
  rpc-svcgssd.service                  loaded    inactive dead    RPC security service for NFS server
  rpcbind.service                      loaded    inactive dead    RPC bind portmap service
  rsyslog.service                      loaded    active   running System Logging Service
  secureboot-db.service                loaded    inactive dead    Secure Boot updates for DB and DBX
# sendmail.service                     not-found inactive dead    sendmail.service
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1
# set-hostname.service                 not-found inactive dead    set-hostname.service
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service
  skydive.service                      loaded    active   running Skydive
# slapd.service                        not-found inactive dead    slapd.service
# slim.service                         not-found inactive dead    slim.service
# snapd.seeded.service                 not-found inactive dead    snapd.seeded.service
  ssh.service                          loaded    active   running OpenBSD Secure Shell server
# sshd-keygen.service                  not-found inactive dead    sshd-keygen.service
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall
  systemd-binfmt.service               loaded    active   exited  Set Up Additional Binary Formats
  systemd-boot-system-token.service    loaded    inactive dead    Store a System Token in an EFI Variable
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status
# systemd-hwdb-update.service          not-found inactive dead    systemd-hwdb-update.service
  systemd-initctl.service              loaded    inactive dead    initctl Compatibility Daemon
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage
  systemd-journald.service             loaded    active   running Journal Service
  systemd-logind.service               loaded    active   running User Login Management
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules
  systemd-networkd-wait-online.service loaded    inactive dead    Wait for Network to be Configured
# systemd-networkd.service             masked    inactive dead    systemd-networkd.service
# systemd-oomd.service                 not-found inactive dead    systemd-oomd.service
  systemd-pstore.service               loaded    inactive dead    Platform Persistent Storage Archival
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems
  systemd-resolved.service             loaded    active   running Network Name Resolution
  systemd-rfkill.service               loaded    inactive dead    Load/Save RF Kill Switch Status
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables
  systemd-sysusers.service             loaded    active   exited  Create System Users
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories
  systemd-udev-trigger.service         loaded    active   exited  Coldplug All udev Devices
  systemd-udevd.service                loaded    active   running Rule-based Manager for Device Events and Files
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service
  systemd-update-utmp-runlevel.service loaded    inactive dead    Record Runlevel Change in UTMP
  systemd-update-utmp.service          loaded    active   exited  Record System Boot/Shutdown in UTMP
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service
  taniumclient.service                 loaded    active   running Tanium Client
  user-runtime-dir@1001.service        loaded    active   exited  User Runtime Directory /run/user/1001
  user@1001.service                    loaded    active   running User Manager for UID 1001
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent
  vagentx.service                      loaded    active   running service wrapper around vault agent
# wdm.service                          not-found inactive dead    wdm.service
# xdm.service                          not-found inactive dead    xdm.service

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.
160 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State  Recv-Q Send-Q      Local Address:Port  Peer Address:PortProcess                                       
udp   UNCONN 0      0               127.0.0.1:917        0.0.0.0:*    users:(("rpc.statd",pid=1178189,fd=5))       
udp   UNCONN 0      0                 0.0.0.0:4789       0.0.0.0:*                                                 
udp   UNCONN 0      0                 0.0.0.0:20674      0.0.0.0:*    users:(("rpc.statd",pid=1178189,fd=8))       
udp   UNCONN 0      0              11.51.30.2:50052      0.0.0.0:*    users:(("fabcon_server",pid=1186655,fd=14))  
udp   UNCONN 0      0           127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=1086055,fd=13))
udp   UNCONN 0      0                 0.0.0.0:111        0.0.0.0:*    users:(("systemd",pid=1,fd=131))             
udp   UNCONN 0      0                    [::]:14173         [::]:*    users:(("rpc.statd",pid=1178189,fd=10))      
udp   UNCONN 0      0                    [::]:111           [::]:*    users:(("systemd",pid=1,fd=133))             
tcp   LISTEN 0      1024            127.0.0.1:17473      0.0.0.0:*    users:(("TaniumClient",pid=2044073,fd=68))   
tcp   LISTEN 0      16384           127.0.0.1:27519      0.0.0.0:*    users:(("containerd",pid=1327573,fd=13))     
tcp   LISTEN 0      4096        127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=1086055,fd=14))
tcp   LISTEN 0      3               127.0.0.1:2616       0.0.0.0:*    users:(("staticd",pid=85745,fd=11))          
tcp   LISTEN 0      3               127.0.0.1:2601       0.0.0.0:*    users:(("zebra",pid=85733,fd=27))            
tcp   LISTEN 0      3               127.0.0.1:2605       0.0.0.0:*    users:(("bgpd",pid=85738,fd=18))             
tcp   LISTEN 0      4096              0.0.0.0:14001      0.0.0.0:*    users:(("rpc.statd",pid=1178189,fd=9))       
tcp   LISTEN 0      16384           127.0.0.1:9100       0.0.0.0:*    users:(("prometheus-node",pid=1184690,fd=3)) 
tcp   LISTEN 0      4096              0.0.0.0:179        0.0.0.0:*    users:(("bgpd",pid=85738,fd=22))             
tcp   LISTEN 0      128               0.0.0.0:22         0.0.0.0:*    users:(("sshd",pid=1192279,fd=3))            
tcp   LISTEN 0      4096              0.0.0.0:111        0.0.0.0:*    users:(("systemd",pid=1,fd=116))             
tcp   LISTEN 0      16384           127.0.0.1:10248      0.0.0.0:*    users:(("kubelet",pid=1352727,fd=16))        
tcp   LISTEN 0      16384           127.0.0.1:10249      0.0.0.0:*    users:(("kube-proxy",pid=1337894,fd=8))      
tcp   LISTEN 0      16384           127.0.0.1:50059      0.0.0.0:*    users:(("fabcon_server",pid=1186655,fd=18))  
tcp   LISTEN 0      16384           127.0.0.1:50055      0.0.0.0:*    users:(("fabcon_server",pid=1186655,fd=17))  
tcp   LISTEN 0      1024           11.51.30.2:17472      0.0.0.0:*    users:(("TaniumClient",pid=2044073,fd=65))   
tcp   LISTEN 0      16384                   *:10250            *:*    users:(("kubelet",pid=1352727,fd=13))        
tcp   LISTEN 0      16384                   *:10256            *:*    users:(("kube-proxy",pid=1337894,fd=18))     
tcp   LISTEN 0      4096                 [::]:179           [::]:*    users:(("bgpd",pid=85738,fd=23))             
tcp   LISTEN 0      128                  [::]:22            [::]:*    users:(("sshd",pid=1192279,fd=4))            
tcp   LISTEN 0      4096                 [::]:111           [::]:*    users:(("systemd",pid=1,fd=132))             
tcp   LISTEN 0      4096   [::ffff:127.0.0.1]:10514            *:*    users:(("iobricksd",pid=337265,fd=56))       
tcp   LISTEN 0      4096                 [::]:59883         [::]:*    users:(("rpc.statd",pid=1178189,fd=11))      
tcp   LISTEN 0      16384                   *:50057            *:*    users:(("fabcon_server",pid=1186655,fd=16))  
tcp   LISTEN 0      16384                   *:50051            *:*    users:(("fabcon_server",pid=1186655,fd=20))  

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

Include /etc/ssh/sshd_config.d/*.conf

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)
KbdInteractiveAuthentication no

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# be allowed through the KbdInteractiveAuthentication and
# PasswordAuthentication.  Depending on your PAM configuration,
# PAM authentication via KbdInteractiveAuthentication may bypass
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
# and KbdInteractiveAuthentication to \'no\'.
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#Compression delayed
#UseDNS no
#PidFile /run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
PubkeyAuthentication yes
PubkeyAcceptedKeyTypes=+ssh-rsa
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Defaults	use_pty

# This preserves proxy settings from user environments of root
# equivalent users (group sudo)
#Defaults:%sudo env_keep += "http_proxy https_proxy ftp_proxy all_proxy no_proxy"

# This allows running arbitrary commands, but so does ALL, and it means
# different sudoers have their choice of editor respected.
#Defaults:%sudo env_keep += "EDITOR"

# Completely harmless preservation of a user preference.
#Defaults:%sudo env_keep += "GREP_COLOR"

# While you shouldn\'t normally run git as root, you need to with etckeeper
#Defaults:%sudo env_keep += "GIT_AUTHOR_* GIT_COMMITTER_*"

# Per-user preferences; root won\'t have sensible values for them.
#Defaults:%sudo env_keep += "EMAIL DEBEMAIL DEBFULLNAME"

# "sudo scp" or "sudo rsync" should be able to use your SSH agent.
#Defaults:%sudo env_keep += "SSH_AGENT_PID SSH_AUTH_SOCK"

# Ditto for GPG agent
#Defaults:%sudo env_keep += "GPG_AGENT_INFO"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "@include" directives:

@includedir /etc/sudoers.d
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
messagebus:x:104:
systemd-timesync:x:105:
input:x:106:
sgx:x:107:
kvm:x:108:
render:x:109:
lxd:x:110:
tss:x:111:
_ssh:x:112:
fwupd-refresh:x:113:
admin:x:115:
netdev:x:116:
syslog:x:114:
sysop:x:1001:
crontab:x:117:
nslcd:x:118:
tcpdump:x:119:
_lldpd:x:120:
ssl-cert:x:121:
postfix:x:122:
postdrop:x:123:
frrvty:x:124:frr
frr:x:125:
vault:x:999:
host-logging:x:60202:
prometheus:x:62700:
docker:x:1002:
libvirt:x:200:
sugroup:x:1003:
sysgt:x:1004:
no_user:x:998:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_faillock.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth required                  pam_faillock.so preauth
auth  [success=4 default=ignore] pam_unix.so nullok_secure
auth  [success=3 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth [default=die]              pam_faillock.so authfail
auth sufficient                 pam_faillock.so authsucc
auth required                   pam_deny.so
auth required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so
password [success=2 default=ignore] pam_unix.so obscure remember=5 use_authtok try_first_pass 
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
# pam_selinux.so changes the SELinux context of the used TTY and configures
# SELinux in order to transition to the user context with the next execve()
# call.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/polkit-1 <==
#%PAM-1.0

@include common-auth
@include common-account
@include common-password
session       required   pam_env.so readenv=1 user_readenv=0
session       required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-session-noninteractive

==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_14_54_27 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group wheel
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "wheel" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/su-l <==
#%PAM-1.0
auth		include		su
account		include		su
password	include		su
session		optional	pam_keyinit.so force revoke
session		include		su

==> /etc/pam.d/sudo <==
#%PAM-1.0

# Set up user limits from /etc/security/limits.conf.
session    required   pam_limits.so

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0

@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/sudo-i <==
#%PAM-1.0

# Set up user limits from /etc/security/limits.conf.
session    required   pam_limits.so

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0

@include common-auth
@include common-account
@include common-session

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin
messagebus:x:103:104::/nonexistent:/usr/sbin/nologin
systemd-timesync:x:104:105:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin
tss:x:105:111:TPM software stack,,,:/var/lib/tpm:/bin/false
sshd:x:107:65534::/run/sshd:/usr/sbin/nologin
fwupd-refresh:x:108:113:fwupd-refresh user,,,:/run/systemd:/usr/sbin/nologin
syslog:x:106:114::/home/syslog:/usr/sbin/nologin
sysop:x:1001:1001::/home/sysop:/bin/bash
nslcd:x:109:118:nslcd name service LDAP connection daemon,,,:/run/nslcd:/usr/sbin/nologin
tcpdump:x:110:119::/nonexistent:/usr/sbin/nologin
_lldpd:x:111:120::/run/lldpd:/usr/sbin/nologin
postfix:x:112:122::/var/spool/postfix:/usr/sbin/nologin
_rpc:x:113:65534::/run/rpcbind:/usr/sbin/nologin
statd:x:114:65534::/var/lib/nfs:/usr/sbin/nologin
frr:x:115:125:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:999::/home/vault:/bin/false
host-logging:x:60201:60202:Logging account:/home/host-logging:/usr/sbin/nologin
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
sysgt:x:1002:1004::/home/sysgt:/bin/bash
genctl:x:60000:200::/home/genctl:/usr/sbin/nologin
no_user:x:65535:998:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.49.14604.0
aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        addresspool-projection-controller-68b6bb5d98-9djlq                3/3     Running     0             7h1m    11.51.30.206   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        baremetal-action-projection-controller-86c44cc4c7-fqc44           3/3     Running     0             7h1m    11.51.30.68    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        baremetal-spec-projection-controller-5ddcfc5599-4p5pc             3/3     Running     0             7h1m    11.51.30.199   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        baremetal-status-projection-controller-c4d6f57d5-8xsfw            3/3     Running     0             7h1m    11.51.30.191   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        baremetal-vnic-spec-projection-controller-7bf7bcfdd5-s2gg7        3/3     Running     0             7h1m    11.51.30.217   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        baremetal-vnic-status-projection-controller-6b64876f7d-mvqff      3/3     Running     0             7h1m    11.51.30.62    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        cloudinit-projection-controller-7598bd7788-bfsnw                  3/3     Running     0             7h1m    11.51.30.55    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        cluster-network-allocation-projection-controller-5bcd54b7472vvx   3/3     Running     0             7h1m    11.51.30.212   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        clusternetwork-projection-controller-c9ff9bbb8-hspmm              3/3     Running     0             7h1m    11.51.30.218   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        computereservation-spec-projection-controller-775b7458d5-prjld    3/3     Running     0             7h1m    11.51.30.193   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        computereservation-status-projection-controller-796489cb9frg2b2   3/3     Running     0             7h1m    11.51.30.202   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        config-info-projection-controller-65f968bb9-kn6vk                 3/3     Running     0             7h1m    11.51.30.214   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        dedicated-spec-projection-controller-6ffb9c6d85-5xcr5             3/3     Running     0             7h1m    11.51.30.195   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        dedicated-status-projection-controller-78cb8cbd47-wj9bf           3/3     Running     0             7h1m    11.51.30.219   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        export-policy-controller-block-8b56dbfd9-pg7td                    2/2     Running     0             8h      11.51.30.181   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        export-policy-rule-controller-block-78d77c767d-8whvq              2/2     Running     0             8h      11.51.30.179   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        fleetman-cccalc-5b9df699b9-qs5j9                                  2/2     Running     2 (25h ago)   25h     11.51.30.18    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        fleetman-rest-server-79666b84d5-nvfpl                             2/2     Running     1 (25h ago)   25h     11.51.30.16    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        flowlog-projection-controller-56657677bc-gb57b                    3/3     Running     0             7h1m    11.51.30.201   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        fluentbit-logs-z9ft9                                              4/4     Running     0             25h     11.51.30.17    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        fluentd-qradar-ds-qn4js                                           1/1     Running     0             25h     11.51.30.14    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        genctl-etcd-cluster-crn4clmzh7                                    3/3     Running     0             25h     11.51.30.56    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        genctl-extension-server-79b498f4db-hd457                          3/3     Running     0             7h1m    11.51.30.189   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        iam-rest-server-79c45f567d-jd8h6                                  2/2     Running     0             25h     11.51.30.15    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        image-export-projection-controller-6dcc95b9ff-n2nbf               3/3     Running     0             7h1m    11.51.30.197   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        image-spec-projection-controller-7999459dfd-h49dg                 3/3     Running     0             7h1m    11.51.30.204   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        image-status-projection-controller-6bf864bb8f-kd2d7               3/3     Running     0             7h1m    11.51.30.67    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        implicit-vpe-gateway-projection-controller-96b6d8b98-djhh8        3/3     Running     0             7h1m    11.51.30.205   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        instance-action-projection-controller-5f9dfd87cf-cj8z4            3/3     Running     0             7h1m    11.51.30.194   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        instance-status-projection-controller-79b57bb6c-zwrfl             3/3     Running     0             7h1m    11.51.30.208   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        kerberos-kdc-slave-6cc65b6f66-wg2l7                               1/2     Running     0             25h     11.51.30.13    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        keylore-7cbff5bb95-wd7tv                                          2/2     Running     0             25h     11.51.30.9     dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        keylore-fileshare-6d746b5db5-8skcl                                2/2     Running     0             25h     11.51.30.10    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        keylore-fileshare-6d746b5db5-9rhfx                                2/2     Running     0             25h     11.51.30.11    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        keylore-fileshare-6d746b5db5-wrc4s                                2/2     Running     0             25h     11.51.30.12    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        kmip-controller-0                                                 2/2     Running     0             8h      11.51.30.187   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        loadbalancer-projection-controller-75dcdb78bf-pkwhx               3/3     Running     0             7h1m    11.51.30.210   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        netapp-interface-call-controller-5c8f89d4d7-nggrf                 2/2     Running     0             8h      11.51.30.177   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        netapp-storage-migration-controller-5b8ccdd69-775hk               2/2     Running     0             8h      11.51.30.185   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        netapp-volume-deleter-block-6cdb765c96-twcds                      2/2     Running     0             8h      11.51.30.186   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        netapp-volume-provisioner-block-97bb88f5-zt8b7                    2/2     Running     0             8h      11.51.30.182   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        netapp-volume-scheduler-block-5898744b55-zv9zn                    2/2     Running     0             8h      11.51.30.176   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        networkacl-projection-controller-558b4dff9c-sx2vc                 3/3     Running     0             7h1m    11.51.30.203   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        nginx-ingress-controller-57665fdbdb-flshg                         3/3     Running     0             22h     11.51.30.95    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        nginx-ingress-controller-57665fdbdb-z5tbf                         3/3     Running     0             22h     11.51.30.94    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        operator-api-server-8457fdf878-wn4s4                              2/2     Running     0             25h     11.51.30.8     dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        placementgroup-spec-projection-controller-6c5f54796f-7dppc        3/3     Running     0             7h1m    11.51.30.209   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        public-address-range-projection-controller-777b6c9d96-g8x55       3/3     Running     0             7h1m    11.51.30.216   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        reservedip-projection-controller-bd85477bb-rfkqg                  3/3     Running     0             7h1m    11.51.30.70    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        resize-volume-controller-6c5ff7844c-xpfqv                         2/2     Running     0             8h      11.51.30.178   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        routing-table-projection-controller-c68db78c4-wtknb               3/3     Running     0             7h1m    11.51.30.215   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        sdp-manager-85759f59d9-sjw7r                                      2/2     Running     0             25h     11.51.30.53    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        sdp-monitor-rest-server-78b98b47f9-x56x7                          2/2     Running     0             25h     11.51.30.54    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        sdp-worker-6cd5db6758-pdhz8                                       2/2     Running     0             25h     11.51.30.59    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        securitygroup-projection-controller-995b5d858-wc2jz               3/3     Running     0             7h1m    11.51.30.207   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        server-scheduler-546dd89db-chh4m                                  1/1     Running     1 (25h ago)   25h     11.51.30.41    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        share-mount-target-spec-projection-controller-68b685c595-6bzg6    3/3     Running     0             7h1m    11.51.30.198   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        share-mount-target-status-projection-controller-6f4f884785j8phk   3/3     Running     0             7h1m    11.51.30.190   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        share-snapshot-spec-projection-controller-54dfb5cf85-zjxqn        3/3     Running     0             7h1m    11.51.30.65    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        share-snapshot-status-projection-controller-64bf75fd5d-n5mn6      3/3     Running     0             7h1m    11.51.30.196   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        sharereplica-spec-projection-controller-6d6cfc7585-wzzfd          3/3     Running     0             7h1m    11.51.30.69    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        sharereplica-status-projection-controller-76fc86ddc-6vkbq         3/3     Running     0             7h1m    11.51.30.63    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        sharereplicacleanup-spec-projection-controller-789b6ff458-bcp5k   3/3     Running     0             7h1m    11.51.30.192   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        sharereplicacleanup-status-projection-controller-5b46f7cc5g8l22   3/3     Running     0             7h1m    11.51.30.200   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        storage-device-controller-6bfb8bd758-n8hnf                        2/2     Running     0             8h      11.51.30.180   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        storage-node-loss-remediation-controller-7c65fbb65f-p8xxn         2/2     Running     0             8h      11.51.30.184   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        storage-snapshot-copy-controller-5b8f4bf67d-mpqr2                 2/2     Running     0             8h      11.51.30.183   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        subnet-projection-controller-66d567759d-jk7nz                     3/3     Running     0             7h1m    11.51.30.220   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        sysman-etcd-cluster-t8hmrz8bbd                                    3/3     Running     0             25h     11.51.30.57    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        sysman-etcd-cluster-vrwhgd4klq                                    3/3     Running     0             25h     11.51.30.58    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        vdisk-projection-controller-858fcdb4bf-dctpq                      3/3     Running     0             7h1m    11.51.30.64    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        vni-projection-controller-749c8ff57b-rwcnk                        3/3     Running     0             7h1m    11.51.30.211   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        vnic-projection-controller-585bdb7585-h8d7p                       3/3     Running     0             7h1m    11.51.30.66    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        volume-spec-projection-controller-6cb69fc46b-wnpqq                3/3     Running     0             7h1m    11.51.30.35    dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        volume-status-projection-controller-7c85447c7b-7ftv9              3/3     Running     0             7h1m    11.51.30.213   dal1-qz2-sr2-rk204-s30   <none>           <none>
genctl        vpe-projection-controller-64f6654466-kx5s4                        3/3     Running     0             7h1m    11.51.30.61    dal1-qz2-sr2-rk204-s30   <none>           <none>
kube-system   coredns-5756cdd955-2vgqw                                          1/1     Running     0             25h     11.51.30.4     dal1-qz2-sr2-rk204-s30   <none>           <none>
kube-system   coredns-5756cdd955-cq9cn                                          1/1     Running     0             25h     11.51.30.3     dal1-qz2-sr2-rk204-s30   <none>           <none>
kube-system   kube-proxy-2795x                                                  1/1     Running     0             25h     10.22.64.84    dal1-qz2-sr2-rk204-s30   <none>           <none>
razee         featureflagsetld-controller-598b655654-hw9q4                      1/1     Running     0             25h     11.51.30.7     dal1-qz2-sr2-rk204-s30   <none>           <none>
razee         mustachetemplate-controller-6978b88dcc-swxtt                      1/1     Running     0             25h     11.51.30.6     dal1-qz2-sr2-rk204-s30   <none>           <none>
razee         remoteresource-controller-64df867f49-bw5gp                        1/1     Running     0             25h     11.51.30.5     dal1-qz2-sr2-rk204-s30   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
44 profiles are loaded.
27 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /usr/bin/prometheus-node-exporter
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /{,usr/}sbin/dhclient
   cri-containerd.apparmor.d
   fluent-bit-logs
   fluentbit-logs
   genctl-ingress-controller
   lsb_release
   nvidia_modprobe
   nvidia_modprobe//kmod
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
   tcpdump
17 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
0 profiles are in kill mode.
0 profiles are in unconfined mode.
317 processes have profiles defined.
308 processes are in enforce mode.
   /usr/bin/prometheus-node-exporter (1184690) 
   /usr/sbin/sshd (1192279) 
   /usr/sbin/sshd (3277244) /usr/sbin/sshd//sysop
   /usr/sbin/sshd (3277289) /usr/sbin/sshd//sysop
   /usr/sbin/dhclient (1719323) /{,usr/}sbin/dhclient
   /usr/bin/dash (255395) cri-containerd.apparmor.d
   /usr/bin/vault (255417) cri-containerd.apparmor.d
   /netapp-volume-scheduler (255888) cri-containerd.apparmor.d
   /usr/bin/dash (256215) cri-containerd.apparmor.d
   /usr/bin/vault (256239) cri-containerd.apparmor.d
   /netapp-interface-call-controller (256528) cri-containerd.apparmor.d
   /usr/bin/dash (256823) cri-containerd.apparmor.d
   /usr/bin/dash (256837) cri-containerd.apparmor.d
   /usr/bin/vault (256888) cri-containerd.apparmor.d
   /usr/bin/vault (256891) cri-containerd.apparmor.d
   /export-policy-rule-controller-block (257403) cri-containerd.apparmor.d
   /resize-volume-controller (257842) cri-containerd.apparmor.d
   /usr/bin/dash (257884) cri-containerd.apparmor.d
   /usr/bin/vault (257915) cri-containerd.apparmor.d
   /usr/bin/dash (258117) cri-containerd.apparmor.d
   /usr/bin/vault (258183) cri-containerd.apparmor.d
   /storage-device-controller (258477) cri-containerd.apparmor.d
   /usr/bin/dash (258508) cri-containerd.apparmor.d
   /usr/bin/vault (258570) cri-containerd.apparmor.d
   /netapp-volume-provisioner-block (258993) cri-containerd.apparmor.d
   /usr/bin/dash (258999) cri-containerd.apparmor.d
   /usr/bin/vault (259027) cri-containerd.apparmor.d
   /usr/bin/dash (259529) cri-containerd.apparmor.d
   /export-policy-controller-block (259535) cri-containerd.apparmor.d
   /usr/bin/vault (259584) cri-containerd.apparmor.d
   /storage-snapshot-copy-controller (259848) cri-containerd.apparmor.d
   /usr/bin/dash (260054) cri-containerd.apparmor.d
   /usr/bin/vault (260081) cri-containerd.apparmor.d
   /storage-node-loss-remediation-controller (260286) cri-containerd.apparmor.d
   /usr/bin/dash (260428) cri-containerd.apparmor.d
   /usr/bin/vault (260454) cri-containerd.apparmor.d
   /netapp-storage-migration-controller (260625) cri-containerd.apparmor.d
   /netapp-volume-deleter-block (260908) cri-containerd.apparmor.d
   /usr/bin/dash (299271) cri-containerd.apparmor.d
   /usr/bin/vault (299287) cri-containerd.apparmor.d
   /kmip-controller (299542) cri-containerd.apparmor.d
   /usr/bin/dash (1216331) cri-containerd.apparmor.d
   /usr/bin/vault (1216363) cri-containerd.apparmor.d
   /bin/healthcheck (1216402) cri-containerd.apparmor.d
   /bin/api-extension-server (1216835) cri-containerd.apparmor.d
   /usr/bin/dash (1221938) cri-containerd.apparmor.d
   /usr/bin/vault (1222034) cri-containerd.apparmor.d
   /bin/healthcheck (1222103) cri-containerd.apparmor.d
   /bin/share-mount-target-status-projection-controller (1222176) cri-containerd.apparmor.d
   /usr/bin/dash (1222557) cri-containerd.apparmor.d
   /usr/bin/vault (1222596) cri-containerd.apparmor.d
   /bin/healthcheck (1222625) cri-containerd.apparmor.d
   /bin/baremetal-status-projection-controller (1222760) cri-containerd.apparmor.d
   /usr/bin/dash (1225541) cri-containerd.apparmor.d
   /usr/bin/vault (1225598) cri-containerd.apparmor.d
   /bin/healthcheck (1225715) cri-containerd.apparmor.d
   /bin/sharereplicacleanup-spec-projection-controller (1225880) cri-containerd.apparmor.d
   /usr/bin/dash (1226192) cri-containerd.apparmor.d
   /usr/bin/vault (1226239) cri-containerd.apparmor.d
   /bin/healthcheck (1226392) cri-containerd.apparmor.d
   /bin/computereservation-spec-projection-controller (1226537) cri-containerd.apparmor.d
   /usr/bin/dash (1229585) cri-containerd.apparmor.d
   /usr/bin/dash (1229657) cri-containerd.apparmor.d
   /usr/bin/vault (1229802) cri-containerd.apparmor.d
   /usr/bin/vault (1229808) cri-containerd.apparmor.d
   /bin/healthcheck (1229982) cri-containerd.apparmor.d
   /bin/healthcheck (1229989) cri-containerd.apparmor.d
   /bin/sharereplicacleanup-status-projection-controller (1230290) cri-containerd.apparmor.d
   /bin/baremetal-spec-projection-controller (1230336) cri-containerd.apparmor.d
   /usr/bin/dash (1230606) cri-containerd.apparmor.d
   /usr/bin/dash (1230620) cri-containerd.apparmor.d
   /usr/bin/vault (1230774) cri-containerd.apparmor.d
   /bin/healthcheck (1230952) cri-containerd.apparmor.d
   /usr/bin/vault (1230971) cri-containerd.apparmor.d
   /bin/healthcheck (1231078) cri-containerd.apparmor.d
   /bin/computereservation-status-projection-controller (1231140) cri-containerd.apparmor.d
   /bin/share-snapshot-status-projection-controller (1231288) cri-containerd.apparmor.d
   /usr/bin/dash (1231852) cri-containerd.apparmor.d
   /usr/bin/dash (1231858) cri-containerd.apparmor.d
   /usr/bin/vault (1232038) cri-containerd.apparmor.d
   /usr/bin/vault (1232039) cri-containerd.apparmor.d
   /bin/healthcheck (1232206) cri-containerd.apparmor.d
   /bin/healthcheck (1232232) cri-containerd.apparmor.d
   /bin/dedicated-spec-projection-controller (1232431) cri-containerd.apparmor.d
   /bin/flowlog-projection-controller (1232452) cri-containerd.apparmor.d
   /usr/bin/dash (1232879) cri-containerd.apparmor.d
   /usr/bin/dash (1232894) cri-containerd.apparmor.d
   /usr/bin/vault (1233027) cri-containerd.apparmor.d
   /usr/bin/vault (1233028) cri-containerd.apparmor.d
   /bin/healthcheck (1233169) cri-containerd.apparmor.d
   /bin/healthcheck (1233196) cri-containerd.apparmor.d
   /bin/instance-action-projection-controller (1233436) cri-containerd.apparmor.d
   /bin/networkacl-projection-controller (1233442) cri-containerd.apparmor.d
   /usr/bin/dash (1234764) cri-containerd.apparmor.d
   /usr/bin/dash (1234866) cri-containerd.apparmor.d
   /usr/bin/vault (1235029) cri-containerd.apparmor.d
   /bin/healthcheck (1235304) cri-containerd.apparmor.d
   /usr/bin/vault (1235312) cri-containerd.apparmor.d
   /bin/healthcheck (1235483) cri-containerd.apparmor.d
   /bin/image-spec-projection-controller (1235616) cri-containerd.apparmor.d
   /bin/implicit-vpe-gateway-projection-controller (1235660) cri-containerd.apparmor.d
   /usr/bin/dash (1236892) cri-containerd.apparmor.d
   /usr/bin/vault (1237015) cri-containerd.apparmor.d
   /bin/healthcheck (1237198) cri-containerd.apparmor.d
   /bin/addresspool-projection-controller (1237380) cri-containerd.apparmor.d
   /usr/bin/dash (1237927) cri-containerd.apparmor.d
   /usr/bin/dash (1237944) cri-containerd.apparmor.d
   /usr/bin/dash (1237955) cri-containerd.apparmor.d
   /usr/bin/vault (1238084) cri-containerd.apparmor.d
   /usr/bin/vault (1238120) cri-containerd.apparmor.d
   /usr/bin/vault (1238144) cri-containerd.apparmor.d
   /bin/healthcheck (1238247) cri-containerd.apparmor.d
   /bin/healthcheck (1238256) cri-containerd.apparmor.d
   /bin/healthcheck (1238262) cri-containerd.apparmor.d
   /bin/instance-status-projection-controller (1238555) cri-containerd.apparmor.d
   /bin/securitygroup-projection-controller (1238569) cri-containerd.apparmor.d
   /bin/share-mount-target-spec-projection-controller (1238582) cri-containerd.apparmor.d
   /usr/bin/dash (1240075) cri-containerd.apparmor.d
   /usr/bin/dash (1240081) cri-containerd.apparmor.d
   /usr/bin/dash (1240087) cri-containerd.apparmor.d
   /usr/bin/vault (1240224) cri-containerd.apparmor.d
   /usr/bin/vault (1240258) cri-containerd.apparmor.d
   /usr/bin/vault (1240272) cri-containerd.apparmor.d
   /bin/healthcheck (1240380) cri-containerd.apparmor.d
   /bin/healthcheck (1240424) cri-containerd.apparmor.d
   /bin/healthcheck (1240430) cri-containerd.apparmor.d
   /bin/placementgroup-spec-projection-controller (1240733) cri-containerd.apparmor.d
   /bin/loadbalancer-projection-controller (1240739) cri-containerd.apparmor.d
   /bin/image-export-projection-controller (1240764) cri-containerd.apparmor.d
   /usr/bin/dash (1241582) cri-containerd.apparmor.d
   /usr/bin/vault (1241670) cri-containerd.apparmor.d
   /bin/healthcheck (1241807) cri-containerd.apparmor.d
   /bin/cluster-network-allocation-projection-controller (1242108) cri-containerd.apparmor.d
   /usr/bin/dash (1242462) cri-containerd.apparmor.d
   /usr/bin/dash (1242499) cri-containerd.apparmor.d
   /usr/bin/vault (1242534) cri-containerd.apparmor.d
   /usr/bin/vault (1242585) cri-containerd.apparmor.d
   /bin/healthcheck (1242628) cri-containerd.apparmor.d
   /bin/healthcheck (1242661) cri-containerd.apparmor.d
   /bin/volume-status-projection-controller (1242864) cri-containerd.apparmor.d
   /bin/vni-projection-controller (1242873) cri-containerd.apparmor.d
   /usr/bin/dash (1243436) cri-containerd.apparmor.d
   /usr/bin/dash (1243448) cri-containerd.apparmor.d
   /usr/bin/vault (1243493) cri-containerd.apparmor.d
   /usr/bin/vault (1243498) cri-containerd.apparmor.d
   /bin/healthcheck (1243593) cri-containerd.apparmor.d
   /bin/healthcheck (1243611) cri-containerd.apparmor.d
   /bin/config-info-projection-controller (1243774) cri-containerd.apparmor.d
   /bin/routing-table-projection-controller (1243783) cri-containerd.apparmor.d
   /usr/bin/dash (1247013) cri-containerd.apparmor.d
   /usr/bin/dash (1247026) cri-containerd.apparmor.d
   /usr/bin/dash (1247050) cri-containerd.apparmor.d
   /usr/bin/vault (1247172) cri-containerd.apparmor.d
   /usr/bin/vault (1247245) cri-containerd.apparmor.d
   /usr/bin/vault (1247248) cri-containerd.apparmor.d
   /bin/healthcheck (1247374) cri-containerd.apparmor.d
   /bin/healthcheck (1247439) cri-containerd.apparmor.d
   /bin/healthcheck (1247445) cri-containerd.apparmor.d
   /bin/clusternetwork-projection-controller (1247703) cri-containerd.apparmor.d
   /bin/dedicated-status-projection-controller (1247826) cri-containerd.apparmor.d
   /bin/public-address-range-projection-controller (1247849) cri-containerd.apparmor.d
   /usr/bin/dash (1248437) cri-containerd.apparmor.d
   /usr/bin/dash (1248443) cri-containerd.apparmor.d
   /usr/bin/vault (1248509) cri-containerd.apparmor.d
   /usr/bin/vault (1248513) cri-containerd.apparmor.d
   /bin/healthcheck (1248616) cri-containerd.apparmor.d
   /bin/healthcheck (1248626) cri-containerd.apparmor.d
   /bin/baremetal-vnic-spec-projection-controller (1248766) cri-containerd.apparmor.d
   /bin/volume-spec-projection-controller (1248773) cri-containerd.apparmor.d
   /usr/bin/dash (1249048) cri-containerd.apparmor.d
   /usr/bin/vault (1249150) cri-containerd.apparmor.d
   /bin/healthcheck (1249254) cri-containerd.apparmor.d
   /bin/subnet-projection-controller (1249532) cri-containerd.apparmor.d
   /usr/bin/dash (1251151) cri-containerd.apparmor.d
   /usr/bin/vault (1251204) cri-containerd.apparmor.d
   /bin/healthcheck (1251276) cri-containerd.apparmor.d
   /bin/cloudinit-projection-controller (1251499) cri-containerd.apparmor.d
   /usr/bin/dash (1253364) cri-containerd.apparmor.d
   /usr/bin/dash (1253370) cri-containerd.apparmor.d
   /usr/bin/vault (1253483) cri-containerd.apparmor.d
   /usr/bin/vault (1253518) cri-containerd.apparmor.d
   /bin/healthcheck (1253605) cri-containerd.apparmor.d
   /bin/healthcheck (1253656) cri-containerd.apparmor.d
   /bin/sharereplica-status-projection-controller (1253767) cri-containerd.apparmor.d
   /bin/vpe-projection-controller (1253779) cri-containerd.apparmor.d
   /usr/bin/dash (1255198) cri-containerd.apparmor.d
   /usr/bin/dash (1255206) cri-containerd.apparmor.d
   /usr/bin/vault (1255337) cri-containerd.apparmor.d
   /usr/bin/vault (1255338) cri-containerd.apparmor.d
   /bin/healthcheck (1255488) cri-containerd.apparmor.d
   /bin/healthcheck (1255505) cri-containerd.apparmor.d
   /bin/vdisk-projection-controller (1255700) cri-containerd.apparmor.d
   /bin/baremetal-vnic-status-projection-controller (1255715) cri-containerd.apparmor.d
   /usr/bin/dash (1256610) cri-containerd.apparmor.d
   /usr/bin/dash (1256705) cri-containerd.apparmor.d
   /usr/bin/vault (1256714) cri-containerd.apparmor.d
   /usr/bin/vault (1256785) cri-containerd.apparmor.d
   /bin/healthcheck (1256806) cri-containerd.apparmor.d
   /bin/healthcheck (1256867) cri-containerd.apparmor.d
   /bin/vnic-projection-controller (1256927) cri-containerd.apparmor.d
   /bin/share-snapshot-spec-projection-controller (1256990) cri-containerd.apparmor.d
   /usr/bin/dash (1257858) cri-containerd.apparmor.d
   /usr/bin/vault (1257934) cri-containerd.apparmor.d
   /bin/healthcheck (1258003) cri-containerd.apparmor.d
   /bin/image-status-projection-controller (1258124) cri-containerd.apparmor.d
   /usr/bin/dash (1259644) cri-containerd.apparmor.d
   /usr/bin/dash (1259668) cri-containerd.apparmor.d
   /usr/bin/vault (1259704) cri-containerd.apparmor.d
   /usr/bin/vault (1259740) cri-containerd.apparmor.d
   /bin/healthcheck (1259788) cri-containerd.apparmor.d
   /bin/healthcheck (1259806) cri-containerd.apparmor.d
   /bin/sharereplica-spec-projection-controller (1259921) cri-containerd.apparmor.d
   /bin/baremetal-action-projection-controller (1259933) cri-containerd.apparmor.d
   /usr/bin/dash (1260197) cri-containerd.apparmor.d
   /usr/bin/vault (1260227) cri-containerd.apparmor.d
   /bin/healthcheck (1260269) cri-containerd.apparmor.d
   /bin/reservedip-projection-controller (1260339) cri-containerd.apparmor.d
   /coredns (1352347) cri-containerd.apparmor.d
   /coredns (1352583) cri-containerd.apparmor.d
   /usr/local/bin/node (1360521) cri-containerd.apparmor.d
   /usr/local/bin/node (1360601) cri-containerd.apparmor.d
   /usr/local/bin/node (1360680) cri-containerd.apparmor.d
   /usr/bin/dash (1380641) cri-containerd.apparmor.d
   /usr/bin/dash (1380654) cri-containerd.apparmor.d
   /usr/bin/vault (1380674) cri-containerd.apparmor.d
   /usr/bin/vault (1380686) cri-containerd.apparmor.d
   /usr/bin/sudo (1381256) cri-containerd.apparmor.d
   /usr/bin/bash (1381271) cri-containerd.apparmor.d
   /usr/bin/sudo (1381273) cri-containerd.apparmor.d
   /opt/ibm/go/watcher (1381275) cri-containerd.apparmor.d
   /usr/local/sbin/krb5kdc (1381301) cri-containerd.apparmor.d
   /bin/operator-api-server (1381346) cri-containerd.apparmor.d
   /bin/keylore-fileshare (1381390) cri-containerd.apparmor.d
   /bin/keylore-fileshare (1381449) cri-containerd.apparmor.d
   /usr/bin/dash (1381466) cri-containerd.apparmor.d
   /usr/bin/vault (1381516) cri-containerd.apparmor.d
   /usr/bin/dash (1381533) cri-containerd.apparmor.d
   /usr/bin/vault (1381556) cri-containerd.apparmor.d
   /bin/keylore-blockstorage (1381593) cri-containerd.apparmor.d
   /usr/bin/dash (1381647) cri-containerd.apparmor.d
   /bin/keylore-fileshare (1381670) cri-containerd.apparmor.d
   /usr/bin/vault (1381685) cri-containerd.apparmor.d
   /usr/bin/dash (1381734) cri-containerd.apparmor.d
   /usr/bin/vault (1381748) cri-containerd.apparmor.d
   /usr/local/sbin/kpropd (1389642) cri-containerd.apparmor.d
   /usr/bin/ruby (1391202) cri-containerd.apparmor.d
   /usr/bin/ruby (1391248) cri-containerd.apparmor.d
   /usr/bin/dash (1392142) cri-containerd.apparmor.d
   /usr/bin/vault (1392157) cri-containerd.apparmor.d
   /iam-rest-server (1392200) cri-containerd.apparmor.d
   /usr/bin/dash (1393210) cri-containerd.apparmor.d
   /usr/bin/vault (1393224) cri-containerd.apparmor.d
   /usr/bin/dash (1394402) cri-containerd.apparmor.d
   /usr/bin/vault (1394434) cri-containerd.apparmor.d
   /bin/ssf-validator-fluentbit (1394466) cri-containerd.apparmor.d
   /fluent-bit/bin/fluent-bit (1394704) cri-containerd.apparmor.d
   /synthetics/datagen (1394755) cri-containerd.apparmor.d
   /usr/bin/dash (1394823) cri-containerd.apparmor.d
   /usr/bin/vault (1394837) cri-containerd.apparmor.d
   /usr/bin/dash (1408883) cri-containerd.apparmor.d
   /usr/bin/vault (1408943) cri-containerd.apparmor.d
   /usr/bin/dash (1409284) cri-containerd.apparmor.d
   /usr/bin/vault (1409307) cri-containerd.apparmor.d
   /usr/bin/bash (1411279) cri-containerd.apparmor.d
   /usr/bin/bash (1411494) cri-containerd.apparmor.d
   /bin/fleetman-rest-server (1411807) cri-containerd.apparmor.d
   /bin/fleetman-cccalc (1412183) cri-containerd.apparmor.d
   /server-scheduler (1412596) cri-containerd.apparmor.d
   /usr/local/bin/etcd (1413583) cri-containerd.apparmor.d
   /usr/bin/dash (1413698) cri-containerd.apparmor.d
   /usr/bin/vault (1413785) cri-containerd.apparmor.d
   /bin/etcd-sidecar-ssf (1413832) cri-containerd.apparmor.d
   /usr/local/bin/etcd (1415464) cri-containerd.apparmor.d
   /usr/bin/dash (1415560) cri-containerd.apparmor.d
   /usr/sbin/sdp-manager (1415594) cri-containerd.apparmor.d
   /usr/bin/vault (1415660) cri-containerd.apparmor.d
   /bin/etcd-sidecar-ssf (1415717) cri-containerd.apparmor.d
   /usr/bin/dash (1419975) cri-containerd.apparmor.d
   /usr/bin/vault (1420004) cri-containerd.apparmor.d
   /usr/bin/bash (1420160) cri-containerd.apparmor.d
   /usr/sbin/sdp-worker (1420180) cri-containerd.apparmor.d
   /usr/local/bin/etcd (1421112) cri-containerd.apparmor.d
   /usr/bin/dash (1421174) cri-containerd.apparmor.d
   /usr/bin/vault (1421219) cri-containerd.apparmor.d
   /bin/etcd-sidecar-ssf (1421249) cri-containerd.apparmor.d
   /usr/sbin/sdp-monitor-rest-server (3278020) cri-containerd.apparmor.d
   /usr/bin/dash (4026288) cri-containerd.apparmor.d
   /usr/bin/vault (4026307) cri-containerd.apparmor.d
   /bin/ssf-validator-nginx (4026352) cri-containerd.apparmor.d
   /usr/bin/dumb-init (4027220) cri-containerd.apparmor.d
   /nginx-ingress-controller (4027234) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4027590) cri-containerd.apparmor.d
   /usr/bin/dash (4037169) cri-containerd.apparmor.d
   /usr/bin/vault (4037214) cri-containerd.apparmor.d
   /bin/ssf-validator-nginx (4037247) cri-containerd.apparmor.d
   /usr/bin/dumb-init (4037309) cri-containerd.apparmor.d
   /nginx-ingress-controller (4037335) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037603) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037604) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037605) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037606) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037607) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037819) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037829) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037830) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037831) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037832) cri-containerd.apparmor.d
   /usr/local/nginx/sbin/nginx (4037833) cri-containerd.apparmor.d
9 processes are in complain mode.
   /usr/lib/frr/bgpd (85738) 
   /usr/lib/frr/staticd (85745) 
   /usr/lib/frr/watchfrr (85720) 
   /usr/lib/frr/zebra (85733) 
   /usr/local/fabcon/fabcon_server (1186655) 
   /usr/local/iobricks/iobricksd (337265) 
   /usr/local/skydive/skydive (335712) 
   /usr/local/skydive/skydive (335747) 
   /usr/local/skydive/skydive (335814) 
0 processes are unconfined but have a profile defined.
0 processes are in mixed mode.
0 processes are in kill mode.
'
<i>2024-12-17 17:36:56.784095</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.908816</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.908802</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.908810</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:56.908813</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.908836</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:36:56.909495</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:36:56.909535</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.909619</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.909610</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.909614</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:56.909617</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.909636</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'control'}
<i>2024-12-17 17:36:56.909655</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:57.183539</td>
    <td>0.24</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.183523</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.183532</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:57.183535</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.183560</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:57.183580</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:57.183600</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:57.183604</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml for test validation
<i>2024-12-17 17:36:57.216357</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:57.216399</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:57.420232</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
	"version":	"2",
	"profiles":	{
		"/etc/hostos-monitoring/plugins.d/configuration-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/ipset-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/iptables-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/liveness":	"enforce",
		"/etc/hostos-monitoring/plugins.d/smartnic-monitoring":	"enforce",
		"/usr/bin/prometheus-node-exporter":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-client.action":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-helper":	"enforce",
		"/usr/lib/connman/scripts/dhclient-script":	"enforce",
		"/usr/sbin/dropbear":	"enforce",
		"/usr/sbin/hostos-monitoring":	"enforce",
		"/usr/sbin/sshd":	"enforce",
		"/usr/sbin/sshd//DEFAULT":	"enforce",
		"/usr/sbin/sshd//root":	"enforce",
		"/usr/sbin/sshd//sysop":	"enforce",
		"/{,usr/}sbin/dhclient":	"enforce",
		"cri-containerd.apparmor.d":	"enforce",
		"fluent-bit-logs":	"enforce",
		"fluentbit-logs":	"enforce",
		"genctl-ingress-controller":	"enforce",
		"lsb_release":	"enforce",
		"nvidia_modprobe":	"enforce",
		"nvidia_modprobe//kmod":	"enforce",
		"sysdig-agent":	"enforce",
		"sysdig-agent-kmodule":	"enforce",
		"sysdig-agent-kmodule//ln_profile":	"enforce",
		"tcpdump":	"enforce",
		"/usr/lib/frr/bgpd":	"complain",
		"/usr/lib/frr/staticd":	"complain",
		"/usr/lib/frr/watchfrr":	"complain",
		"/usr/lib/frr/zebra":	"complain",
		"/usr/local/fabcon/fabcon_server":	"complain",
		"/usr/local/iobricks/bessctl/bessctl":	"complain",
		"/usr/local/iobricks/iobricksd":	"complain",
		"/usr/local/iobricks/monitor/monitor":	"complain",
		"/usr/local/iobricks/monitor/monitor_datapath":	"complain",
		"/usr/local/iobricks/monitor/monitor_fmt":	"complain",
		"/usr/local/iobricks/monitor/monitor_vpe_enable":	"complain",
		"/usr/local/skydive/skydive":	"complain",
		"/usr/sbin/mlx-setup.sh":	"complain",
		"confined_user":	"complain",
		"docker-extended":	"complain",
		"fluentd-logs":	"complain",
		"fluentd-qradar":	"complain"
	},
	"processes":	{
		"/bin/addresspool-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237380",
				"status":	"enforce"
			}],
		"/bin/api-extension-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1216835",
				"status":	"enforce"
			}],
		"/bin/baremetal-action-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259933",
				"status":	"enforce"
			}],
		"/bin/baremetal-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230336",
				"status":	"enforce"
			}],
		"/bin/baremetal-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222760",
				"status":	"enforce"
			}],
		"/bin/baremetal-vnic-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248766",
				"status":	"enforce"
			}],
		"/bin/baremetal-vnic-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255715",
				"status":	"enforce"
			}],
		"/bin/cloudinit-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1251499",
				"status":	"enforce"
			}],
		"/bin/cluster-network-allocation-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242108",
				"status":	"enforce"
			}],
		"/bin/clusternetwork-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247703",
				"status":	"enforce"
			}],
		"/bin/computereservation-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1226537",
				"status":	"enforce"
			}],
		"/bin/computereservation-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231140",
				"status":	"enforce"
			}],
		"/bin/config-info-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243774",
				"status":	"enforce"
			}],
		"/bin/dedicated-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232431",
				"status":	"enforce"
			}],
		"/bin/dedicated-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247826",
				"status":	"enforce"
			}],
		"/bin/etcd-sidecar-ssf":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1413832",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415717",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1421249",
				"status":	"enforce"
			}],
		"/bin/fleetman-cccalc":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1412183",
				"status":	"enforce"
			}],
		"/bin/fleetman-rest-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1411807",
				"status":	"enforce"
			}],
		"/bin/flowlog-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232452",
				"status":	"enforce"
			}],
		"/bin/healthcheck":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1216402",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222103",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222625",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1225715",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1226392",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229982",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229989",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230952",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231078",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232206",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232232",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233169",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233196",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235304",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235483",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237198",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238247",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238256",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238262",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240380",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240424",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240430",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1241807",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242628",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242661",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243593",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243611",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247374",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247439",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247445",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248616",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248626",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1249254",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1251276",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253605",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253656",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255488",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255505",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256806",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256867",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1258003",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259788",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259806",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1260269",
				"status":	"enforce"
			}],
		"/bin/image-export-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240764",
				"status":	"enforce"
			}],
		"/bin/image-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235616",
				"status":	"enforce"
			}],
		"/bin/image-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1258124",
				"status":	"enforce"
			}],
		"/bin/implicit-vpe-gateway-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235660",
				"status":	"enforce"
			}],
		"/bin/instance-action-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233436",
				"status":	"enforce"
			}],
		"/bin/instance-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238555",
				"status":	"enforce"
			}],
		"/bin/keylore-blockstorage":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381593",
				"status":	"enforce"
			}],
		"/bin/keylore-fileshare":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381390",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381449",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381670",
				"status":	"enforce"
			}],
		"/bin/loadbalancer-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240739",
				"status":	"enforce"
			}],
		"/bin/networkacl-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233442",
				"status":	"enforce"
			}],
		"/bin/operator-api-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381346",
				"status":	"enforce"
			}],
		"/bin/placementgroup-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240733",
				"status":	"enforce"
			}],
		"/bin/public-address-range-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247849",
				"status":	"enforce"
			}],
		"/bin/reservedip-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1260339",
				"status":	"enforce"
			}],
		"/bin/routing-table-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243783",
				"status":	"enforce"
			}],
		"/bin/securitygroup-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238569",
				"status":	"enforce"
			}],
		"/bin/share-mount-target-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238582",
				"status":	"enforce"
			}],
		"/bin/share-mount-target-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222176",
				"status":	"enforce"
			}],
		"/bin/share-snapshot-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256990",
				"status":	"enforce"
			}],
		"/bin/share-snapshot-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231288",
				"status":	"enforce"
			}],
		"/bin/sharereplica-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259921",
				"status":	"enforce"
			}],
		"/bin/sharereplica-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253767",
				"status":	"enforce"
			}],
		"/bin/sharereplicacleanup-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1225880",
				"status":	"enforce"
			}],
		"/bin/sharereplicacleanup-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230290",
				"status":	"enforce"
			}],
		"/bin/ssf-validator-fluentbit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394466",
				"status":	"enforce"
			}],
		"/bin/ssf-validator-nginx":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4026352",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037247",
				"status":	"enforce"
			}],
		"/bin/subnet-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1249532",
				"status":	"enforce"
			}],
		"/bin/vdisk-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255700",
				"status":	"enforce"
			}],
		"/bin/vni-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242873",
				"status":	"enforce"
			}],
		"/bin/vnic-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256927",
				"status":	"enforce"
			}],
		"/bin/volume-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248773",
				"status":	"enforce"
			}],
		"/bin/volume-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242864",
				"status":	"enforce"
			}],
		"/bin/vpe-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253779",
				"status":	"enforce"
			}],
		"/coredns":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1352347",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1352583",
				"status":	"enforce"
			}],
		"/export-policy-controller-block":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259535",
				"status":	"enforce"
			}],
		"/export-policy-rule-controller-block":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"257403",
				"status":	"enforce"
			}],
		"/fluent-bit/bin/fluent-bit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394704",
				"status":	"enforce"
			}],
		"/iam-rest-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1392200",
				"status":	"enforce"
			}],
		"/kmip-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"299542",
				"status":	"enforce"
			}],
		"/netapp-interface-call-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256528",
				"status":	"enforce"
			}],
		"/netapp-storage-migration-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260625",
				"status":	"enforce"
			}],
		"/netapp-volume-deleter-block":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260908",
				"status":	"enforce"
			}],
		"/netapp-volume-provisioner-block":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258993",
				"status":	"enforce"
			}],
		"/netapp-volume-scheduler":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"255888",
				"status":	"enforce"
			}],
		"/nginx-ingress-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4027234",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037335",
				"status":	"enforce"
			}],
		"/opt/ibm/go/watcher":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381275",
				"status":	"enforce"
			}],
		"/resize-volume-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"257842",
				"status":	"enforce"
			}],
		"/server-scheduler":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1412596",
				"status":	"enforce"
			}],
		"/storage-device-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258477",
				"status":	"enforce"
			}],
		"/storage-node-loss-remediation-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260286",
				"status":	"enforce"
			}],
		"/storage-snapshot-copy-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259848",
				"status":	"enforce"
			}],
		"/synthetics/datagen":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394755",
				"status":	"enforce"
			}],
		"/usr/bin/bash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381271",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1411279",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1411494",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1420160",
				"status":	"enforce"
			}],
		"/usr/bin/dash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"255395",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256215",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256823",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256837",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"257884",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258117",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258508",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258999",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259529",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260054",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260428",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"299271",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1216331",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1221938",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222557",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1225541",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1226192",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229585",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229657",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230606",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230620",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231852",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231858",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232879",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232894",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1234764",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1234866",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1236892",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237927",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237944",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237955",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240075",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240081",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240087",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1241582",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242462",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242499",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243436",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243448",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247013",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247026",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247050",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248437",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248443",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1249048",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1251151",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253364",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253370",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255198",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255206",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256610",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256705",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1257858",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259644",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259668",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1260197",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380641",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380654",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381466",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381533",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381647",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381734",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1392142",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1393210",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394402",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394823",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1408883",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1409284",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1413698",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415560",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1419975",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1421174",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4026288",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037169",
				"status":	"enforce"
			}],
		"/usr/bin/dumb-init":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4027220",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037309",
				"status":	"enforce"
			}],
		"/usr/bin/prometheus-node-exporter":	[{
				"profile":	"/usr/bin/prometheus-node-exporter",
				"pid":	"1184690",
				"status":	"enforce"
			}],
		"/usr/bin/ruby":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1391202",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1391248",
				"status":	"enforce"
			}],
		"/usr/bin/sudo":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381256",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381273",
				"status":	"enforce"
			}],
		"/usr/bin/vault":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"255417",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256239",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256888",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256891",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"257915",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258183",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258570",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259027",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259584",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260081",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260454",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"299287",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1216363",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222034",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222596",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1225598",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1226239",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229802",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229808",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230774",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230971",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232038",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232039",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233027",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233028",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235029",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235312",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237015",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238084",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238120",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238144",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240224",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240258",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240272",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1241670",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242534",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242585",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243493",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243498",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247172",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247245",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247248",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248509",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248513",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1249150",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1251204",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253483",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253518",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255337",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255338",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256714",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256785",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1257934",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259704",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259740",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1260227",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380674",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380686",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381516",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381556",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381685",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381748",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1392157",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1393224",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394434",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394837",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1408943",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1409307",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1413785",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415660",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1420004",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1421219",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4026307",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037214",
				"status":	"enforce"
			}],
		"/usr/local/bin/etcd":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1413583",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415464",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1421112",
				"status":	"enforce"
			}],
		"/usr/local/bin/node":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1360521",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1360601",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1360680",
				"status":	"enforce"
			}],
		"/usr/local/nginx/sbin/nginx":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4027590",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037603",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037604",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037605",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037606",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037607",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037819",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037829",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037830",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037831",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037832",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037833",
				"status":	"enforce"
			}],
		"/usr/local/sbin/kpropd":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1389642",
				"status":	"enforce"
			}],
		"/usr/local/sbin/krb5kdc":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381301",
				"status":	"enforce"
			}],
		"/usr/sbin/dhclient":	[{
				"profile":	"/{,usr/}sbin/dhclient",
				"pid":	"1719323",
				"status":	"enforce"
			}],
		"/usr/sbin/sdp-manager":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415594",
				"status":	"enforce"
			}],
		"/usr/sbin/sdp-monitor-rest-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"3278221",
				"status":	"enforce"
			}],
		"/usr/sbin/sdp-worker":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1420180",
				"status":	"enforce"
			}],
		"/usr/sbin/sshd":	[{
				"profile":	"/usr/sbin/sshd",
				"pid":	"1192279",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"3277244",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"3277289",
				"status":	"enforce"
			}],
		"/usr/lib/frr/bgpd":	[{
				"profile":	"/usr/lib/frr/bgpd",
				"pid":	"85738",
				"status":	"complain"
			}],
		"/usr/lib/frr/staticd":	[{
				"profile":	"/usr/lib/frr/staticd",
				"pid":	"85745",
				"status":	"complain"
			}],
		"/usr/lib/frr/watchfrr":	[{
				"profile":	"/usr/lib/frr/watchfrr",
				"pid":	"85720",
				"status":	"complain"
			}],
		"/usr/lib/frr/zebra":	[{
				"profile":	"/usr/lib/frr/zebra",
				"pid":	"85733",
				"status":	"complain"
			}],
		"/usr/local/fabcon/fabcon_server":	[{
				"profile":	"/usr/local/fabcon/fabcon_server",
				"pid":	"1186655",
				"status":	"complain"
			}],
		"/usr/local/iobricks/iobricksd":	[{
				"profile":	"/usr/local/iobricks/iobricksd",
				"pid":	"337265",
				"status":	"complain"
			}],
		"/usr/local/skydive/skydive":	[{
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"335712",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"335747",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"335814",
				"status":	"complain"
			}]
	}
}
'
<i>2024-12-17 17:36:57.426655</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 845, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 1226, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1542 chars]e"}}' != '{"pr[333 chars]", "/usr/bin/prometheus-node-exporter": "enfor[1489 chars]e"}}'
Diff is 4207 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:57.426740</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:57.426849</td>
    <td>0.31</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.426839</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.426844</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:57.426846</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.426869</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:36:57.496873</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.496898</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:36:57.496901</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:57.496935</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:57.496963</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:57.496967</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml for test validation
<i>2024-12-17 17:36:57.529022</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:57.529069</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:57.735910</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
	"version":	"2",
	"profiles":	{
		"/etc/hostos-monitoring/plugins.d/configuration-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/ipset-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/iptables-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/liveness":	"enforce",
		"/etc/hostos-monitoring/plugins.d/smartnic-monitoring":	"enforce",
		"/usr/bin/prometheus-node-exporter":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-client.action":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-helper":	"enforce",
		"/usr/lib/connman/scripts/dhclient-script":	"enforce",
		"/usr/sbin/dropbear":	"enforce",
		"/usr/sbin/hostos-monitoring":	"enforce",
		"/usr/sbin/sshd":	"enforce",
		"/usr/sbin/sshd//DEFAULT":	"enforce",
		"/usr/sbin/sshd//root":	"enforce",
		"/usr/sbin/sshd//sysop":	"enforce",
		"/{,usr/}sbin/dhclient":	"enforce",
		"cri-containerd.apparmor.d":	"enforce",
		"fluent-bit-logs":	"enforce",
		"fluentbit-logs":	"enforce",
		"genctl-ingress-controller":	"enforce",
		"lsb_release":	"enforce",
		"nvidia_modprobe":	"enforce",
		"nvidia_modprobe//kmod":	"enforce",
		"sysdig-agent":	"enforce",
		"sysdig-agent-kmodule":	"enforce",
		"sysdig-agent-kmodule//ln_profile":	"enforce",
		"tcpdump":	"enforce",
		"/usr/lib/frr/bgpd":	"complain",
		"/usr/lib/frr/staticd":	"complain",
		"/usr/lib/frr/watchfrr":	"complain",
		"/usr/lib/frr/zebra":	"complain",
		"/usr/local/fabcon/fabcon_server":	"complain",
		"/usr/local/iobricks/bessctl/bessctl":	"complain",
		"/usr/local/iobricks/iobricksd":	"complain",
		"/usr/local/iobricks/monitor/monitor":	"complain",
		"/usr/local/iobricks/monitor/monitor_datapath":	"complain",
		"/usr/local/iobricks/monitor/monitor_fmt":	"complain",
		"/usr/local/iobricks/monitor/monitor_vpe_enable":	"complain",
		"/usr/local/skydive/skydive":	"complain",
		"/usr/sbin/mlx-setup.sh":	"complain",
		"confined_user":	"complain",
		"docker-extended":	"complain",
		"fluentd-logs":	"complain",
		"fluentd-qradar":	"complain"
	},
	"processes":	{
		"/bin/addresspool-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237380",
				"status":	"enforce"
			}],
		"/bin/api-extension-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1216835",
				"status":	"enforce"
			}],
		"/bin/baremetal-action-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259933",
				"status":	"enforce"
			}],
		"/bin/baremetal-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230336",
				"status":	"enforce"
			}],
		"/bin/baremetal-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222760",
				"status":	"enforce"
			}],
		"/bin/baremetal-vnic-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248766",
				"status":	"enforce"
			}],
		"/bin/baremetal-vnic-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255715",
				"status":	"enforce"
			}],
		"/bin/cloudinit-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1251499",
				"status":	"enforce"
			}],
		"/bin/cluster-network-allocation-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242108",
				"status":	"enforce"
			}],
		"/bin/clusternetwork-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247703",
				"status":	"enforce"
			}],
		"/bin/computereservation-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1226537",
				"status":	"enforce"
			}],
		"/bin/computereservation-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231140",
				"status":	"enforce"
			}],
		"/bin/config-info-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243774",
				"status":	"enforce"
			}],
		"/bin/dedicated-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232431",
				"status":	"enforce"
			}],
		"/bin/dedicated-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247826",
				"status":	"enforce"
			}],
		"/bin/etcd-sidecar-ssf":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1413832",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415717",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1421249",
				"status":	"enforce"
			}],
		"/bin/fleetman-cccalc":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1412183",
				"status":	"enforce"
			}],
		"/bin/fleetman-rest-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1411807",
				"status":	"enforce"
			}],
		"/bin/flowlog-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232452",
				"status":	"enforce"
			}],
		"/bin/healthcheck":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1216402",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222103",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222625",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1225715",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1226392",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229982",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229989",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230952",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231078",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232206",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232232",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233169",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233196",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235304",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235483",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237198",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238247",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238256",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238262",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240380",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240424",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240430",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1241807",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242628",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242661",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243593",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243611",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247374",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247439",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247445",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248616",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248626",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1249254",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1251276",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253605",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253656",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255488",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255505",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256806",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256867",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1258003",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259788",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259806",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1260269",
				"status":	"enforce"
			}],
		"/bin/image-export-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240764",
				"status":	"enforce"
			}],
		"/bin/image-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235616",
				"status":	"enforce"
			}],
		"/bin/image-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1258124",
				"status":	"enforce"
			}],
		"/bin/implicit-vpe-gateway-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235660",
				"status":	"enforce"
			}],
		"/bin/instance-action-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233436",
				"status":	"enforce"
			}],
		"/bin/instance-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238555",
				"status":	"enforce"
			}],
		"/bin/keylore-blockstorage":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381593",
				"status":	"enforce"
			}],
		"/bin/keylore-fileshare":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381390",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381449",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381670",
				"status":	"enforce"
			}],
		"/bin/loadbalancer-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240739",
				"status":	"enforce"
			}],
		"/bin/networkacl-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233442",
				"status":	"enforce"
			}],
		"/bin/operator-api-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381346",
				"status":	"enforce"
			}],
		"/bin/placementgroup-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240733",
				"status":	"enforce"
			}],
		"/bin/public-address-range-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247849",
				"status":	"enforce"
			}],
		"/bin/reservedip-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1260339",
				"status":	"enforce"
			}],
		"/bin/routing-table-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243783",
				"status":	"enforce"
			}],
		"/bin/securitygroup-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238569",
				"status":	"enforce"
			}],
		"/bin/share-mount-target-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238582",
				"status":	"enforce"
			}],
		"/bin/share-mount-target-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222176",
				"status":	"enforce"
			}],
		"/bin/share-snapshot-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256990",
				"status":	"enforce"
			}],
		"/bin/share-snapshot-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231288",
				"status":	"enforce"
			}],
		"/bin/sharereplica-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259921",
				"status":	"enforce"
			}],
		"/bin/sharereplica-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253767",
				"status":	"enforce"
			}],
		"/bin/sharereplicacleanup-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1225880",
				"status":	"enforce"
			}],
		"/bin/sharereplicacleanup-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230290",
				"status":	"enforce"
			}],
		"/bin/ssf-validator-fluentbit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394466",
				"status":	"enforce"
			}],
		"/bin/ssf-validator-nginx":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4026352",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037247",
				"status":	"enforce"
			}],
		"/bin/subnet-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1249532",
				"status":	"enforce"
			}],
		"/bin/vdisk-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255700",
				"status":	"enforce"
			}],
		"/bin/vni-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242873",
				"status":	"enforce"
			}],
		"/bin/vnic-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256927",
				"status":	"enforce"
			}],
		"/bin/volume-spec-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248773",
				"status":	"enforce"
			}],
		"/bin/volume-status-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242864",
				"status":	"enforce"
			}],
		"/bin/vpe-projection-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253779",
				"status":	"enforce"
			}],
		"/coredns":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1352347",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1352583",
				"status":	"enforce"
			}],
		"/export-policy-controller-block":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259535",
				"status":	"enforce"
			}],
		"/export-policy-rule-controller-block":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"257403",
				"status":	"enforce"
			}],
		"/fluent-bit/bin/fluent-bit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394704",
				"status":	"enforce"
			}],
		"/iam-rest-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1392200",
				"status":	"enforce"
			}],
		"/kmip-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"299542",
				"status":	"enforce"
			}],
		"/netapp-interface-call-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256528",
				"status":	"enforce"
			}],
		"/netapp-storage-migration-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260625",
				"status":	"enforce"
			}],
		"/netapp-volume-deleter-block":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260908",
				"status":	"enforce"
			}],
		"/netapp-volume-provisioner-block":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258993",
				"status":	"enforce"
			}],
		"/netapp-volume-scheduler":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"255888",
				"status":	"enforce"
			}],
		"/nginx-ingress-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4027234",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037335",
				"status":	"enforce"
			}],
		"/opt/ibm/go/watcher":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381275",
				"status":	"enforce"
			}],
		"/resize-volume-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"257842",
				"status":	"enforce"
			}],
		"/server-scheduler":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1412596",
				"status":	"enforce"
			}],
		"/storage-device-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258477",
				"status":	"enforce"
			}],
		"/storage-node-loss-remediation-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260286",
				"status":	"enforce"
			}],
		"/storage-snapshot-copy-controller":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259848",
				"status":	"enforce"
			}],
		"/synthetics/datagen":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394755",
				"status":	"enforce"
			}],
		"/usr/bin/bash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381271",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1411279",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1411494",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1420160",
				"status":	"enforce"
			}],
		"/usr/bin/dash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"255395",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256215",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256823",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256837",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"257884",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258117",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258508",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258999",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259529",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260054",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260428",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"299271",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1216331",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1221938",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222557",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1225541",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1226192",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229585",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229657",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230606",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230620",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231852",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1231858",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232879",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232894",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1234764",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1234866",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1236892",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237927",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237944",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237955",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240075",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240081",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240087",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1241582",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242462",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242499",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243436",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243448",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247013",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247026",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247050",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248437",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248443",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1249048",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1251151",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253364",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253370",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255198",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255206",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256610",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256705",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1257858",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259644",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259668",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1260197",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380641",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380654",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381466",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381533",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381647",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381734",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1392142",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1393210",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394402",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394823",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1408883",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1409284",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1413698",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415560",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1419975",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1421174",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4026288",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037169",
				"status":	"enforce"
			}],
		"/usr/bin/dumb-init":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4027220",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037309",
				"status":	"enforce"
			}],
		"/usr/bin/prometheus-node-exporter":	[{
				"profile":	"/usr/bin/prometheus-node-exporter",
				"pid":	"1184690",
				"status":	"enforce"
			}],
		"/usr/bin/ruby":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1391202",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1391248",
				"status":	"enforce"
			}],
		"/usr/bin/sudo":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381256",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381273",
				"status":	"enforce"
			}],
		"/usr/bin/vault":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"255417",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256239",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256888",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"256891",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"257915",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258183",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"258570",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259027",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"259584",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260081",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"260454",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"299287",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1216363",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222034",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1222596",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1225598",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1226239",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229802",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1229808",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230774",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1230971",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232038",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1232039",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233027",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1233028",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235029",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1235312",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1237015",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238084",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238120",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1238144",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240224",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240258",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1240272",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1241670",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242534",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1242585",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243493",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1243498",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247172",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247245",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1247248",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248509",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1248513",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1249150",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1251204",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253483",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1253518",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255337",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1255338",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256714",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1256785",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1257934",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259704",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1259740",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1260227",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380674",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1380686",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381516",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381556",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381685",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381748",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1392157",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1393224",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394434",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1394837",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1408943",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1409307",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1413785",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415660",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1420004",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1421219",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4026307",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037214",
				"status":	"enforce"
			}],
		"/usr/local/bin/etcd":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1413583",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415464",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1421112",
				"status":	"enforce"
			}],
		"/usr/local/bin/node":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1360521",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1360601",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1360680",
				"status":	"enforce"
			}],
		"/usr/local/nginx/sbin/nginx":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4027590",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037603",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037604",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037605",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037606",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037607",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037819",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037829",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037830",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037831",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037832",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"4037833",
				"status":	"enforce"
			}],
		"/usr/local/sbin/kpropd":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1389642",
				"status":	"enforce"
			}],
		"/usr/local/sbin/krb5kdc":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1381301",
				"status":	"enforce"
			}],
		"/usr/sbin/dhclient":	[{
				"profile":	"/{,usr/}sbin/dhclient",
				"pid":	"1719323",
				"status":	"enforce"
			}],
		"/usr/sbin/sdp-manager":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1415594",
				"status":	"enforce"
			}],
		"/usr/sbin/sdp-monitor-rest-server":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"3278318",
				"status":	"enforce"
			}],
		"/usr/sbin/sdp-worker":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1420180",
				"status":	"enforce"
			}],
		"/usr/sbin/sshd":	[{
				"profile":	"/usr/sbin/sshd",
				"pid":	"1192279",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"3277244",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"3277289",
				"status":	"enforce"
			}],
		"/usr/lib/frr/bgpd":	[{
				"profile":	"/usr/lib/frr/bgpd",
				"pid":	"85738",
				"status":	"complain"
			}],
		"/usr/lib/frr/staticd":	[{
				"profile":	"/usr/lib/frr/staticd",
				"pid":	"85745",
				"status":	"complain"
			}],
		"/usr/lib/frr/watchfrr":	[{
				"profile":	"/usr/lib/frr/watchfrr",
				"pid":	"85720",
				"status":	"complain"
			}],
		"/usr/lib/frr/zebra":	[{
				"profile":	"/usr/lib/frr/zebra",
				"pid":	"85733",
				"status":	"complain"
			}],
		"/usr/local/fabcon/fabcon_server":	[{
				"profile":	"/usr/local/fabcon/fabcon_server",
				"pid":	"1186655",
				"status":	"complain"
			}],
		"/usr/local/iobricks/iobricksd":	[{
				"profile":	"/usr/local/iobricks/iobricksd",
				"pid":	"337265",
				"status":	"complain"
			}],
		"/usr/local/skydive/skydive":	[{
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"335712",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"335747",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"335814",
				"status":	"complain"
			}]
	}
}
'
<i>2024-12-17 17:36:57.741468</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 845, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 1226, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1542 chars]e"}}' != '{"pr[333 chars]", "/usr/bin/prometheus-node-exporter": "enfor[1489 chars]e"}}'
Diff is 4207 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:57.741547</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.881624</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.881611</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.881618</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:57.881620</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.881654</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.881671</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.930982</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:36:57.933378</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
messagebus
systemd-timesync
input
sgx
kvm
render
lxd
tss
_ssh
fwupd-refresh
admin
netdev
syslog
sysop
crontab
nslcd
tcpdump
_lldpd
ssl-cert
postfix
postdrop
frrvty
frr
vault
host-logging
prometheus
docker
libvirt
sugroup
sysgt
no_user
'
<i>2024-12-17 17:36:57.933447</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.933528</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.933518</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.933523</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:57.933525</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.933556</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.933574</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.979085</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:36:57.980960</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin
messagebus::/nonexistent:/usr/sbin/nologin
systemd-timesync:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
sshd::/run/sshd:/usr/sbin/nologin
fwupd-refresh:fwupd-refresh user,,,:/run/systemd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
nslcd:nslcd name service LDAP connection daemon,,,:/run/nslcd:/usr/sbin/nologin
tcpdump::/nonexistent:/usr/sbin/nologin
_lldpd::/run/lldpd:/usr/sbin/nologin
postfix::/var/spool/postfix:/usr/sbin/nologin
_rpc::/run/rpcbind:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
host-logging:Logging account:/home/host-logging:/usr/sbin/nologin
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
genctl::/home/genctl:/usr/sbin/nologin
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:36:57.981056</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:58.109653</td>
    <td>0.33</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:58.109640</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:58.109647</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:58.109650</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:58.109708</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.109756</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.109771</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:36:58.109843</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.109855</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:36:58.110583</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.110599</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:36:58.110687</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.110699</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.110713</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:36:58.110780</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.110792</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release6 : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release6
<i>2024-12-17 17:36:58.110954</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.110967</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:36:58.112112</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.112131</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:36:58.112423</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:58.430258</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:36:58.432513</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root    0 Dec 17 17:36 cron.allow
drwxr-x--- 2 root root   80 Dec 17 17:36 cron.d
drwxr-x--- 2 root root  260 Dec 17 17:36 cron.daily
drwxr-x--- 2 root root  180 Dec 17 17:36 cron.hourly
drwxr-x--- 2 root root   40 Dec 17 17:36 cron.monthly
drwxr-x--- 2 root root   40 Dec 17 17:36 cron.weekly
-rw-r----- 1 root root 1229 Dec 17 17:36 crontab
'
<i>2024-12-17 17:36:58.432528</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:36:58.435967</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:58.435982</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:36:58.436006</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:58.436154</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:58.436143</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:58.436148</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:58.436151</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:58.436175</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:36:58.437853</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
'
<i>2024-12-17 17:36:58.437868</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:36:58.439633</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:58.439661</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release6/control : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release6/control
<i>2024-12-17 17:36:58.439680</i> <b style="color:rgb(0 133 115);">[INFO]</b> shell_artifacts/cronjobs/crontab_data/release6/control personality folder not present for comparison
<i>2024-12-17 17:36:58.439692</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:58.439785</td>
    <td>7.23</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:58.439775</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:58.439780</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:36:58.439783</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:58.439802</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:36:58.441898</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:58.441911</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:36:58.442490</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:58.442499</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:00.460423</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:00.460448</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:37:00.460481</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:00.460485</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:00.460489</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:03.645620</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
.
good
'
<i>2024-12-17 17:37:03.645646</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:37:03.645653</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:37:03.647786</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:03.647802</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:05.666448</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:05.666564</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.806631</td>
    <td>0.22</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.806617</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.806625</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:05.806628</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.806665</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.806669</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.806672</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:06.023031</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

Linked to: nmnode2-02-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:37:06.023161</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:06.149791</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:06.149778</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:06.149786</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:06.149788</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:06.149822</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:06.149826</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:06.149829</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:06.206115</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:37:06.206216</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:06.206335</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:06.206324</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:06.206329</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:06.206331</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:06.206379</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:06.206382</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:06.206386</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:06.262813</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:37:06.262911</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:06.387388</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:06.387375</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:06.387382</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:06.387385</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:06.387428</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:06.387431</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:06.387434</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:06.393262</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:37:06.393316</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:06.393398</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:06.393389</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:06.393394</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:06.393396</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:06.393425</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:06.393429</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:06.393432</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:06.399210</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:37:06.399256</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:06.399328</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:06.399318</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:06.399323</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:06.399325</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:06.399354</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:06.399358</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:06.399361</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_1535/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:06.404843</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:37:06.404890</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:06.527415</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s30 (control)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:06.527402</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:06.527409</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:10 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:29 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:12 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:39 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:50 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:12 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:40 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:07 UTC, STATUS=success)

<i>2024-12-17 17:37:06.527412</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:06.527435</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:37:06.529857</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.XXXXXXXXXjhxYeP
'
<i>2024-12-17 17:37:06.529871</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.XXXXXXXXXjhxYeP | grep "publickey ssh-rsa"
<i>2024-12-17 17:37:06.531763</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:37:06.531812</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:54.945346</td>
    <td>1.31</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:54.945331</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:54.945339</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:54.945342</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:54.945401</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.945406</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.945409</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:56.257640</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 8 packets, 500 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     786K  105M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2      10M   21G KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3     786K  105M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4      10M   21G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5      12M   22G HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    49196 3090K KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    49196 3090K KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3    4211K   18G KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4    5384K   18G HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    1116K  117M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    5740K 3074M KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3    1103K  116M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4    1103K  116M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5    1103K  116M DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
6    1103K  116M DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
7        0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
8        0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0           
9        0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0           
10       0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0           
11       0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
12   1103K  116M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 2 packets, 144 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      682  345K KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      617  341K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      682  345K KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      617  341K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5      993  502K HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      812 56704 KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4      936 63688 HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2     5429  375K KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5     5429  375K HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION                                                                  
  acpid.service                        loaded    inactive dead    ACPI event daemon                                                            
# am-utils.service                     not-found inactive dead    am-utils.service                                                             
# apache2.service                      not-found inactive dead    apache2.service                                                              
  apparmor.service                     loaded    active   exited  AppArmor initialization                                                      
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities                                       
# apt-daily.service                    masked    inactive dead    apt-daily.service                                                            
# atd.service                          not-found inactive dead    atd.service                                                                  
  auditd.service                       loaded    active   running Security Auditing Service                                                    
  autofs.service                       loaded    active   running Automounts filesystems on demand                                             
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats                      
  blk-availability.service             loaded    active   exited  Availability of block devices                                                
  ceph-crash.service                   loaded    active   running Ceph crash dump collector                                                    
# citadel.service                      not-found inactive dead    citadel.service                                                              
  cld-blockagent-server.service        loaded    active   running Genesis block-agent Service                                                  
  cld-coalesce-agent-nr.service        loaded    active   running Genesis coalesce-agent-nr Service                                            
  cld-coalesce-agent.service           loaded    active   running Genesis coalesce-agent Service                                               
  cld-cos-transfer-agent-nr.service    loaded    active   running Genesis cos-transfer-agent-nr Service                                        
  cld-cos-transfer-agent.service       loaded    active   running Genesis cos-transfer-agent Service                                           
  cld-net-block-agent.service          loaded    active   running Genesis net-block-agent Service                                              
  cloudnet-gobgp.service               loaded    inactive dead    gobgpd service                                                               
  containerd.service                   loaded    active   running containerd container runtime                                                 
# courier-ldap.service                 not-found inactive dead    courier-ldap.service                                                         
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service                                                      
# courier-mta.service                  not-found inactive dead    courier-mta.service                                                          
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service                                                      
# courier-pop.service                  not-found inactive dead    courier-pop.service                                                          
  cron.service                         loaded    active   running Regular background program processing daemon                                 
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service                                                          
  dbus.service                         loaded    active   running D-Bus System Message Bus                                                     
# display-manager.service              not-found inactive dead    display-manager.service                                                      
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon                                                   
  docker.service                       loaded    active   running Docker Application Container Engine                                          
# dovecot.service                      not-found inactive dead    dovecot.service                                                              
  ebtables.service                     loaded    active   exited  ebtables ruleset management                                                  
  emergency.service                    loaded    inactive dead    Emergency Shell                                                              
# exim4.service                        not-found inactive dead    exim4.service                                                                
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service                                    
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.      
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor                                                    
# fcoe.service                         not-found inactive dead    fcoe.service                                                                 
# firewalld.service                    not-found inactive dead    firewalld.service                                                            
  frr.service                          loaded    active   running FRRouting                                                                    
  fstrim.service                       loaded    inactive dead    Discard unused blocks                                                        
# gdm3.service                         not-found inactive dead    gdm3.service                                                                 
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available                      
  getty@tty1.service                   loaded    active   running Getty on tty1                                                                
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes                                    
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service                                                 
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service                                                          
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service                                                          
  hmonagent-mlx.service                loaded    active   running Genesis Fabric-3 Health Monitor Agent                                        
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device          
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service                                                       
# iscsi.service                        not-found inactive dead    iscsi.service                                                                
# iscsid.service                       not-found inactive dead    iscsid.service                                                               
# kdm.service                          not-found inactive dead    kdm.service                                                                  
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service                                            
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec                                            
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system                           
# keylime_agent.service                masked    inactive dead    keylime_agent.service                                                        
  kmod-static-nodes.service            loaded    active   exited  Create list of required static device nodes for the current kernel           
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service                                                   
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service                                                             
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster                                                 
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent                                           
  libvirt-guests.service               loaded    active   exited  Suspend/Resume Running libvirt Guests                                        
  libvirtd.service                     loaded    active   running Virtualization daemon                                                        
  lldpd.service                        loaded    active   running LLDP daemon                                                                  
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service                                                      
  lvm2-lvmetad.service                 loaded    active   running LVM2 metadata daemon                                                         
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon                                                             
  lvm2-monitor.service                 loaded    active   exited  Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service                                                 
# masqmail.service                     not-found inactive dead    masqmail.service                                                             
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.                      
  motd-news.service                    loaded    inactive dead    Message of the Day                                                           
  mst.service                          loaded    active   exited  LSB: mst                                                                     
  nessusagent.service                  loaded    active   running The Nessus Client Agent                                                      
# network.service                      not-found inactive dead    network.service                                                              
  networking.service                   loaded    inactive dead    Raise network interfaces                                                     
# nfs-blkmap.service                   not-found inactive dead    nfs-blkmap.service                                                           
  nfs-config.service                   loaded    inactive dead    Preprocess NFS configuration                                                 
# nfs-server.service                   not-found inactive dead    nfs-server.service                                                           
  nfs-utils.service                    loaded    active   exited  NFS server and client services                                               
  nftables.service                     loaded    active   exited  nftables                                                                     
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon                                                  
# nullmailer.service                   not-found inactive dead    nullmailer.service                                                           
  ondemand.service                     loaded    inactive dead    Set the CPU Frequency Scaling governor                                       
  osqueryd.service                     loaded    active   running The osquery Daemon                                                           
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service                                                   
# plymouth-start.service               not-found inactive dead    plymouth-start.service                                                       
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics                                      
  qemu-kvm.service                     loaded    active   exited  QEMU KVM preparation - module, ksm, hugepages                                
  rbdmap.service                       loaded    active   exited  Map RBD devices                                                              
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility                                                  
  rclone-agent@rclone-agent.service    loaded    inactive dead    rclone wrapper agent service                                                 
  rclone-validate.service              loaded    inactive dead    Rclone config validator service                                              
  rescue.service                       loaded    inactive dead    Rescue Shell                                                                 
  rpc-gssd.service                     loaded    active   running RPC security service for NFS client and server                               
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart                                                
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.                                      
  rpcbind.service                      loaded    inactive dead    RPC bind portmap service                                                     
  rsync.service                        loaded    inactive dead    fast remote file copy program daemon                                         
  rsyslog.service                      loaded    active   running System Logging Service                                                       
# sendmail.service                     not-found inactive dead    sendmail.service                                                             
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0                                                        
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1                                                        
# set-hostname.service                 not-found inactive dead    set-hostname.service                                                         
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service                                                           
  skydive.service                      loaded    active   running Skydive                                                                      
# slapd.service                        not-found inactive dead    slapd.service                                                                
# slim.service                         not-found inactive dead    slim.service                                                                 
  ssh.service                          loaded    active   running OpenBSD Secure Shell server                                                  
# sssd.service                         not-found inactive dead    sssd.service                                                                 
  strongswan.service                   loaded    active   running strongSwan IPsec IKEv1/IKEv2 daemon using ipsec.conf                         
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console                                        
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall                                            
  systemd-binfmt.service               loaded    inactive dead    Set Up Additional Binary Formats                                             
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device                                             
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status                                    
  systemd-hwdb-update.service          loaded    inactive dead    Rebuild Hardware Database                                                    
  systemd-initctl.service              loaded    inactive dead    /dev/initctl Compatibility Daemon                                            
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage                                          
  systemd-journald.service             loaded    active   running Journal Service                                                              
  systemd-logind.service               loaded    active   running Login Service                                                                
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk                                        
  systemd-machined.service             loaded    active   running Virtual Machine and Container Registration Service                           
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules                                                          
  systemd-networkd-wait-online.service loaded    active   exited  Wait for Network to be Configured                                            
  systemd-networkd.service             loaded    active   running Network Service                                                              
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed                                                        
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems                                         
  systemd-resolved.service             loaded    active   running Network Name Resolution                                                      
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables                                                       
# systemd-sysusers.service             not-found inactive dead    systemd-sysusers.service                                                     
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization                                                 
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories                                             
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev                                           
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories                                        
  systemd-udev-trigger.service         loaded    active   exited  udev Coldplug all Devices                                                    
  systemd-udevd.service                loaded    active   running udev Kernel Device Manager                                                   
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service                                                  
  systemd-update-utmp-runlevel.service loaded    inactive dead    Update UTMP about System Runlevel Changes                                    
  systemd-update-utmp.service          loaded    active   exited  Update UTMP about System Boot/Shutdown                                       
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions                                                         
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service                                               
  taniumclient.service                 loaded    active   running Tanium Client                                                                
  user@1000.service                    loaded    active   running User Manager for UID 1000                                                    
  uuidd.service                        loaded    active   running Daemon for generating UUIDs                                                  
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent                                      
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent                                       
  vagentx.service                      loaded    active   running service wrapper around vault agent                                           
  virtlockd.service                    loaded    inactive dead    Virtual machine lock manager                                                 
  virtlogd.service                     loaded    inactive dead    Virtual machine log manager                                                  
# wdm.service                          not-found inactive dead    wdm.service                                                                  
# xdm.service                          not-found inactive dead    xdm.service                                                                  
# xencommons.service                   not-found inactive dead    xencommons.service                                                           
# xendomains.service                   not-found inactive dead    xendomains.service                                                           
# ypbind.service                       not-found inactive dead    ypbind.service                                                               

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.

159 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State   Recv-Q  Send-Q         Local Address:Port      Peer Address:Port                                                                                  
udp   UNCONN  0       0                    0.0.0.0:39209          0.0.0.0:*      users:(("rpc.statd",pid=142827,fd=8))                                          
udp   UNCONN  0       0                 11.51.32.2:50052          0.0.0.0:*      users:(("fabcon_server",pid=152806,fd=14))                                     
udp   UNCONN  0       0              127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=103796,fd=12))                                   
udp   UNCONN  0       0                    0.0.0.0:500            0.0.0.0:*      users:(("charon",pid=13648,fd=14))                                             
udp   UNCONN  0       0                  127.0.0.1:963            0.0.0.0:*      users:(("rpc.statd",pid=142827,fd=5))                                          
udp   UNCONN  0       0                    0.0.0.0:4500           0.0.0.0:*      users:(("charon",pid=13648,fd=15))                                             
udp   UNCONN  0       0                    0.0.0.0:4789           0.0.0.0:*                                                                                     
udp   UNCONN  0       0                       [::]:48417             [::]:*      users:(("rpc.statd",pid=142827,fd=10))                                         
udp   UNCONN  0       0                          *:500                  *:*      users:(("charon",pid=13648,fd=12))                                             
udp   UNCONN  0       0                          *:4500                 *:*      users:(("charon",pid=13648,fd=13))                                             
tcp   LISTEN  0       16384              127.0.0.1:27519          0.0.0.0:*      users:(("containerd",pid=88097,fd=14))                                         
tcp   LISTEN  0       128                  0.0.0.0:32319          0.0.0.0:*      users:(("rpc.statd",pid=142827,fd=9))                                          
tcp   LISTEN  0       1024              11.51.32.2:17472          0.0.0.0:*      users:(("TaniumClient",pid=130385,fd=65))                                      
tcp   LISTEN  0       1024               127.0.0.1:17473          0.0.0.0:*      users:(("TaniumClient",pid=130385,fd=67))                                      
tcp   LISTEN  0       16384              127.0.0.1:50055          0.0.0.0:*      users:(("fabcon_server",pid=152806,fd=17))                                     
tcp   LISTEN  0       16384              127.0.0.1:10248          0.0.0.0:*      users:(("kubelet",pid=117483,fd=14))                                           
tcp   LISTEN  0       16384              127.0.0.1:10249          0.0.0.0:*      users:(("kube-proxy",pid=100588,fd=8))                                         
tcp   LISTEN  0       3                  127.0.0.1:2601           0.0.0.0:*      users:(("zebra",pid=190981,fd=27))                                             
tcp   LISTEN  0       16384              127.0.0.1:50059          0.0.0.0:*      users:(("fabcon_server",pid=152806,fd=18))                                     
tcp   LISTEN  0       16384              127.0.0.1:9100           0.0.0.0:*      users:(("prometheus-node",pid=150793,fd=3))                                    
tcp   LISTEN  0       3                  127.0.0.1:2605           0.0.0.0:*      users:(("bgpd",pid=190986,fd=18))                                              
tcp   LISTEN  0       128                  0.0.0.0:179            0.0.0.0:*      users:(("bgpd",pid=190986,fd=22))                                              
tcp   LISTEN  0       128            127.0.0.53%lo:53             0.0.0.0:*      users:(("systemd-resolve",pid=103796,fd=13))                                   
tcp   LISTEN  0       128                  0.0.0.0:22             0.0.0.0:*      users:(("sshd",pid=160000,fd=3))                                               
tcp   LISTEN  0       3                  127.0.0.1:2616           0.0.0.0:*      users:(("staticd",pid=190993,fd=11))                                           
tcp   LISTEN  0       128                     [::]:15839             [::]:*      users:(("rpc.statd",pid=142827,fd=11))                                         
tcp   LISTEN  0       16384                      *:50051                *:*      users:(("fabcon_server",pid=152806,fd=27))                                     
tcp   LISTEN  0       16384                      *:50057                *:*      users:(("fabcon_server",pid=152806,fd=16))                                     
tcp   LISTEN  0       16384                      *:10250                *:*      users:(("kubelet",pid=117483,fd=26))                                           
tcp   LISTEN  0       16384                      *:10256                *:*      users:(("kube-proxy",pid=100588,fd=18))                                        
tcp   LISTEN  0       128       [::ffff:127.0.0.1]:10514                *:*      users:(("iobricksd",pid=66176,fd=47))                                          
tcp   LISTEN  0       128                     [::]:179               [::]:*      users:(("bgpd",pid=190986,fd=23))                                              
tcp   LISTEN  0       128                     [::]:22                [::]:*      users:(("sshd",pid=160000,fd=4))                                               

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==
#	$OpenBSD: sshd_config,v 1.101 2017/03/14 07:19:07 djm Exp $

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/bin:/bin:/usr/sbin:/sbin

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# PasswordAuthentication.  Depending on your PAM configuration,
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#UseLogin no
#Compression delayed
#UseDNS no
#PidFile /var/run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "#include" directives:

#includedir /etc/sudoers.d
Defaults use_pty
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
lxd:x:104:
input:x:105:
crontab:x:106:
messagebus:x:107:
ssh:x:108:
admin:x:110:
netdev:x:111:
uuidd:x:109:
syslog:x:112:
sysop:x:1000:
rdma:x:113:
ceph:x:64045:
nslcd:x:114:
_lldpd:x:115:
kvm:x:116:
libvirt:x:200:
libvirt-qemu:x:64055:libvirt-qemu
libvirt-dnsmasq:x:118:
docker:x:999:
ssl-cert:x:119:
postfix:x:120:
postdrop:x:121:
tss:x:122:
frrvty:x:123:frr
frr:x:124:
vault:x:998:
prometheus:x:62700:
systemd-timesync:x:997:
sugroup:x:1001:
sysgt:x:1002:
no_user:x:996:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_tally2.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth  [success=2 default=ignore] pam_unix.so nullok_secure
auth  [success=1 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth  required                   pam_deny.so
auth  required                   pam_tally2.so onerr=fail audit silent deny=5 unlock_time=900
auth  required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so remember=5
password [success=2 default=ignore] pam_unix.so obscure use_authtok try_first_pass sha512
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

session optional /usr/lib/pam_osquery.so

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows root logins except on tty\'s listed in /etc/securetty
# (Replaces the `CONSOLE\' setting from login.defs)
#
# With the default control of this module:
#   [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die]
# root will not be prompted for a password on insecure lines.
# if an invalid username is entered, a password is prompted (but login
# will eventually be rejected)
#
# You can change it to a "requisite" module if you think root may mis-type
# her login and should not be prompted for a password in that case. But
# this will leave the system as vulnerable to user enumeration attacks.
#
# You can change it to a "required" module if you think it permits to
# guess valid user names of your system (invalid user names are considered
# as possibly being root on insecure lines), but root passwords may be
# communicated over insecure lines.
auth [success=ok new_authtok_reqd=ok ignore=ignore user_unknown=bad default=die] pam_securetty.so

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/polkit-1 <==
#%PAM-1.0

@include common-auth
@include common-account
@include common-password
session       required   pam_env.so readenv=1 user_readenv=0
session       required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-session-noninteractive

==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_04_15_01 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group root
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "root" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/sudo <==
#%PAM-1.0

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/systemd-user <==
# This file is part of systemd.
#
# Used by systemd --user instances.

@include common-account

session  required pam_selinux.so close
session  required pam_selinux.so nottys open
session  required pam_loginuid.so
session  required pam_limits.so
@include common-session-noninteractive
session optional pam_systemd.so

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd:x:103:65534::/var/lib/lxd/:/bin/false
messagebus:x:105:107::/nonexistent:/usr/sbin/nologin
sshd:x:106:65534::/run/sshd:/usr/sbin/nologin
uuidd:x:107:109::/run/uuidd:/usr/sbin/nologin
syslog:x:109:112::/home/syslog:/usr/sbin/nologin
sysop:x:1000:1000::/home/sysop:/bin/bash
ceph:x:64045:64045:Ceph storage service:/var/lib/ceph:/usr/sbin/nologin
nslcd:x:104:114:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd:x:108:115::/var/run/lldpd:/usr/sbin/nologin
strongswan:x:110:65534::/var/lib/strongswan:/usr/sbin/nologin
libvirt-qemu:x:64055:116:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
libvirt-dnsmasq:x:111:118:Libvirt Dnsmasq,,,:/var/lib/libvirt/dnsmasq:/usr/sbin/nologin
postfix:x:112:120::/var/spool/postfix:/usr/sbin/nologin
statd:x:113:65534::/var/lib/nfs:/usr/sbin/nologin
tss:x:114:122:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:x:115:122:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:x:116:124:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:998::/home/vault:/bin/false
genctl:x:60000:200:GenCTL User,,,:/home/genctl:/usr/sbin/nologin
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:x:998:997:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt:x:1001:1002::/home/sysgt:/bin/bash
no_user:x:65535:996:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
mail.*				-/var/log/mail.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.28.12504.0aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        fluentbit-logs-m449v                                              4/4     Running     0             25h     11.51.32.5     dal1-qz2-sr2-rk204-s32   <none>           <none>
genctl        fluentd-qradar-ds-l6pft                                           1/1     Running     0             25h     11.51.32.3     dal1-qz2-sr2-rk204-s32   <none>           <none>
genctl        ifv-rclone-config-writer-h5bpc                                    1/1     Running     0             25h     11.51.32.4     dal1-qz2-sr2-rk204-s32   <none>           <none>
genctl        storage-agent-4f4sk                                               2/2     Running     0             8h      11.51.32.82    dal1-qz2-sr2-rk204-s32   <none>           <none>
kube-system   kube-proxy-x8v8l                                                  1/1     Running     0             25h     10.22.64.85    dal1-qz2-sr2-rk204-s32   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
58 profiles are loaded.
40 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /sbin/block-agent-server
   /sbin/coalesce-agent
   /sbin/coalesce-agent-nr
   /sbin/cos-transfer-agent
   /sbin/cos-transfer-agent-nr
   /sbin/dhclient
   /usr/bin/autofs_rclone
   /usr/bin/prometheus-node-exporter
   /usr/bin/rclone-agent
   /usr/bin/rclone-configurator
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/lib/ipsec/charon
   /usr/lib/ipsec/stroke
   /usr/sbin/canonical-livepatchd
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /usr/sbin/swanctl
   /usr/sbin/tcpdump
   /{,usr/}sbin/net-block-agent
   cri-containerd.apparmor.d
   docker-default
   fluentbit-logs
   genctl-ingress-controller
   libvirtd
   libvirtd//qemu_bridge_helper
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
   virt-aa-helper
18 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/hmonagent
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
40 processes have profiles defined.
25 processes are in enforce mode.
   /sbin/block-agent-server (158398) 
   /sbin/coalesce-agent (81759) 
   /sbin/coalesce-agent-nr (147932) 
   /sbin/cos-transfer-agent (81991) 
   /sbin/cos-transfer-agent-nr (147998) 
   /sbin/dhclient (103677) 
   /usr/bin/prometheus-node-exporter (150793) 
   /usr/lib/ipsec/charon (13648) 
   /usr/sbin/sshd (160000) 
   /usr/sbin/sshd//sysop (36227) 
   /usr/sbin/sshd//sysop (36239) 
   /{,usr/}sbin/net-block-agent (82171) 
   cri-containerd.apparmor.d (6935) 
   cri-containerd.apparmor.d (155859) 
   cri-containerd.apparmor.d (156035) 
   cri-containerd.apparmor.d (156254) 
   cri-containerd.apparmor.d (157347) 
   cri-containerd.apparmor.d (157373) 
   cri-containerd.apparmor.d (157410) 
   cri-containerd.apparmor.d (157500) 
   cri-containerd.apparmor.d (157569) 
   cri-containerd.apparmor.d (168120) 
   cri-containerd.apparmor.d (168143) 
   cri-containerd.apparmor.d (168395) 
   libvirtd (147840) 
15 processes are in complain mode.
   /usr/lib/frr/bgpd (190986) 
   /usr/lib/frr/staticd (190993) 
   /usr/lib/frr/watchfrr (190966) 
   /usr/lib/frr/zebra (190981) 
   /usr/local/fabcon/fabcon_server (152806) 
   /usr/local/fabcon/fabcon_server (153995) 
   /usr/local/fabcon/fabcon_server (154001) 
   /usr/local/fabcon/fabcon_server (154008) 
   /usr/local/fabcon/fabcon_server (154016) 
   /usr/local/fabcon/fabcon_server (154025) 
   /usr/local/iobricks/iobricksd (66176) 
   /usr/local/skydive/skydive (64132) 
   /usr/local/skydive/skydive (64186) 
   /usr/local/skydive/skydive (64257) 
   /usr/sbin/hmonagent (67393) 
0 processes are unconfined but have a profile defined.
'
<i>2024-12-17 17:36:56.257854</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.356090</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.356078</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.356085</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:56.356088</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.356119</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:36:56.357319</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:36:56.357480</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.357664</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.357652</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.357658</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:56.357661</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.357692</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'service'}
<i>2024-12-17 17:36:56.357720</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.580614</td>
    <td>0.29</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.580601</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.580608</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:56.580611</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.580638</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.580662</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.580682</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:56.580685</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:56.620711</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.620879</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:56.866204</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/block-agent-server": [
            {
                "pid": "158398",
                "status": "enforce"
            }
        ],
        "/sbin/coalesce-agent": [
            {
                "pid": "81759",
                "status": "enforce"
            }
        ],
        "/sbin/coalesce-agent-nr": [
            {
                "pid": "147932",
                "status": "enforce"
            }
        ],
        "/sbin/cos-transfer-agent": [
            {
                "pid": "81991",
                "status": "enforce"
            }
        ],
        "/sbin/cos-transfer-agent-nr": [
            {
                "pid": "147998",
                "status": "enforce"
            }
        ],
        "/sbin/dhclient": [
            {
                "pid": "103677",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "150793",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "190986",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "190993",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "190966",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "190981",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "13648",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "152806",
                "status": "complain"
            },
            {
                "pid": "153995",
                "status": "complain"
            },
            {
                "pid": "154001",
                "status": "complain"
            },
            {
                "pid": "154008",
                "status": "complain"
            },
            {
                "pid": "154016",
                "status": "complain"
            },
            {
                "pid": "154025",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "66176",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "64132",
                "status": "complain"
            },
            {
                "pid": "64186",
                "status": "complain"
            },
            {
                "pid": "64257",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "67393",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "160000",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "36227",
                "status": "enforce"
            },
            {
                "pid": "36239",
                "status": "enforce"
            }
        ],
        "/{,usr/}sbin/net-block-agent": [
            {
                "pid": "82171",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "6935",
                "status": "enforce"
            },
            {
                "pid": "155859",
                "status": "enforce"
            },
            {
                "pid": "156035",
                "status": "enforce"
            },
            {
                "pid": "156254",
                "status": "enforce"
            },
            {
                "pid": "157347",
                "status": "enforce"
            },
            {
                "pid": "157373",
                "status": "enforce"
            },
            {
                "pid": "157410",
                "status": "enforce"
            },
            {
                "pid": "157500",
                "status": "enforce"
            },
            {
                "pid": "157569",
                "status": "enforce"
            },
            {
                "pid": "168120",
                "status": "enforce"
            },
            {
                "pid": "168143",
                "status": "enforce"
            },
            {
                "pid": "168395",
                "status": "enforce"
            }
        ],
        "libvirtd": [
            {
                "pid": "147840",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/block-agent-server": "enforce",
        "/sbin/coalesce-agent": "enforce",
        "/sbin/coalesce-agent-nr": "enforce",
        "/sbin/cos-transfer-agent": "enforce",
        "/sbin/cos-transfer-agent-nr": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/autofs_rclone": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/bin/rclone-agent": "enforce",
        "/usr/bin/rclone-configurator": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "/{,usr/}sbin/net-block-agent": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "libvirtd": "enforce",
        "libvirtd//qemu_bridge_helper": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce",
        "virt-aa-helper": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:56.874187</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[2083 chars]e"}}' != '{"pr[333 chars]", "/sbin/block-agent-server": "enforce", "/sb[2030 chars]e"}}'
Diff is 5289 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:56.874351</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.874506</td>
    <td>0.52</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.874495</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:56.874501</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:56.874503</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.874530</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:36:57.100127</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.100159</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:36:57.100167</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:57.100220</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:57.100250</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_5.yml : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml
<i>2024-12-17 17:36:57.100255</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_5.yml for test validation
<i>2024-12-17 17:36:57.138280</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:57.138332</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:57.385809</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
    "processes": {
        "/sbin/block-agent-server": [
            {
                "pid": "158398",
                "status": "enforce"
            }
        ],
        "/sbin/coalesce-agent": [
            {
                "pid": "81759",
                "status": "enforce"
            }
        ],
        "/sbin/coalesce-agent-nr": [
            {
                "pid": "147932",
                "status": "enforce"
            }
        ],
        "/sbin/cos-transfer-agent": [
            {
                "pid": "81991",
                "status": "enforce"
            }
        ],
        "/sbin/cos-transfer-agent-nr": [
            {
                "pid": "147998",
                "status": "enforce"
            }
        ],
        "/sbin/dhclient": [
            {
                "pid": "103677",
                "status": "enforce"
            }
        ],
        "/usr/bin/prometheus-node-exporter": [
            {
                "pid": "150793",
                "status": "enforce"
            }
        ],
        "/usr/lib/frr/bgpd": [
            {
                "pid": "190986",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/staticd": [
            {
                "pid": "190993",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/watchfrr": [
            {
                "pid": "190966",
                "status": "complain"
            }
        ],
        "/usr/lib/frr/zebra": [
            {
                "pid": "190981",
                "status": "complain"
            }
        ],
        "/usr/lib/ipsec/charon": [
            {
                "pid": "13648",
                "status": "enforce"
            }
        ],
        "/usr/local/fabcon/fabcon_server": [
            {
                "pid": "152806",
                "status": "complain"
            },
            {
                "pid": "153995",
                "status": "complain"
            },
            {
                "pid": "154001",
                "status": "complain"
            },
            {
                "pid": "154008",
                "status": "complain"
            },
            {
                "pid": "154016",
                "status": "complain"
            },
            {
                "pid": "154025",
                "status": "complain"
            }
        ],
        "/usr/local/iobricks/iobricksd": [
            {
                "pid": "66176",
                "status": "complain"
            }
        ],
        "/usr/local/skydive/skydive": [
            {
                "pid": "64132",
                "status": "complain"
            },
            {
                "pid": "64186",
                "status": "complain"
            },
            {
                "pid": "64257",
                "status": "complain"
            }
        ],
        "/usr/sbin/hmonagent": [
            {
                "pid": "67393",
                "status": "complain"
            }
        ],
        "/usr/sbin/sshd": [
            {
                "pid": "160000",
                "status": "enforce"
            }
        ],
        "/usr/sbin/sshd//sysop": [
            {
                "pid": "36227",
                "status": "enforce"
            },
            {
                "pid": "36239",
                "status": "enforce"
            }
        ],
        "/{,usr/}sbin/net-block-agent": [
            {
                "pid": "82171",
                "status": "enforce"
            }
        ],
        "cri-containerd.apparmor.d": [
            {
                "pid": "6935",
                "status": "enforce"
            },
            {
                "pid": "155859",
                "status": "enforce"
            },
            {
                "pid": "156035",
                "status": "enforce"
            },
            {
                "pid": "156254",
                "status": "enforce"
            },
            {
                "pid": "157347",
                "status": "enforce"
            },
            {
                "pid": "157373",
                "status": "enforce"
            },
            {
                "pid": "157410",
                "status": "enforce"
            },
            {
                "pid": "157500",
                "status": "enforce"
            },
            {
                "pid": "157569",
                "status": "enforce"
            },
            {
                "pid": "168120",
                "status": "enforce"
            },
            {
                "pid": "168143",
                "status": "enforce"
            },
            {
                "pid": "168395",
                "status": "enforce"
            }
        ],
        "libvirtd": [
            {
                "pid": "147840",
                "status": "enforce"
            }
        ]
    },
    "profiles": {
        "/etc/hostos-monitoring/plugins.d/configuration-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/ipset-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/iptables-monitoring": "enforce",
        "/etc/hostos-monitoring/plugins.d/liveness": "enforce",
        "/etc/hostos-monitoring/plugins.d/smartnic-monitoring": "enforce",
        "/sbin/block-agent-server": "enforce",
        "/sbin/coalesce-agent": "enforce",
        "/sbin/coalesce-agent-nr": "enforce",
        "/sbin/cos-transfer-agent": "enforce",
        "/sbin/cos-transfer-agent-nr": "enforce",
        "/sbin/dhclient": "enforce",
        "/usr/bin/autofs_rclone": "enforce",
        "/usr/bin/prometheus-node-exporter": "enforce",
        "/usr/bin/rclone-agent": "enforce",
        "/usr/bin/rclone-configurator": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-client.action": "enforce",
        "/usr/lib/NetworkManager/nm-dhcp-helper": "enforce",
        "/usr/lib/connman/scripts/dhclient-script": "enforce",
        "/usr/lib/frr/bgpd": "complain",
        "/usr/lib/frr/staticd": "complain",
        "/usr/lib/frr/watchfrr": "complain",
        "/usr/lib/frr/zebra": "complain",
        "/usr/lib/ipsec/charon": "enforce",
        "/usr/lib/ipsec/stroke": "enforce",
        "/usr/local/fabcon/fabcon_server": "complain",
        "/usr/local/iobricks/bessctl/bessctl": "complain",
        "/usr/local/iobricks/iobricksd": "complain",
        "/usr/local/iobricks/monitor/monitor": "complain",
        "/usr/local/iobricks/monitor/monitor_datapath": "complain",
        "/usr/local/iobricks/monitor/monitor_fmt": "complain",
        "/usr/local/iobricks/monitor/monitor_vpe_enable": "complain",
        "/usr/local/skydive/skydive": "complain",
        "/usr/sbin/canonical-livepatchd": "enforce",
        "/usr/sbin/dropbear": "enforce",
        "/usr/sbin/hmonagent": "complain",
        "/usr/sbin/hostos-monitoring": "enforce",
        "/usr/sbin/mlx-setup.sh": "complain",
        "/usr/sbin/sshd": "enforce",
        "/usr/sbin/sshd//DEFAULT": "enforce",
        "/usr/sbin/sshd//root": "enforce",
        "/usr/sbin/sshd//sysop": "enforce",
        "/usr/sbin/swanctl": "enforce",
        "/usr/sbin/tcpdump": "enforce",
        "/{,usr/}sbin/net-block-agent": "enforce",
        "confined_user": "complain",
        "cri-containerd.apparmor.d": "enforce",
        "docker-default": "enforce",
        "docker-extended": "complain",
        "fluentbit-logs": "enforce",
        "fluentd-logs": "complain",
        "fluentd-qradar": "complain",
        "genctl-ingress-controller": "enforce",
        "libvirtd": "enforce",
        "libvirtd//qemu_bridge_helper": "enforce",
        "sysdig-agent": "enforce",
        "sysdig-agent-kmodule": "enforce",
        "sysdig-agent-kmodule//ln_profile": "enforce",
        "virt-aa-helper": "enforce"
    },
    "version": "1"
}'
<i>2024-12-17 17:36:57.392885</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 829, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.6/unittest/case.py", line 1203, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.6/unittest/case.py", line 670, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[2083 chars]e"}}' != '{"pr[333 chars]", "/sbin/block-agent-server": "enforce", "/sb[2030 chars]e"}}'
Diff is 5289 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:57.393027</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.508254</td>
    <td>0.06</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.508241</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.508249</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:57.508251</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.508302</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:57.508327</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.560985</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:36:57.564121</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
lxd
input
crontab
messagebus
ssh
admin
netdev
uuidd
syslog
sysop
rdma
ceph
nslcd
_lldpd
kvm
libvirt
libvirt-qemu
libvirt-dnsmasq
docker
ssl-cert
postfix
postdrop
tss
frrvty
frr
vault
prometheus
systemd-timesync
sugroup
sysgt
no_user
'
<i>2024-12-17 17:36:57.564414</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.564658</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.564645</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.564653</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:57.564655</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.564738</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_5.yml : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_5.yml
<i>2024-12-17 17:36:57.564775</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_generic.yml : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_generic.yml
<i>2024-12-17 17:36:57.616250</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:36:57.618976</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/var/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd/netif:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd/resolve:/usr/sbin/nologin
lxd::/var/lib/lxd/:/bin/false
messagebus::/nonexistent:/usr/sbin/nologin
sshd::/run/sshd:/usr/sbin/nologin
uuidd::/run/uuidd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
ceph:Ceph storage service:/var/lib/ceph:/usr/sbin/nologin
nslcd:nslcd name service LDAP connection daemon,,,:/var/run/nslcd/:/usr/sbin/nologin
_lldpd::/var/run/lldpd:/usr/sbin/nologin
strongswan::/var/lib/strongswan:/usr/sbin/nologin
libvirt-qemu:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
libvirt-dnsmasq:Libvirt Dnsmasq,,,:/var/lib/libvirt/dnsmasq:/usr/sbin/nologin
postfix::/var/spool/postfix:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
keylime:Keylime remote attestation,,,:/var/lib/keylime:/bin/false
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
genctl:GenCTL User,,,:/home/genctl:/usr/sbin/nologin
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
systemd-timesync:Time Synchronization added by HostOS:/run/systemd:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:36:57.619302</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.722586</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.722572</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.722579</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:57.722583</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.722668</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.722698</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.722714</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:36:57.722768</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.722781</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:36:57.723241</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.723255</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:36:57.723295</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.723306</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.723317</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:36:57.723364</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.723375</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.723385</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:36:57.723977</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.723991</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:36:57.724094</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.724106</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release5 : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release5
<i>2024-12-17 17:36:57.746331</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:36:57.748709</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root   0 Dec 17 17:36 cron.allow
drwxr-x--- 2 root root  60 Dec 17 17:36 cron.d
drwxr-x--- 2 root root 300 Dec 17 17:36 cron.daily
drwxr-x--- 2 root root 200 Dec 17 17:36 cron.hourly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.monthly
drwxr-x--- 2 root root  40 Dec 17 17:36 cron.weekly
-rw-r----- 1 root root 815 Dec 17 17:36 crontab
'
<i>2024-12-17 17:36:57.748753</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:36:57.751852</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.751893</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:36:57.751935</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:57.752189</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.752175</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.752181</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:57.752185</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.752214</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:36:57.754612</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'*/15 * * * * /usr/bin/rclone_cache_monitor.sh -r 10 -i 10 | /usr/bin/logger -t rclone_cache_monitor
0 0 * * * /usr/bin/nfs-mount-details.sh
0 0 * * * /usr/bin/nfsiostat-collect.sh
* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
'
<i>2024-12-17 17:36:57.754659</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:36:57.756718</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.756796</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release5/service : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/service
<i>2024-12-17 17:36:57.756825</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release5/service : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/service
<i>2024-12-17 17:36:57.756831</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -y --suppress-common-lines -EZbwB /tmp/crontab_data /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release5/service
<i>2024-12-17 17:36:57.758511</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger	      <
'
<i>2024-12-17 17:36:57.758676</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown
<i>2024-12-17 17:36:57.759129</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/scripts/../tests/cronjob_info/test_crontasks.py", line 140, in test_crontab_diff
    self.assertEqual(exit_code, 0, "Diffs in crontab tasks found!")
  File "/home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 226, in assertEqual
    raise e
  File "/home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
AssertionError: 1 != 0 : Diffs in crontab tasks found!
</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.759274</td>
    <td>7.21</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.759263</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:36:57.759269</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:36:57.759272</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.759296</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:36:57.761412</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.761452</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:36:57.762509</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.762542</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:36:59.775773</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:59.775839</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:36:59.775911</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.775917</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.775925</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:02.951482</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
.
good
'
<i>2024-12-17 17:37:02.951542</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:37:02.951555</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:37:02.953625</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:02.953660</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:04.966075</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:04.966293</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.075353</td>
    <td>0.13</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.075338</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.075346</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:37:05.075349</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.075401</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.075405</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.075408</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.203414</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

Linked to: nmnode2-02-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:37:05.203624</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.298833</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.298819</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.298827</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:37:05.298831</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.298874</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.298879</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.298882</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.333426</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.333539</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.333679</td>
    <td>0.03</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.333668</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.333674</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:37:05.333677</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.333722</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.333728</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.333731</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.368380</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.368509</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.461319</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.461305</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.461313</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:37:05.461316</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.461357</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.461360</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.461363</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.466074</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:37:05.466198</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.466356</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.466344</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.466350</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:37:05.466353</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.466401</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.466407</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.466410</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.471356</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:37:05.471495</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.471616</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.471605</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.471611</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:37:05.471613</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.471656</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.471661</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.471664</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014277_6186/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.476566</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:37:05.476667</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.569158</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s32 (service)</td>
    <td>Ubuntu-18.04.6-LTS-(Bionic-Beaver), Kernel: 4.15.0-1108-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.569145</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-18.04.6-LTS-(Bionic-Beaver)
<i>2024-12-17 17:37:05.569152</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:5.0.9-20240202T112409Z_04bb6b3 (Dec 16 2024 03:49:37 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 03:50:00 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:5.5.5-20241202T143334Z_cd3fc07 (Dec 16 2024 03:56:00 UTC, STATUS=success)

hostos-base-net-sw-release:5.14.44-20241211T074844Z_17b88763 (Dec 16 2024 04:04:09 UTC, STATUS=success)

hostos-nextgen-os-sw-release:5.2.1-20241125T082223Z_93a5590 (Dec 16 2024 04:10:20 UTC, STATUS=success)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 04:15:18 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:5.6.6-20241114T234347Z_f89e05d (Dec 16 2024 15:32:10 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:5.5.6-20241216T171852Z_140f4e7 (Dec 17 2024 05:05:02 UTC, STATUS=success)

<i>2024-12-17 17:37:05.569155</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.569183</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:37:05.571859</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.IUL8QlRN8BvvQ4g
'
<i>2024-12-17 17:37:05.571904</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.IUL8QlRN8BvvQ4g | grep "publickey ssh-rsa"
<i>2024-12-17 17:37:05.574034</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:37:05.574175</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for PCI Audit</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:54.956546</td>
    <td>1.37</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:54.956533</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:54.956540</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:54.956543</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:54.956575</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/info_collector/pci_info_collector.sh : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.956579</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:54.956581</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/info_collector/pci_info_collector.sh
<i>2024-12-17 17:36:56.324109</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ iptables listing ##############</b>

Chain INPUT (policy DROP 26967 packets, 1665K bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     785K  104M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    3541K 4050M KUBE-NODEPORTS  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes health check service ports */
3     785K  104M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
4    3541K 4050M KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
5    3712K 4515M HOSTOS-INPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain OUTPUT (policy DROP 7407 packets, 444K bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1    36858 2313K KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    36858 2313K KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
3    3205K  548M KUBE-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
4    3350K  569M HOSTOS-OUTPUT  all  --  *      *       0.0.0.0/0            0.0.0.0/0           


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1     195K   12M KUBE-PROXY-FIREWALL  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes load balancer firewall */
2    3525K 2682M KUBE-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0            /* kubernetes forwarding rules */
3     181K   11M KUBE-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes service portals */
4     181K   11M KUBE-EXTERNAL-SERVICES  all  --  *      *       0.0.0.0/0            0.0.0.0/0            ctstate NEW /* kubernetes externally-visible service portals */
5        0     0 ACCEPT     all  --  *      *       11.0.0.0/8           0.0.0.0/0            /* hostos_config_network */ ctstate RELATED,ESTABLISHED
6     181K   11M HOSTOS-FORWARD  all  --  *      *       0.0.0.0/0            0.0.0.0/0           
Chain INPUT (policy DROP 65 packets, 4680 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      682  345K KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2      617  341K KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3      682  345K KUBE-NODEPORTS  all      *      *       ::/0                 ::/0                 /* kubernetes health check service ports */
4      617  341K KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5      711  359K HOSTOS-INPUT  all      *      *       ::/0                 ::/0                


Chain OUTPUT (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1      243 13896 KUBE-FIREWALL  all      *      *       ::/0                 ::/0                
2        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4      252 14400 HOSTOS-OUTPUT  all      *      *       ::/0                 ::/0                


Chain FORWARD (policy DROP 0 packets, 0 bytes)
num   pkts bytes target     prot opt in     out     source               destination         
1        0     0 KUBE-PROXY-FIREWALL  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes load balancer firewall */
2      244 14240 KUBE-FORWARD  all      *      *       ::/0                 ::/0                 /* kubernetes forwarding rules */
3        0     0 KUBE-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes service portals */
4        0     0 KUBE-EXTERNAL-SERVICES  all      *      *       ::/0                 ::/0                 ctstate NEW /* kubernetes externally-visible service portals */
5      244 14240 HOSTOS-FORWARD  all      *      *       ::/0                 ::/0                

<b>############ services listing ##############</b>

  UNIT                                 LOAD      ACTIVE   SUB     DESCRIPTION
# am-utils.service                     not-found inactive dead    am-utils.service
# apache2.service                      not-found inactive dead    apache2.service
  apparmor.service                     loaded    active   exited  Load AppArmor profiles
  apt-daily-upgrade.service            loaded    inactive dead    Daily apt upgrade and clean activities
# apt-daily.service                    masked    inactive dead    apt-daily.service
# atd.service                          not-found inactive dead    atd.service
  auditd.service                       loaded    active   running Security Auditing Service
  auth-rpcgss-module.service           loaded    inactive dead    Kernel Module supporting RPCSEC_GSS
  autofs.service                       loaded    active   running Automounts filesystems on demand
  binfmt-support.service               loaded    active   exited  Enable support for additional executable binary formats
  blk-availability.service             loaded    active   exited  Availability of block devices
# citadel.service                      not-found inactive dead    citadel.service
  cloud-config.service                 loaded    inactive dead    Cloud-init: Config Stage
  cloud-final.service                  loaded    active   exited  Cloud-init: Final Stage
  cloud-init-hotplugd.service          loaded    inactive dead    Cloud-init: Hotplug Hook
  cloud-init-local.service             loaded    active   exited  Cloud-init: Local Stage (pre-network)
  cloud-init.service                   loaded    active   exited  Cloud-init: Network Stage
  cloudnet-gobgp.service               loaded    inactive dead    gobgpd service
# connman.service                      not-found inactive dead    connman.service
  containerd.service                   loaded    active   running containerd container runtime
# courier-ldap.service                 not-found inactive dead    courier-ldap.service
# courier-mta-ssl.service              not-found inactive dead    courier-mta-ssl.service
# courier-mta.service                  not-found inactive dead    courier-mta.service
# courier-pop-ssl.service              not-found inactive dead    courier-pop-ssl.service
# courier-pop.service                  not-found inactive dead    courier-pop.service
  cron.service                         loaded    active   running Regular background program processing daemon
# cyrus-imapd.service                  not-found inactive dead    cyrus-imapd.service
  dbus.service                         loaded    active   running D-Bus System Message Bus
# display-manager.service              not-found inactive dead    display-manager.service
  dm-event.service                     loaded    inactive dead    Device-mapper event daemon
  dmesg.service                        loaded    inactive dead    Save initial kernel messages after boot
# dovecot.service                      not-found inactive dead    dovecot.service
  dpkg-db-backup.service               loaded    inactive dead    Daily dpkg database backup service
  e2scrub_all.service                  loaded    inactive dead    Online ext4 Metadata Check for All Filesystems
  e2scrub_reap.service                 loaded    inactive dead    Remove Stale Online ext4 Metadata Check Snapshots
  emergency.service                    loaded    inactive dead    Emergency Shell
# exim4.service                        not-found inactive dead    exim4.service
  fabcon-mlx.service                   loaded    active   running Genesis network fabric controller service
  fabinst-inst.service                 loaded    inactive dead    Installation of scripts necessary for the installation of SDN software.
  falcon-sensor.service                loaded    inactive dead    CrowdStrike Falcon Sensor
# fcoe.service                         not-found inactive dead    fcoe.service
  finalrd.service                      loaded    active   exited  Create final runtime dir for shutdown pivot root
# firewalld.service                    not-found inactive dead    firewalld.service
  fluent-bit-ops-logs.service          loaded    inactive dead    Fluent Bit agent forwarding ops logs to remote.
  fluent-bit-qradar.service            loaded    inactive dead    Fluent Bit agent forwarding audit logs to QRadar.
  frr.service                          loaded    active   running FRRouting
  fstrim.service                       loaded    inactive dead    Discard unused blocks on filesystems from /etc/fstab
# gdm3.service                         not-found inactive dead    gdm3.service
  getty-static.service                 loaded    inactive dead    getty on tty2-tty6 if dbus and logind are not available
  getty@tty1.service                   loaded    active   running Getty on tty1
  gravingyard.service                  loaded    active   exited  Apply genesis policy to booted kubernetes
# gssproxy.service                     not-found inactive dead    gssproxy.service
# heartbeat-failed@frr.service         not-found inactive dead    heartbeat-failed@frr.service
# heimdal-kcm.service                  not-found inactive dead    heimdal-kcm.service
# heimdal-kdc.service                  not-found inactive dead    heimdal-kdc.service
# hv_kvp_daemon.service                not-found inactive dead    hv_kvp_daemon.service
  ifupdown-pre.service                 loaded    inactive dead    Helper to synchronize boot up for ifupdown
  iobricks-mlx.service                 loaded    active   running Genesis IOBricks Service on DPDK through Mellanox connectx-5 device
# ip6tables.service                    not-found inactive dead    ip6tables.service
# iptables.service                     not-found inactive dead    iptables.service
# iscsi-shutdown.service               not-found inactive dead    iscsi-shutdown.service
  iscsid.service                       loaded    inactive dead    iSCSI initiator daemon (iscsid)
# kdm.service                          not-found inactive dead    kdm.service
  kdump-tools.service                  loaded    active   exited  Kernel crash dump capture service
  kexec-load.service                   loaded    active   exited  LSB: Load kernel image with kexec
  kexec.service                        loaded    active   exited  LSB: Execute the kexec -e command to reboot system
  kmod-static-nodes.service            loaded    active   exited  Create List of Static Device Nodes
# kolab-cyrus-common.service           not-found inactive dead    kolab-cyrus-common.service
# krb5-kdc.service                     not-found inactive dead    krb5-kdc.service
  kubebootstrap.service                loaded    inactive dead    Bootstrap Kubernetes cluster
  kubelet.service                      loaded    active   running kubelet: The Kubernetes Node Agent
  libvirt-guests.service               loaded    active   exited  Suspend/Resume Running libvirt Guests
  libvirtd.service                     loaded    active   running Virtualization daemon
  lldpd.service                        loaded    active   running LLDP daemon
# logrotate.service                    loaded    failed   failed  Rotate log files
# lvm2-activation.service              not-found inactive dead    lvm2-activation.service
  lvm2-lvmpolld.service                loaded    inactive dead    LVM2 poll daemon
  lvm2-monitor.service                 loaded    active   exited  Monitoring of LVM2 mirrors, snapshots etc. using dmeventd or progress polling
# mail-transport-agent.service         not-found inactive dead    mail-transport-agent.service
# masqmail.service                     not-found inactive dead    masqmail.service
  mlx-config.service                   loaded    active   exited  Boot time configuration and setup of Mellanox hardware.
  modprobe@configfs.service            loaded    inactive dead    Load Kernel Module configfs
  modprobe@drm.service                 loaded    inactive dead    Load Kernel Module drm
  modprobe@efi_pstore.service          loaded    inactive dead    Load Kernel Module efi_pstore
  modprobe@fuse.service                loaded    inactive dead    Load Kernel Module fuse
  motd-news.service                    loaded    inactive dead    Message of the Day
  mst.service                          loaded    active   exited  LSB: mst
  nessusagent.service                  loaded    active   running The Nessus Client Agent
  netplan-ovs-cleanup.service          loaded    inactive dead    OpenVSwitch configuration for cleanup
# network.service                      not-found inactive dead    network.service
  networking.service                   loaded    inactive dead    Raise network interfaces
# NetworkManager.service               not-found inactive dead    NetworkManager.service
# nfs-server.service                   not-found inactive dead    nfs-server.service
  nfs-utils.service                    loaded    inactive dead    NFS server and client services
  nslcd.service                        loaded    active   running LSB: LDAP connection daemon
# nullmailer.service                   not-found inactive dead    nullmailer.service
  open-iscsi.service                   loaded    inactive dead    Login to default iSCSI targets
  osqueryd.service                     loaded    active   running The osquery Daemon
# ovsdb-server.service                 not-found inactive dead    ovsdb-server.service
# plymouth-quit-wait.service           not-found inactive dead    plymouth-quit-wait.service
# plymouth-start.service               not-found inactive dead    plymouth-start.service
  prometheus-node-exporter.service     loaded    active   running Prometheus exporter for machine metrics
  qemu-kvm.service                     loaded    active   exited  QEMU KVM preparation - module, ksm, hugepages
# rbdmap.service                       not-found inactive dead    rbdmap.service
  rc-local.service                     loaded    inactive dead    /etc/rc.local Compatibility
  rescue.service                       loaded    inactive dead    Rescue Shell
  rpc-gssd.service                     loaded    inactive dead    RPC security service for NFS client and server
  rpc-statd-notify.service             loaded    inactive dead    Notify NFS peers of a restart
  rpc-statd.service                    loaded    active   running NFS status monitor for NFSv2/3 locking.
  rpc-svcgssd.service                  loaded    inactive dead    RPC security service for NFS server
  rpcbind.service                      loaded    inactive dead    RPC bind portmap service
  rsyslog.service                      loaded    active   running System Logging Service
  secureboot-db.service                loaded    inactive dead    Secure Boot updates for DB and DBX
# sendmail.service                     not-found inactive dead    sendmail.service
  serial-getty@ttyS0.service           loaded    active   running Serial Getty on ttyS0
  serial-getty@ttyS1.service           loaded    active   running Serial Getty on ttyS1
# set-hostname.service                 not-found inactive dead    set-hostname.service
# shishi-kdc.service                   not-found inactive dead    shishi-kdc.service
  skydive.service                      loaded    active   running Skydive
# slapd.service                        not-found inactive dead    slapd.service
# slim.service                         not-found inactive dead    slim.service
# snapd.seeded.service                 not-found inactive dead    snapd.seeded.service
  ssh.service                          loaded    active   running OpenBSD Secure Shell server
# sshd-keygen.service                  not-found inactive dead    sshd-keygen.service
# sssd.service                         not-found inactive dead    sssd.service
  systemd-ask-password-console.service loaded    inactive dead    Dispatch Password Requests to Console
  systemd-ask-password-wall.service    loaded    inactive dead    Forward Password Requests to Wall
  systemd-binfmt.service               loaded    active   exited  Set Up Additional Binary Formats
  systemd-boot-system-token.service    loaded    inactive dead    Store a System Token in an EFI Variable
  systemd-fsck-root.service            loaded    inactive dead    File System Check on Root Device
  systemd-fsckd.service                loaded    inactive dead    File System Check Daemon to report status
# systemd-hwdb-update.service          not-found inactive dead    systemd-hwdb-update.service
  systemd-initctl.service              loaded    inactive dead    initctl Compatibility Daemon
  systemd-journal-flush.service        loaded    active   exited  Flush Journal to Persistent Storage
  systemd-journald.service             loaded    active   running Journal Service
  systemd-logind.service               loaded    active   running User Login Management
  systemd-machine-id-commit.service    loaded    inactive dead    Commit a transient machine-id on disk
  systemd-machined.service             loaded    active   running Virtual Machine and Container Registration Service
  systemd-modules-load.service         loaded    active   exited  Load Kernel Modules
  systemd-networkd-wait-online.service loaded    inactive dead    Wait for Network to be Configured
# systemd-networkd.service             masked    inactive dead    systemd-networkd.service
# systemd-oomd.service                 not-found inactive dead    systemd-oomd.service
  systemd-pstore.service               loaded    inactive dead    Platform Persistent Storage Archival
  systemd-random-seed.service          loaded    active   exited  Load/Save Random Seed
  systemd-remount-fs.service           loaded    active   exited  Remount Root and Kernel File Systems
  systemd-resolved.service             loaded    active   running Network Name Resolution
  systemd-rfkill.service               loaded    inactive dead    Load/Save RF Kill Switch Status
  systemd-sysctl.service               loaded    active   exited  Apply Kernel Variables
  systemd-sysusers.service             loaded    active   exited  Create System Users
  systemd-timesyncd.service            loaded    active   running Network Time Synchronization
  systemd-tmpfiles-clean.service       loaded    inactive dead    Cleanup of Temporary Directories
  systemd-tmpfiles-setup-dev.service   loaded    active   exited  Create Static Device Nodes in /dev
  systemd-tmpfiles-setup.service       loaded    active   exited  Create Volatile Files and Directories
  systemd-udev-trigger.service         loaded    active   exited  Coldplug All udev Devices
  systemd-udevd.service                loaded    active   running Rule-based Manager for Device Events and Files
# systemd-update-done.service          not-found inactive dead    systemd-update-done.service
  systemd-update-utmp-runlevel.service loaded    inactive dead    Record Runlevel Change in UTMP
  systemd-update-utmp.service          loaded    active   exited  Record System Boot/Shutdown in UTMP
  systemd-user-sessions.service        loaded    active   exited  Permit User Sessions
# systemd-vconsole-setup.service       not-found inactive dead    systemd-vconsole-setup.service
  taniumclient.service                 loaded    active   running Tanium Client
  user-runtime-dir@1001.service        loaded    active   exited  User Runtime Directory /run/user/1001
  user@1001.service                    loaded    active   running User Manager for UID 1001
  vagentkeys.service                   loaded    active   running service wrapper around vault keys agent
  vagentrpw.service                    loaded    active   running service wrapper around vault rpw agent
  vagentx.service                      loaded    active   running service wrapper around vault agent
  virtlockd.service                    loaded    inactive dead    Virtual machine lock manager
  virtlogd.service                     loaded    inactive dead    Virtual machine log manager
# wdm.service                          not-found inactive dead    wdm.service
# xdm.service                          not-found inactive dead    xdm.service
# xencommons.service                   not-found inactive dead    xencommons.service
# xendomains.service                   not-found inactive dead    xendomains.service
# ypbind.service                       not-found inactive dead    ypbind.service

LOAD   = Reflects whether the unit definition was properly loaded.
ACTIVE = The high-level unit activation state, i.e. generalization of SUB.
SUB    = The low-level unit activation state, values depend on unit type.
173 loaded units listed.
To show all installed unit files use \'systemctl list-unit-files\'.

<b>############ socket listing ##############</b>

Netid State  Recv-Q Send-Q      Local Address:Port  Peer Address:PortProcess                                       
udp   UNCONN 0      0           127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=1094677,fd=13))
udp   UNCONN 0      0                 0.0.0.0:111        0.0.0.0:*    users:(("systemd",pid=1,fd=71))              
udp   UNCONN 0      0               127.0.0.1:854        0.0.0.0:*    users:(("rpc.statd",pid=1175582,fd=5))       
udp   UNCONN 0      0                 0.0.0.0:4789       0.0.0.0:*                                                 
udp   UNCONN 0      0                 0.0.0.0:15944      0.0.0.0:*    users:(("rpc.statd",pid=1175582,fd=8))       
udp   UNCONN 0      0              11.51.34.2:50052      0.0.0.0:*    users:(("fabcon_server",pid=1184052,fd=14))  
udp   UNCONN 0      0                    [::]:111           [::]:*    users:(("systemd",pid=1,fd=73))              
udp   UNCONN 0      0                    [::]:38424         [::]:*    users:(("rpc.statd",pid=1175582,fd=10))      
tcp   LISTEN 0      16384           127.0.0.1:9100       0.0.0.0:*    users:(("prometheus-node",pid=1182056,fd=3)) 
tcp   LISTEN 0      16384           127.0.0.1:10248      0.0.0.0:*    users:(("kubelet",pid=1339092,fd=18))        
tcp   LISTEN 0      16384           127.0.0.1:10249      0.0.0.0:*    users:(("kube-proxy",pid=1325046,fd=8))      
tcp   LISTEN 0      4096              0.0.0.0:33155      0.0.0.0:*    users:(("rpc.statd",pid=1175582,fd=9))       
tcp   LISTEN 0      3               127.0.0.1:2616       0.0.0.0:*    users:(("staticd",pid=88742,fd=11))          
tcp   LISTEN 0      3               127.0.0.1:2605       0.0.0.0:*    users:(("bgpd",pid=88735,fd=18))             
tcp   LISTEN 0      3               127.0.0.1:2601       0.0.0.0:*    users:(("zebra",pid=88730,fd=26))            
tcp   LISTEN 0      16384           127.0.0.1:27519      0.0.0.0:*    users:(("containerd",pid=1314779,fd=13))     
tcp   LISTEN 0      1024            127.0.0.1:17473      0.0.0.0:*    users:(("TaniumClient",pid=200885,fd=67))    
tcp   LISTEN 0      1024           11.51.34.2:17472      0.0.0.0:*    users:(("TaniumClient",pid=200885,fd=65))    
tcp   LISTEN 0      4096              0.0.0.0:179        0.0.0.0:*    users:(("bgpd",pid=88735,fd=22))             
tcp   LISTEN 0      128               0.0.0.0:22         0.0.0.0:*    users:(("sshd",pid=1189855,fd=3))            
tcp   LISTEN 0      4096              0.0.0.0:111        0.0.0.0:*    users:(("systemd",pid=1,fd=70))              
tcp   LISTEN 0      4096        127.0.0.53%lo:53         0.0.0.0:*    users:(("systemd-resolve",pid=1094677,fd=14))
tcp   LISTEN 0      16384           127.0.0.1:50059      0.0.0.0:*    users:(("fabcon_server",pid=1184052,fd=18))  
tcp   LISTEN 0      16384           127.0.0.1:50055      0.0.0.0:*    users:(("fabcon_server",pid=1184052,fd=20))  
tcp   LISTEN 0      4096   [::ffff:127.0.0.1]:10514            *:*    users:(("iobricksd",pid=340363,fd=56))       
tcp   LISTEN 0      4096                 [::]:32979         [::]:*    users:(("rpc.statd",pid=1175582,fd=11))      
tcp   LISTEN 0      16384                   *:50057            *:*    users:(("fabcon_server",pid=1184052,fd=19))  
tcp   LISTEN 0      16384                   *:50051            *:*    users:(("fabcon_server",pid=1184052,fd=21))  
tcp   LISTEN 0      16384                   *:10256            *:*    users:(("kube-proxy",pid=1325046,fd=13))     
tcp   LISTEN 0      16384                   *:10250            *:*    users:(("kubelet",pid=1339092,fd=14))        
tcp   LISTEN 0      4096                 [::]:179           [::]:*    users:(("bgpd",pid=88735,fd=23))             
tcp   LISTEN 0      128                  [::]:22            [::]:*    users:(("sshd",pid=1189855,fd=4))            
tcp   LISTEN 0      4096                 [::]:111           [::]:*    users:(("systemd",pid=1,fd=72))              

<b>############ critical file listing ##############</b>

==> /etc/ssh/sshd_config <==

# This is the sshd server system-wide configuration file.  See
# sshd_config(5) for more information.

# This sshd was compiled with PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games

# The strategy used for options in the default sshd_config shipped with
# OpenSSH is to specify options with their default value where
# possible, but leave them commented.  Uncommented options override the
# default value.

Include /etc/ssh/sshd_config.d/*.conf

#Port 22
#AddressFamily any
#ListenAddress 0.0.0.0
#ListenAddress ::

#HostKey /etc/ssh/ssh_host_rsa_key
#HostKey /etc/ssh/ssh_host_ecdsa_key
#HostKey /etc/ssh/ssh_host_ed25519_key

#RekeyLimit default none

# Logging
#SyslogFacility AUTH

# Authentication:


#PubkeyAuthentication yes

# Expect .ssh/authorized_keys2 to be disregarded by default in future.
#AuthorizedKeysFile	.ssh/authorized_keys .ssh/authorized_keys2

#AuthorizedPrincipalsFile none

#AuthorizedKeysCommand none
#AuthorizedKeysCommandUser nobody

# For this to work you will also need host keys in /etc/ssh/ssh_known_hosts
# Change to yes if you don\'t trust ~/.ssh/known_hosts for
# HostbasedAuthentication
#IgnoreUserKnownHosts no
# Don\'t read the user\'s ~/.rhosts and ~/.shosts files

# To disable tunneled clear text passwords, change to no here!

# Change to yes to enable challenge-response passwords (beware issues with
# some PAM modules and threads)
KbdInteractiveAuthentication no

# Kerberos options
#KerberosAuthentication no
#KerberosOrLocalPasswd yes
#KerberosTicketCleanup yes
#KerberosGetAFSToken no

# GSSAPI options
#GSSAPIAuthentication no
#GSSAPICleanupCredentials yes
#GSSAPIStrictAcceptorCheck yes
#GSSAPIKeyExchange no

# Set this to \'yes\' to enable PAM authentication, account processing,
# and session processing. If this is enabled, PAM authentication will
# be allowed through the KbdInteractiveAuthentication and
# PasswordAuthentication.  Depending on your PAM configuration,
# PAM authentication via KbdInteractiveAuthentication may bypass
# If you just want the PAM account and session checks to run without
# PAM authentication, then enable this but set PasswordAuthentication
# and KbdInteractiveAuthentication to \'no\'.
UsePAM yes

#AllowTcpForwarding yes
#GatewayPorts no
#X11DisplayOffset 10
#X11UseLocalhost yes
#PermitTTY yes
PrintMotd no
#PrintLastLog yes
#TCPKeepAlive yes
#Compression delayed
#UseDNS no
#PidFile /run/sshd.pid
#PermitTunnel no
#ChrootDirectory none
#VersionAddendum none

# no default banner path

# Allow client to pass locale environment variables
AcceptEnv LANG LC_*

# override default of no subsystems
Subsystem	sftp	/usr/lib/openssh/sftp-server

# Example of overriding settings on a per-user basis
#Match User anoncvs
#	AllowTcpForwarding no
#	PermitTTY no
#	ForceCommand cvs server
PubkeyAuthentication yes
PubkeyAcceptedKeyTypes=+ssh-rsa
TrustedUserCAKeys /etc/ssh/trusted-user-ca-keys.pem
MaxStartups 10:30:60
AllowUsers *@10.223.90.233 *@10.223.90.234 *@192.168.95.0 *@192.168.95.17 *@192.168.95.134 *@192.168.95.137 sysop@192.168.95.0 sysop@192.168.95.1 sysop@192.168.95.2 sysop@192.168.95.3 sysop@192.168.95.4 sysop@192.168.95.5 sysop@192.168.95.6 sysop@192.168.95.7 sysop@192.168.95.8 sysop@192.168.95.9 sysop@192.168.95.10 sysop@192.168.95.11 sysop@192.168.95.12 sysop@192.168.95.13 sysop@192.168.95.14 sysop@192.168.95.15 sysop@192.168.95.16 sysop@192.168.95.17 sysop@192.168.95.18 sysop@192.168.95.19 sysop@192.168.95.20 sysop@192.168.95.21 sysop@192.168.95.22 sysop@192.168.95.23 sysop@192.168.95.24 sysop@192.168.95.25 sysop@192.168.95.26 sysop@192.168.95.27 sysop@192.168.95.28 sysop@192.168.95.29 sysop@192.168.95.30 sysop@192.168.95.31 
PermitRootLogin no
Ciphers aes256-ctr,aes128-ctr
KexAlgorithms curve25519-sha256,curve25519-sha256@libssh.org,diffie-hellman-group14-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha256,ecdh-sha2-nistp521,ecdh-sha2-nistp384,ecdh-sha2-nistp256
MACs hmac-sha2-512,hmac-sha2-256
LoginGraceTime 60
HostbasedAuthentication no
IgnoreRhosts yes
X11Forwarding no
LogLevel INFO
MaxAuthTries 10
PermitUserEnvironment no
Protocol 2
Banner /etc/issue.net
ClientAliveCountMax 0
PermitEmptyPasswords no
PasswordAuthentication yes
ChallengeResponseAuthentication no
AllowAgentForwarding no
StrictModes yes
RevokedKeys /etc/ssh/revoked_keys
ExposeAuthInfo yes
#sysop conditionals
ClientAliveInterval 300
MaxSessions 3
Match User sysop
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10
#sysgt conditionals
Match User sysgt
    PasswordAuthentication no
    ClientAliveCountMax 3
    MaxSessions 10

==> /etc/sudoers <==
#
# This file MUST be edited with the \'visudo\' command as root.
#
# Please consider adding local content in /etc/sudoers.d/ instead of
# directly modifying this file.
#
# See the man page for details on how to write a sudoers file.
#
Defaults	env_reset
Defaults	mail_badpass
Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"
Defaults	use_pty

# This preserves proxy settings from user environments of root
# equivalent users (group sudo)
#Defaults:%sudo env_keep += "http_proxy https_proxy ftp_proxy all_proxy no_proxy"

# This allows running arbitrary commands, but so does ALL, and it means
# different sudoers have their choice of editor respected.
#Defaults:%sudo env_keep += "EDITOR"

# Completely harmless preservation of a user preference.
#Defaults:%sudo env_keep += "GREP_COLOR"

# While you shouldn\'t normally run git as root, you need to with etckeeper
#Defaults:%sudo env_keep += "GIT_AUTHOR_* GIT_COMMITTER_*"

# Per-user preferences; root won\'t have sensible values for them.
#Defaults:%sudo env_keep += "EMAIL DEBEMAIL DEBFULLNAME"

# "sudo scp" or "sudo rsync" should be able to use your SSH agent.
#Defaults:%sudo env_keep += "SSH_AGENT_PID SSH_AUTH_SOCK"

# Ditto for GPG agent
#Defaults:%sudo env_keep += "GPG_AGENT_INFO"

# Host alias specification

# User alias specification

# Cmnd alias specification

# User privilege specification
root	ALL=(ALL:ALL) ALL

# Members of the admin group may gain root privileges
%admin ALL=(ALL) ALL

# Allow members of group sudo to execute any command
%sudo	ALL=(ALL:ALL) ALL

# See sudoers(5) for more information on "@include" directives:

@includedir /etc/sudoers.d
Defaults logfile=/var/log/sudo.log

==> /etc/sudoers.d/20-NG-BNPP-SUPPORT <==
%NG-BNPP-SUPPORT  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/22-NG-DEVOPS <==
%NG-DEVOPS  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/24-NG-IPOPS-GROUP <==
%NG-IPOPS-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/28-NG-SSRe-GROUP <==
%NG-SSRe-GROUP ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/29-NG-STAGE <==
%NG-STAGE  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/31-NG-SYSTEMS-ENG-GROUP <==
%NG-SYSTEMS-ENG-GROUP  ALL=(ALL) ALL, !/usr/bin/ssh,!/usr/sbin/visudo,!/usr/bin/vim /etc/sudoers,!/usr/bin/nano /etc/sudoers,!/usr/local/bin/pip,!/usr/local/bin/pip3,!/usr/bin/apt,!/usr/bin/apt-get

==> /etc/sudoers.d/README <==
#
# As of Debian version 1.7.2p1-1, the default /etc/sudoers file created on
# installation of the package now includes the directive:
#
# 	#includedir /etc/sudoers.d
#
# This will cause sudo to read and parse any files in the /etc/sudoers.d
# directory that do not end in \'~\' or contain a \'.\' character.
#
# Note that there must be at least one file in the sudoers.d directory (this
# one will do), and all files in this directory should be mode 0440.
#
# Note also, that because sudoers contents can vary widely, no attempt is
# made to add this directive to existing sudoers files on upgrade.  Feel free
# to add the above directive to the end of your /etc/sudoers file to enable
# this functionality for existing installations if you wish!
#
# Finally, please note that using the visudo command is the recommended way
# to update sudoers content, since it protects against many failure modes.
# See the man page for visudo for more information.
#

==> /etc/sudoers.d/sysgt <==
sysgt ALL=(ALL) NOPASSWD:ALL

==> /etc/sudoers.d/sysop <==
sysop ALL=(ALL) NOPASSWD:ALL

==> /etc/group <==
root:x:0:
daemon:x:1:
bin:x:2:
sys:x:3:
adm:x:4:syslog
tty:x:5:
disk:x:6:
lp:x:7:
mail:x:8:
news:x:9:
uucp:x:10:
man:x:12:
proxy:x:13:
kmem:x:15:
dialout:x:20:
fax:x:21:
voice:x:22:
cdrom:x:24:
floppy:x:25:
tape:x:26:
sudo:x:27:
audio:x:29:
dip:x:30:
www-data:x:33:
backup:x:34:
operator:x:37:
list:x:38:
irc:x:39:
src:x:40:
gnats:x:41:
shadow:x:42:
utmp:x:43:
video:x:44:
sasl:x:45:
plugdev:x:46:
staff:x:50:
games:x:60:
users:x:100:
nogroup:x:65534:
systemd-journal:x:101:
systemd-network:x:102:
systemd-resolve:x:103:
messagebus:x:104:
systemd-timesync:x:105:
input:x:106:
sgx:x:107:
kvm:x:108:
render:x:109:
lxd:x:110:
tss:x:111:
_ssh:x:112:
fwupd-refresh:x:113:
admin:x:115:
netdev:x:116:
syslog:x:114:
sysop:x:1001:
crontab:x:117:
nslcd:x:118:
tcpdump:x:119:
_lldpd:x:120:
rdma:x:121:
libvirt:x:200:
libvirt-qemu:x:64055:libvirt-qemu
libvirt-dnsmasq:x:123:
swtpm:x:124:
ssl-cert:x:125:
postfix:x:126:
postdrop:x:127:
frrvty:x:128:frr
frr:x:129:
vault:x:999:
host-logging:x:60202:
prometheus:x:62700:
docker:x:1002:
sugroup:x:1003:
sysgt:x:1004:
no_user:x:998:

==> /etc/pam.conf <==
# ---------------------------------------------------------------------------#
# /etc/pam.conf								     #
# ---------------------------------------------------------------------------#
#
# NOTE
# ----
#
# NOTE: Most program use a file under the /etc/pam.d/ directory to setup their
# PAM service modules. This file is used only if that directory does not exist.
# ---------------------------------------------------------------------------#

# Format:
# serv.	module	   ctrl	      module [path]	...[args..]		     #
# name	type	   flag							     #


==> /etc/pam.d/chfn <==
#
# The PAM configuration file for the Shadow `chfn\' service
#

# This allows root to change user infomation without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session



==> /etc/pam.d/chpasswd <==
# The PAM configuration file for the Shadow \'chpasswd\' service
#

@include common-password


==> /etc/pam.d/chsh <==
#
# The PAM configuration file for the Shadow `chsh\' service
#

# This will not allow a user to change their shell unless
# their current one is listed in /etc/shells. This keeps
# accounts with special shells from changing them.
auth       required   pam_shells.so

# This allows root to change user shell without being
# prompted for a password
auth		sufficient	pam_rootok.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


==> /etc/pam.d/common-account <==
#common-account incantation
account    [success=2 new_authtok_reqd=done default=ignore]   pam_unix.so
account    [success=1 default=ignore]                         pam_ldap.so minimum_uid=10000
account    requisite                                          pam_deny.so
account    required                                           pam_permit.so
account    required                                           pam_faillock.so
account    required                                           pam_access.so

==> /etc/pam.d/common-auth <==
#common-auth incantation
auth required                  pam_faillock.so preauth
auth  [success=4 default=ignore] pam_unix.so nullok_secure
auth  [success=3 default=ignore] pam_ldap.so use_first_pass minimum_uid=10000
auth [default=die]              pam_faillock.so authfail
auth sufficient                 pam_faillock.so authsucc
auth required                   pam_deny.so
auth required                   pam_permit.so

==> /etc/pam.d/common-password <==
#common-password incantation
password requisite     pam_pwquality.so retry=3
password required      pam_pwhistory.so
password [success=2 default=ignore] pam_unix.so obscure remember=5 use_authtok try_first_pass 
password [success=1 user_unknown=ignore default=die] pam_ldap.so use_authtok try_first_pass minimum_uid=10000
password required      pam_deny.so
password required      pam_permit.so

==> /etc/pam.d/common-session <==
session [default=1] pam_permit.so
session requisite   pam_deny.so
session required    pam_permit.so
session optional    pam_umask.so umask=0027
session required    pam_unix.so
session [success=ok default=ignore] pam_ldap.so minimum_uid=10000
session optional    pam_mkhomedir.so umask=0027 skel=/etc/skel/
session optional    pam_systemd.so
session required    pam_limits.so

==> /etc/pam.d/common-session-noninteractive <==
#
# /etc/pam.d/common-session-noninteractive - session-related modules
# common to all non-interactive services
#
# This file is included from other service-specific PAM config files,
# and should contain a list of modules that define tasks to be performed
# at the start and end of all non-interactive sessions.
#
# As of pam 1.0.1-6, this file is managed by pam-auth-update by default.
# To take advantage of this, it is recommended that you configure any
# local modules either before or after the default block, and use
# pam-auth-update to manage selection of other modules.  See
# pam-auth-update(8) for details.

# here are the per-package modules (the "Primary" block)
session	[default=1]			pam_permit.so
# here\'s the fallback if no module succeeds
session	requisite			pam_deny.so
# prime the stack with a positive return value if there isn\'t one already;
# this avoids us returning an error just because nothing sets a success code
# since the modules above will each just jump around
session	required			pam_permit.so
# The pam_umask module will set the umask according to the system default in
# /etc/login.defs and user settings, solving the problem of different
# umask settings with different shells, display managers, remote sessions etc.
# See "man pam_umask".
session optional			pam_umask.so
# and here are more per-package modules (the "Additional" block)
session	required	pam_unix.so 
session	[success=ok default=ignore]	pam_ldap.so minimum_uid=10000
# end of pam-auth-update config

==> /etc/pam.d/cron <==
# The PAM configuration file for the cron daemon

@include common-auth

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Read environment variables from pam_env\'s default files, /etc/environment
# and /etc/security/pam_env.conf.
session       required   pam_env.so

# In addition, read system locale information
session       required   pam_env.so envfile=/etc/default/locale

@include common-account
@include common-session-noninteractive 

# Sets up user limits, please define limits for cron tasks
# through /etc/security/limits.conf
session    required   pam_limits.so


==> /etc/pam.d/frr <==
# Any user may call vtysh but only those belonging to the group frrvty can
# actually connect to the socket and use the program.
auth	sufficient	pam_permit.so

==> /etc/pam.d/login <==
#
# The PAM configuration file for the Shadow `login\' service
#

# Enforce a minimal delay in case of failure (in microseconds).
# (Replaces the `FAIL_DELAY\' setting from login.defs)
# Note that other modules may require another minimal delay. (for example,
# to disable any delay, you should add the nodelay option to pam_unix)
auth       optional   pam_faildelay.so  delay=3000000

# Outputs an issue file prior to each login prompt (Replaces the
# ISSUE_FILE option from login.defs). Uncomment for use
# auth       required   pam_issue.so issue=/etc/issue

# Disallows other than root logins when /etc/nologin exists
# (Replaces the `NOLOGINS_FILE\' option from login.defs)
auth       requisite  pam_nologin.so

# SELinux needs to be the first session rule. This ensures that any
# lingering context has been cleared. Without this it is possible
# that a module could execute code in the wrong domain.
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so close

# Sets the loginuid process attribute
session    required     pam_loginuid.so

# Prints the message of the day upon successful login.
# (Replaces the `MOTD_FILE\' option in login.defs)
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional   pam_motd.so motd=/run/motd.dynamic
session    optional   pam_motd.so noupdate

# SELinux needs to intervene at login time to ensure that the process
# starts in the proper default security context. Only sessions which are
# intended to run in the user\'s context should be run after this.
# pam_selinux.so changes the SELinux context of the used TTY and configures
# SELinux in order to transition to the user context with the next execve()
# call.
session [success=ok ignore=ignore module_unknown=ignore default=bad] pam_selinux.so open
# When the module is present, "required" would be sufficient (When SELinux
# is disabled, this returns success.)

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Standard Un*x authentication.
@include common-auth

# This allows certain extra groups to be granted to a user
# based on things like time of day, tty, service, and user.
# Please edit /etc/security/group.conf to fit your needs
# (Replaces the `CONSOLE_GROUPS\' option in login.defs)
auth       optional   pam_group.so

# Uncomment and edit /etc/security/time.conf if you need to set
# time restraint on logins.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# Uncomment and edit /etc/security/access.conf if you need to
# set access limits.
# (Replaces /etc/login.access file)
# account  required       pam_access.so

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# Prints the last login info upon successful login
# (Replaces the `LASTLOG_ENAB\' option from login.defs)
session    optional   pam_lastlog.so

# Prints the status of the user\'s mailbox upon successful login
# (Replaces the `MAIL_CHECK_ENAB\' option from login.defs). 
#
# This also defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
session    optional   pam_mail.so standard

# Create a new session keyring.
session    optional   pam_keyinit.so force revoke

# Standard Un*x account and session
@include common-account
@include common-session
@include common-password

==> /etc/pam.d/newusers <==
# The PAM configuration file for the Shadow \'newusers\' service
#

@include common-password


==> /etc/pam.d/other <==
#
# /etc/pam.d/other - specify the PAM fallback behaviour
#
# Note that this file is used for any unspecified service; for example
#if /etc/pam.d/cron  specifies no session modules but cron calls
#pam_open_session, the session module out of /etc/pam.d/other is
#used.  If you really want nothing to happen then use pam_permit.so or
#pam_deny.so as appropriate.

# We fall back to the system default in /etc/pam.d/common-*
# 

@include common-auth
@include common-account
@include common-password
@include common-session

==> /etc/pam.d/passwd <==
#
# The PAM configuration file for the Shadow `passwd\' service
#

@include common-password


==> /etc/pam.d/polkit-1 <==
#%PAM-1.0

@include common-auth
@include common-account
@include common-password
session       required   pam_env.so readenv=1 user_readenv=0
session       required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0
@include common-session-noninteractive

==> /etc/pam.d/runuser <==
#%PAM-1.0
auth		sufficient	pam_rootok.so
session		optional	pam_keyinit.so revoke
session		required	pam_limits.so
session		required	pam_unix.so

==> /etc/pam.d/runuser-l <==
#%PAM-1.0
auth		include		runuser
session		optional	pam_keyinit.so force revoke
-session	optional	pam_systemd.so
session		include		runuser

==> /etc/pam.d/sshd <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open
session optional pam_apparmor.so order=user,group,default

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/sshd.2024_12_16_14_54_22 <==
# PAM configuration for the Secure Shell service

# Standard Un*x authentication.
@include common-auth

# Disallow non-root logins when /etc/nologin exists.
account    required     pam_nologin.so

# Uncomment and edit /etc/security/access.conf if you need to set complex
# access limits that are hard to express in sshd_config.
# account  required     pam_access.so

# Standard Un*x authorization.
@include common-account

# SELinux needs to be the first session rule.  This ensures that any
# lingering context has been cleared.  Without this it is possible that a
# module could execute code in the wrong domain.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so close

# Set the loginuid process attribute.
session    required     pam_loginuid.so

# Create a new session keyring.
session    optional     pam_keyinit.so force revoke

# Standard Un*x session setup and teardown.
@include common-session

# Print the message of the day upon successful login.
# This includes a dynamically generated part from /run/motd.dynamic
# and a static (admin-editable) part from /etc/motd.
session    optional     pam_motd.so  motd=/run/motd.dynamic
session    optional     pam_motd.so noupdate

# Print the status of the user\'s mailbox upon successful login.
session    optional     pam_mail.so standard noenv # [1]

# Set up user limits from /etc/security/limits.conf.
session    required     pam_limits.so

# Read environment variables from /etc/environment and
# /etc/security/pam_env.conf.
session    required     pam_env.so # [1]
# In Debian 4.0 (etch), locale-related environment variables were moved to
# /etc/default/locale, so read that as well.
session    required     pam_env.so user_readenv=1 envfile=/etc/default/locale

# SELinux needs to intervene at login time to ensure that the process starts
# in the proper default security context.  Only sessions which are intended
# to run in the user\'s context should be run after this.
session [success=ok ignore=ignore module_unknown=ignore default=bad]        pam_selinux.so open

# Standard Un*x password updating.
@include common-password

==> /etc/pam.d/su <==
#
# The PAM configuration file for the Shadow `su\' service
#

# This allows root to su without passwords (normal operation)
auth       sufficient pam_rootok.so

# Uncomment this to force users to be a member of group wheel
# before they can use `su\'. You can also add "group=foo"
# to the end of this line if you want to use a group other
# than the default "wheel" (but this may have side effect of
# denying "root" user, unless she\'s a member of "foo" or explicitly
# permitted earlier by e.g. "sufficient pam_rootok.so").
# (Replaces the `SU_WHEEL_ONLY\' option from login.defs)
# auth       required   pam_wheel.so

# Uncomment this if you want wheel members to be able to
# su without a password.
# auth       sufficient pam_wheel.so trust

# Uncomment this if you want members of a specific group to not
# be allowed to use su at all.
# auth       required   pam_wheel.so deny group=nosu

# Uncomment and edit /etc/security/time.conf if you need to set
# time restrainst on su usage.
# (Replaces the `PORTTIME_CHECKS_ENAB\' option from login.defs
# as well as /etc/porttime)
# account    requisite  pam_time.so

# This module parses environment configuration file(s)
# and also allows you to use an extended config
# file /etc/security/pam_env.conf.
# 
# parsing /etc/environment needs "readenv=1"
session       required   pam_env.so readenv=1
# locale variables are also kept into /etc/default/locale in etch
# reading this file *in addition to /etc/environment* does not hurt
session       required   pam_env.so readenv=1 envfile=/etc/default/locale

# Defines the MAIL environment variable
# However, userdel also needs MAIL_DIR and MAIL_FILE variables
# in /etc/login.defs to make sure that removing a user 
# also removes the user\'s mail spool file.
# See comments in /etc/login.defs
#
# "nopen" stands to avoid reporting new mail when su\'ing to another user
session    optional   pam_mail.so nopen

# Sets up user limits according to /etc/security/limits.conf
# (Replaces the use of /etc/limits in old login)
session    required   pam_limits.so

# The standard Unix authentication modules, used with
# NIS (man nsswitch) as well as normal /etc/passwd and
# /etc/shadow entries.
@include common-auth
@include common-account
@include common-session


auth required pam_wheel.so use_uid group=sugroup

==> /etc/pam.d/su-l <==
#%PAM-1.0
auth		include		su
account		include		su
password	include		su
session		optional	pam_keyinit.so force revoke
session		include		su

==> /etc/pam.d/sudo <==
#%PAM-1.0

# Set up user limits from /etc/security/limits.conf.
session    required   pam_limits.so

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0

@include common-auth
@include common-account
@include common-session-noninteractive

==> /etc/pam.d/sudo-i <==
#%PAM-1.0

# Set up user limits from /etc/security/limits.conf.
session    required   pam_limits.so

session    required   pam_env.so readenv=1 user_readenv=0
session    required   pam_env.so readenv=1 envfile=/etc/default/locale user_readenv=0

@include common-auth
@include common-account
@include common-session

==> /etc/passwd <==
root:x:0:0:root:/root:/bin/bash
daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin
bin:x:2:2:bin:/bin:/usr/sbin/nologin
sys:x:3:3:sys:/dev:/usr/sbin/nologin
sync:x:4:65534:sync:/bin:/bin/sync
games:x:5:60:games:/usr/games:/usr/sbin/nologin
man:x:6:12:man:/var/cache/man:/usr/sbin/nologin
lp:x:7:7:lp:/var/spool/lpd:/usr/sbin/nologin
mail:x:8:8:mail:/var/mail:/usr/sbin/nologin
news:x:9:9:news:/var/spool/news:/usr/sbin/nologin
uucp:x:10:10:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:x:13:13:proxy:/bin:/usr/sbin/nologin
www-data:x:33:33:www-data:/var/www:/usr/sbin/nologin
backup:x:34:34:backup:/var/backups:/usr/sbin/nologin
list:x:38:38:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:x:39:39:ircd:/run/ircd:/usr/sbin/nologin
gnats:x:41:41:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:x:65534:65534:nobody:/nonexistent:/usr/sbin/nologin
_apt:x:100:65534::/nonexistent:/usr/sbin/nologin
systemd-network:x:101:102:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin
systemd-resolve:x:102:103:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin
messagebus:x:103:104::/nonexistent:/usr/sbin/nologin
systemd-timesync:x:104:105:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin
tss:x:105:111:TPM software stack,,,:/var/lib/tpm:/bin/false
sshd:x:107:65534::/run/sshd:/usr/sbin/nologin
fwupd-refresh:x:108:113:fwupd-refresh user,,,:/run/systemd:/usr/sbin/nologin
syslog:x:106:114::/home/syslog:/usr/sbin/nologin
sysop:x:1001:1001::/home/sysop:/bin/bash
nslcd:x:109:118:nslcd name service LDAP connection daemon,,,:/run/nslcd:/usr/sbin/nologin
tcpdump:x:110:119::/nonexistent:/usr/sbin/nologin
_lldpd:x:111:120::/run/lldpd:/usr/sbin/nologin
libvirt-qemu:x:64055:108:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
libvirt-dnsmasq:x:112:123:Libvirt Dnsmasq,,,:/var/lib/libvirt/dnsmasq:/usr/sbin/nologin
swtpm:x:113:124:virtual TPM software stack,,,:/var/lib/swtpm:/bin/false
postfix:x:114:126::/var/spool/postfix:/usr/sbin/nologin
_rpc:x:115:65534::/run/rpcbind:/usr/sbin/nologin
statd:x:116:65534::/var/lib/nfs:/usr/sbin/nologin
frr:x:117:129:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault:x:999:999::/home/vault:/bin/false
host-logging:x:60201:60202:Logging account:/home/host-logging:/usr/sbin/nologin
prometheus:x:627000:62700:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
sysgt:x:1002:1004::/home/sysgt:/bin/bash
genctl:x:60000:200::/home/genctl:/usr/sbin/nologin
no_user:x:65535:998:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin

==> /etc/systemd/timesyncd.conf <==
[Time]
NTP=10.0.77.54
FallbackNTP=10.0.77.54
RootDistanceMaxSec=30

==> /etc/rsyslog.d/50-default.conf <==
template(name="syslog_priority" type="string" string="%TIMESTAMP% %HOSTNAME% %syslogtag%<%syslogpriority-text:::uppercase%> <%syslogfacility-text:::uppercase%> %msg%\
")
#  Default rules for rsyslog.
#
#			For more information see rsyslog.conf(5) and /etc/rsyslog.conf

#
# First some standard log files.  Log by facility.
#
auth,authpriv.*			/var/log/auth.log;syslog_priority
*.*;auth,authpriv.none		-/var/log/syslog;syslog_priority
#cron.*				/var/log/cron.log
#daemon.*			-/var/log/daemon.log
kern.*				-/var/log/kern.log
#lpr.*				-/var/log/lpr.log
#user.*				-/var/log/user.log

#
# Logging for the mail system.  Split it up so that
# it is easy to write scripts to parse these files.
#
#mail.info			-/var/log/mail.info
#mail.warn			-/var/log/mail.warn
mail.err			/var/log/mail.err

#
# Some "catch-all" log files.
#
#*.=debug;\
#	auth,authpriv.none;\
#	news.none;mail.none	-/var/log/debug
#*.=info;*.=notice;*.=warn;\
#	auth,authpriv.none;\
#	cron,daemon.none;\
#	mail,news.none		-/var/log/messages

#
# Emergencies are sent to everybody logged in.
#
*.emerg				:omusrmsg:*

#
# I like to have messages displayed on the console, but only on a virtual
# console I usually leave idle.
#
#daemon,mail.*;\
#	news.=crit;news.=err;news.=notice;\
#	*.=debug;*.=info;\
#	*.=notice;*.=warn	/dev/tty8
local6.* /var/log/commands.log
*.*;mail.none;news.none -/var/log/messages
*.=warning;*.=err -/var/log/warn
*.crit /var/log/warn
local0,local1.* -/var/log/localmessages
local2,local3.* -/var/log/localmessages
local4,local5.* -/var/log/localmessages
local6,local7.* -/var/log/localmessages
mail.* -/var/log/mail
mail.info -/var/log/mail.info
mail.warning -/var/log/mail.warn
news.crit -/var/log/news/news.crit
news.err -/var/log/news/news.err
news.notice -/var/log/news/news.notice
auth,authpriv.* -/var/log/secure
cron.* /var/log/cron
auth,authpriv.* @@192.168.95.149:514
local6.* @@192.168.95.149:514

<b>############ Crowdstrike EDR verification ##############</b>

version = 6.49.14604.0
aid is not set.

<b>############ kubectl pods and microservices listing ##############</b>

NAMESPACE     NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                                     AGE
default       kubernetes                            ClusterIP   172.16.0.1       <none>        443/TCP                                                     25h
genctl        acadia-discovery-server               ClusterIP   172.16.226.0     <none>        10083/TCP                                                   25h
genctl        acadia-rsos-admin                     ClusterIP   None             <none>        <none>                                                      25h
genctl        bm-server-controller                  ClusterIP   172.16.133.238   <none>        8888/TCP                                                    25h
genctl        bm-server-manager                     ClusterIP   172.16.101.203   <none>        8888/TCP                                                    25h
genctl        compute-deployment-orchestrator       ClusterIP   172.16.218.18    <none>        8443/TCP                                                    25h
genctl        console-proxy                         ClusterIP   172.16.60.26     <none>        7681/TCP,443/TCP                                            25h
genctl        dedicated-node-controller             ClusterIP   172.16.236.218   <none>        8888/TCP                                                    25h
genctl        dedicated-node-migration-controller   ClusterIP   172.16.68.29     <none>        8888/TCP                                                    25h
genctl        diagnostics-rest-server               ClusterIP   172.16.154.78    <none>        8443/TCP                                                    25h
genctl        etcd-restore-operator                 ClusterIP   172.16.219.39    <none>        19999/TCP                                                   20h
genctl        firmware-service                      ClusterIP   172.16.89.207    <none>        8443/TCP                                                    25h
genctl        fleetman-rest-server                  ClusterIP   172.16.143.152   <none>        8080/TCP                                                    25h
genctl        fluentd-log-aggregator                ClusterIP   172.16.148.170   <none>        24225/TCP                                                   25h
genctl        fluentd-qradar-aggregator             ClusterIP   172.16.183.88    <none>        24229/TCP                                                   25h
genctl        fluentd-syslog-aggregator             ClusterIP   172.16.252.55    <none>        24226/TCP                                                   25h
genctl        genctl-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        genctl-etcd-cluster-client            ClusterIP   172.16.219.192   <none>        2379/TCP                                                    25h
genctl        genctl-etcd-cluster-nodeport          NodePort    172.16.206.40    <none>        2379:4379/TCP                                               25h
genctl        genctl-extension-server               ClusterIP   172.16.225.136   <none>        443/TCP,449/TCP                                             25h
genctl        genctl-extension-server-headless      ClusterIP   None             <none>        <none>                                                      25h
genctl        iam-rest-server                       ClusterIP   172.16.164.195   <none>        8443/TCP,8444/TCP,9393/TCP                                  25h
genctl        k8s-xinetd                            ClusterIP   None             <none>        754/TCP                                                     25h
genctl        kali-etcd-cluster                     ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        kali-etcd-cluster-client              ClusterIP   172.16.65.63     <none>        2379/TCP                                                    25h
genctl        kali-etcd-cluster-nodeport            NodePort    172.16.204.67    <none>        2379:8378/TCP                                               25h
genctl        kali-server                           ClusterIP   172.16.50.51     <none>        50053/TCP,55053/TCP,2112/TCP,2113/TCP                       25h
genctl        kali-server-nodeport                  NodePort    172.16.164.207   <none>        50053:8053/TCP,55053:8063/TCP                               25h
genctl        kdc-nginx-ingress                     NodePort    172.16.233.163   <none>        88:88/TCP,749:749/TCP,749:749/UDP,88:88/UDP,8000:9000/UDP   25h
genctl        kerberos-service                      ClusterIP   None             <none>        88/UDP,88/TCP,749/UDP,749/TCP,8000/UDP                      25h
genctl        keylore                               ClusterIP   172.16.24.66     <none>        8443/TCP,8441/TCP,8444/TCP                                  25h
genctl        keylore-fileshare                     ClusterIP   172.16.15.121    <none>        8445/TCP,8444/TCP,8441/TCP                                  25h
genctl        kmip-controller-service               NodePort    172.16.157.131   <none>        5696:5696/TCP                                               25h
genctl        net-control-cleanup                   ClusterIP   172.16.206.191   <none>        443/TCP                                                     25h
genctl        nginx-ingress                         NodePort    172.16.247.149   <none>        8443:443/TCP                                                25h
genctl        nscon-etcd-cluster                    ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        nscon-etcd-cluster-client             ClusterIP   172.16.100.28    <none>        2379/TCP                                                    25h
genctl        nscon-etcd-cluster-nodeport           NodePort    172.16.118.194   <none>        2379:8379/TCP                                               25h
genctl        nscon-server                          ClusterIP   172.16.50.50     <none>        50050/UDP,50050/TCP,50060/TCP,2112/TCP,2113/TCP             25h
genctl        nscon-server-nodeport                 NodePort    172.16.156.188   <none>        50050:8050/TCP,50060:8060/TCP                               25h
genctl        operator-api-server                   ClusterIP   172.16.156.84    <none>        8443/TCP,8445/TCP                                           25h
genctl        operator-nginx-ingress                NodePort    172.16.187.42    <none>        8443:8443/TCP                                               25h
genctl        ops-extension-server                  ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-extension-server             ClusterIP   None             <none>        <none>                                                      25h
genctl        regional-storage-admin                ClusterIP   None             <none>        <none>                                                      25h
genctl        sdp-monitor-rest-server               ClusterIP   172.16.82.4      <none>        8080/TCP                                                    25h
genctl        server-node-controller                ClusterIP   172.16.145.239   <none>        8443/TCP                                                    25h
genctl        server-scheduler                      ClusterIP   172.16.254.5     <none>        8888/TCP                                                    25h
genctl        smartnic-store                        ClusterIP   172.16.80.39     <none>        443/TCP                                                     25h
genctl        sysman-etcd-cluster                   ClusterIP   None             <none>        2379/TCP,2380/TCP                                           25h
genctl        sysman-etcd-cluster-client            ClusterIP   172.16.37.219    <none>        2379/TCP                                                    25h
genctl        vm-instance-controller                ClusterIP   172.16.207.12    <none>        8888/TCP                                                    25h
genctl        vm-scheduler                          ClusterIP   172.16.110.103   <none>        8888/TCP                                                    25h
kube-system   kube-dns                              ClusterIP   172.16.0.10      <none>        53/UDP,53/TCP,9153/TCP                                      25h
genctl        fluentbit-logs-6jfhd                                              4/4     Running     0             25h     11.51.34.4     dal1-qz2-sr2-rk204-s34   <none>           <none>
genctl        fluentd-qradar-ds-h49kn                                           1/1     Running     0             25h     11.51.34.3     dal1-qz2-sr2-rk204-s34   <none>           <none>
kube-system   kube-proxy-nph4n                                                  1/1     Running     0             25h     10.22.64.86    dal1-qz2-sr2-rk204-s34   <none>           <none>
Client Version: v1.29.9
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
Server Version: v1.29.9

<b>############ apparmor profile listing ##############</b>

apparmor module is loaded.
47 profiles are loaded.
30 profiles are in enforce mode.
   /etc/hostos-monitoring/plugins.d/configuration-monitoring
   /etc/hostos-monitoring/plugins.d/ipset-monitoring
   /etc/hostos-monitoring/plugins.d/iptables-monitoring
   /etc/hostos-monitoring/plugins.d/liveness
   /etc/hostos-monitoring/plugins.d/smartnic-monitoring
   /usr/bin/prometheus-node-exporter
   /usr/lib/NetworkManager/nm-dhcp-client.action
   /usr/lib/NetworkManager/nm-dhcp-helper
   /usr/lib/connman/scripts/dhclient-script
   /usr/sbin/dropbear
   /usr/sbin/hostos-monitoring
   /usr/sbin/sshd
   /usr/sbin/sshd//DEFAULT
   /usr/sbin/sshd//root
   /usr/sbin/sshd//sysop
   /{,usr/}sbin/dhclient
   cri-containerd.apparmor.d
   fluent-bit-logs
   fluentbit-logs
   genctl-ingress-controller
   libvirtd
   libvirtd//qemu_bridge_helper
   lsb_release
   nvidia_modprobe
   nvidia_modprobe//kmod
   sysdig-agent
   sysdig-agent-kmodule
   sysdig-agent-kmodule//ln_profile
   tcpdump
   virt-aa-helper
17 profiles are in complain mode.
   /usr/lib/frr/bgpd
   /usr/lib/frr/staticd
   /usr/lib/frr/watchfrr
   /usr/lib/frr/zebra
   /usr/local/fabcon/fabcon_server
   /usr/local/iobricks/bessctl/bessctl
   /usr/local/iobricks/iobricksd
   /usr/local/iobricks/monitor/monitor
   /usr/local/iobricks/monitor/monitor_datapath
   /usr/local/iobricks/monitor/monitor_fmt
   /usr/local/iobricks/monitor/monitor_vpe_enable
   /usr/local/skydive/skydive
   /usr/sbin/mlx-setup.sh
   confined_user
   docker-extended
   fluentd-logs
   fluentd-qradar
0 profiles are in kill mode.
0 profiles are in unconfined mode.
22 processes have profiles defined.
13 processes are in enforce mode.
   /usr/bin/prometheus-node-exporter (1182056) 
   /usr/sbin/sshd (1189855) 
   /usr/sbin/sshd (682709) /usr/sbin/sshd//sysop
   /usr/sbin/sshd (682721) /usr/sbin/sshd//sysop
   /usr/sbin/dhclient (3378637) /{,usr/}sbin/dhclient
   /usr/bin/ruby (1372194) cri-containerd.apparmor.d
   /usr/bin/ruby (1372241) cri-containerd.apparmor.d
   /usr/bin/dash (1373965) cri-containerd.apparmor.d
   /usr/bin/vault (1373980) cri-containerd.apparmor.d
   /bin/ssf-validator-fluentbit (1374011) cri-containerd.apparmor.d
   /fluent-bit/bin/fluent-bit (1374081) cri-containerd.apparmor.d
   /synthetics/datagen (1374130) cri-containerd.apparmor.d
   /usr/sbin/libvirtd (1179349) libvirtd
9 processes are in complain mode.
   /usr/lib/frr/bgpd (88735) 
   /usr/lib/frr/staticd (88742) 
   /usr/lib/frr/watchfrr (88717) 
   /usr/lib/frr/zebra (88730) 
   /usr/local/fabcon/fabcon_server (1184052) 
   /usr/local/iobricks/iobricksd (340363) 
   /usr/local/skydive/skydive (338670) 
   /usr/local/skydive/skydive (338700) 
   /usr/local/skydive/skydive (338811) 
0 processes are unconfined but have a profile defined.
0 processes are in mixed mode.
0 processes are in kill mode.
'
<i>2024-12-17 17:36:56.324258</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cur_dir :Verify current directory command</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.440259</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.440246</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.440253</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:56.440256</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.440276</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - pwd
<i>2024-12-17 17:36:56.440956</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/home/sysop
'
<i>2024-12-17 17:36:56.440993</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_node_personality :Verify if node personality/ies is/are valid</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:56.441082</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.441058</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.441077</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:56.441080</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.441106</i> <b style="color:rgb(0 133 115);">[INFO]</b> NODE ROLES {'observability'}
<i>2024-12-17 17:36:56.441125</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_apparmor_profiles_json :Verify if appropriate apparmor profiles with correct statuses are in place - using json report</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.685709</td>
    <td>0.2</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.685697</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.685703</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:56.685706</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.685727</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.685743</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:56.685759</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:56.685762</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml for test validation
<i>2024-12-17 17:36:56.718473</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.718514</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:56.882495</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
	"version":	"2",
	"profiles":	{
		"/etc/hostos-monitoring/plugins.d/configuration-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/ipset-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/iptables-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/liveness":	"enforce",
		"/etc/hostos-monitoring/plugins.d/smartnic-monitoring":	"enforce",
		"/usr/bin/prometheus-node-exporter":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-client.action":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-helper":	"enforce",
		"/usr/lib/connman/scripts/dhclient-script":	"enforce",
		"/usr/sbin/dropbear":	"enforce",
		"/usr/sbin/hostos-monitoring":	"enforce",
		"/usr/sbin/sshd":	"enforce",
		"/usr/sbin/sshd//DEFAULT":	"enforce",
		"/usr/sbin/sshd//root":	"enforce",
		"/usr/sbin/sshd//sysop":	"enforce",
		"/{,usr/}sbin/dhclient":	"enforce",
		"cri-containerd.apparmor.d":	"enforce",
		"fluent-bit-logs":	"enforce",
		"fluentbit-logs":	"enforce",
		"genctl-ingress-controller":	"enforce",
		"libvirtd":	"enforce",
		"libvirtd//qemu_bridge_helper":	"enforce",
		"lsb_release":	"enforce",
		"nvidia_modprobe":	"enforce",
		"nvidia_modprobe//kmod":	"enforce",
		"sysdig-agent":	"enforce",
		"sysdig-agent-kmodule":	"enforce",
		"sysdig-agent-kmodule//ln_profile":	"enforce",
		"tcpdump":	"enforce",
		"virt-aa-helper":	"enforce",
		"/usr/lib/frr/bgpd":	"complain",
		"/usr/lib/frr/staticd":	"complain",
		"/usr/lib/frr/watchfrr":	"complain",
		"/usr/lib/frr/zebra":	"complain",
		"/usr/local/fabcon/fabcon_server":	"complain",
		"/usr/local/iobricks/bessctl/bessctl":	"complain",
		"/usr/local/iobricks/iobricksd":	"complain",
		"/usr/local/iobricks/monitor/monitor":	"complain",
		"/usr/local/iobricks/monitor/monitor_datapath":	"complain",
		"/usr/local/iobricks/monitor/monitor_fmt":	"complain",
		"/usr/local/iobricks/monitor/monitor_vpe_enable":	"complain",
		"/usr/local/skydive/skydive":	"complain",
		"/usr/sbin/mlx-setup.sh":	"complain",
		"confined_user":	"complain",
		"docker-extended":	"complain",
		"fluentd-logs":	"complain",
		"fluentd-qradar":	"complain"
	},
	"processes":	{
		"/bin/ssf-validator-fluentbit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1374011",
				"status":	"enforce"
			}],
		"/fluent-bit/bin/fluent-bit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1374081",
				"status":	"enforce"
			}],
		"/synthetics/datagen":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1374130",
				"status":	"enforce"
			}],
		"/usr/bin/dash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1373965",
				"status":	"enforce"
			}],
		"/usr/bin/prometheus-node-exporter":	[{
				"profile":	"/usr/bin/prometheus-node-exporter",
				"pid":	"1182056",
				"status":	"enforce"
			}],
		"/usr/bin/ruby":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1372194",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1372241",
				"status":	"enforce"
			}],
		"/usr/bin/vault":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1373980",
				"status":	"enforce"
			}],
		"/usr/sbin/dhclient":	[{
				"profile":	"/{,usr/}sbin/dhclient",
				"pid":	"3378637",
				"status":	"enforce"
			}],
		"/usr/sbin/libvirtd":	[{
				"profile":	"libvirtd",
				"pid":	"1179349",
				"status":	"enforce"
			}],
		"/usr/sbin/sshd":	[{
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"682709",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"682721",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd",
				"pid":	"1189855",
				"status":	"enforce"
			}],
		"/usr/lib/frr/bgpd":	[{
				"profile":	"/usr/lib/frr/bgpd",
				"pid":	"88735",
				"status":	"complain"
			}],
		"/usr/lib/frr/staticd":	[{
				"profile":	"/usr/lib/frr/staticd",
				"pid":	"88742",
				"status":	"complain"
			}],
		"/usr/lib/frr/watchfrr":	[{
				"profile":	"/usr/lib/frr/watchfrr",
				"pid":	"88717",
				"status":	"complain"
			}],
		"/usr/lib/frr/zebra":	[{
				"profile":	"/usr/lib/frr/zebra",
				"pid":	"88730",
				"status":	"complain"
			}],
		"/usr/local/fabcon/fabcon_server":	[{
				"profile":	"/usr/local/fabcon/fabcon_server",
				"pid":	"1184052",
				"status":	"complain"
			}],
		"/usr/local/iobricks/iobricksd":	[{
				"profile":	"/usr/local/iobricks/iobricksd",
				"pid":	"340363",
				"status":	"complain"
			}],
		"/usr/local/skydive/skydive":	[{
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"338670",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"338700",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"338811",
				"status":	"complain"
			}]
	}
}
'
<i>2024-12-17 17:36:56.888672</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 845, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 1226, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1637 chars]e"}}' != '{"pr[333 chars]", "/usr/bin/prometheus-node-exporter": "enfor[1584 chars]e"}}'
Diff is 4397 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:56.888755</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_restart_apparmor :Restart apparmor services and run the apparmor tests again</td>
    <td class='failed status'>failed</td>
    <td>2024-12-17 17:36:56.888856</td>
    <td>0.27</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:56.888846</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:56.888851</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:56.888853</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:56.888874</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart apparmor
<i>2024-12-17 17:36:56.954761</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:56.954774</i> <b style="color:rgb(0 133 115);">[INFO]</b> apparmor restart serive successful!
<i>2024-12-17 17:36:56.954778</i> <b style="color:rgb(0 133 115);">[INFO]</b> Checking for all profiles and expected statuses
<i>2024-12-17 17:36:56.954801</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:56.954822</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/apparmor/apparmor_profiles_release_6.yml : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml
<i>2024-12-17 17:36:56.954825</i> <b style="color:rgb(0 133 115);">[INFO]</b> Using manifest /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/apparmor/apparmor_profiles_release_6.yml for test validation
<i>2024-12-17 17:36:56.985710</i> <b style="color:rgb(0 133 115);">[INFO]</b> KUBE BUNDLES FOUND ON NODE
<i>2024-12-17 17:36:56.985752</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - sudo aa-status --pretty-json
<i>2024-12-17 17:36:57.154535</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'{
	"version":	"2",
	"profiles":	{
		"/etc/hostos-monitoring/plugins.d/configuration-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/ipset-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/iptables-monitoring":	"enforce",
		"/etc/hostos-monitoring/plugins.d/liveness":	"enforce",
		"/etc/hostos-monitoring/plugins.d/smartnic-monitoring":	"enforce",
		"/usr/bin/prometheus-node-exporter":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-client.action":	"enforce",
		"/usr/lib/NetworkManager/nm-dhcp-helper":	"enforce",
		"/usr/lib/connman/scripts/dhclient-script":	"enforce",
		"/usr/sbin/dropbear":	"enforce",
		"/usr/sbin/hostos-monitoring":	"enforce",
		"/usr/sbin/sshd":	"enforce",
		"/usr/sbin/sshd//DEFAULT":	"enforce",
		"/usr/sbin/sshd//root":	"enforce",
		"/usr/sbin/sshd//sysop":	"enforce",
		"/{,usr/}sbin/dhclient":	"enforce",
		"cri-containerd.apparmor.d":	"enforce",
		"fluent-bit-logs":	"enforce",
		"fluentbit-logs":	"enforce",
		"genctl-ingress-controller":	"enforce",
		"libvirtd":	"enforce",
		"libvirtd//qemu_bridge_helper":	"enforce",
		"lsb_release":	"enforce",
		"nvidia_modprobe":	"enforce",
		"nvidia_modprobe//kmod":	"enforce",
		"sysdig-agent":	"enforce",
		"sysdig-agent-kmodule":	"enforce",
		"sysdig-agent-kmodule//ln_profile":	"enforce",
		"tcpdump":	"enforce",
		"virt-aa-helper":	"enforce",
		"/usr/lib/frr/bgpd":	"complain",
		"/usr/lib/frr/staticd":	"complain",
		"/usr/lib/frr/watchfrr":	"complain",
		"/usr/lib/frr/zebra":	"complain",
		"/usr/local/fabcon/fabcon_server":	"complain",
		"/usr/local/iobricks/bessctl/bessctl":	"complain",
		"/usr/local/iobricks/iobricksd":	"complain",
		"/usr/local/iobricks/monitor/monitor":	"complain",
		"/usr/local/iobricks/monitor/monitor_datapath":	"complain",
		"/usr/local/iobricks/monitor/monitor_fmt":	"complain",
		"/usr/local/iobricks/monitor/monitor_vpe_enable":	"complain",
		"/usr/local/skydive/skydive":	"complain",
		"/usr/sbin/mlx-setup.sh":	"complain",
		"confined_user":	"complain",
		"docker-extended":	"complain",
		"fluentd-logs":	"complain",
		"fluentd-qradar":	"complain"
	},
	"processes":	{
		"/bin/ssf-validator-fluentbit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1374011",
				"status":	"enforce"
			}],
		"/fluent-bit/bin/fluent-bit":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1374081",
				"status":	"enforce"
			}],
		"/synthetics/datagen":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1374130",
				"status":	"enforce"
			}],
		"/usr/bin/dash":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1373965",
				"status":	"enforce"
			}],
		"/usr/bin/prometheus-node-exporter":	[{
				"profile":	"/usr/bin/prometheus-node-exporter",
				"pid":	"1182056",
				"status":	"enforce"
			}],
		"/usr/bin/ruby":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1372194",
				"status":	"enforce"
			}, {
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1372241",
				"status":	"enforce"
			}],
		"/usr/bin/vault":	[{
				"profile":	"cri-containerd.apparmor.d",
				"pid":	"1373980",
				"status":	"enforce"
			}],
		"/usr/sbin/dhclient":	[{
				"profile":	"/{,usr/}sbin/dhclient",
				"pid":	"3378637",
				"status":	"enforce"
			}],
		"/usr/sbin/libvirtd":	[{
				"profile":	"libvirtd",
				"pid":	"1179349",
				"status":	"enforce"
			}],
		"/usr/sbin/sshd":	[{
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"682709",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd//sysop",
				"pid":	"682721",
				"status":	"enforce"
			}, {
				"profile":	"/usr/sbin/sshd",
				"pid":	"1189855",
				"status":	"enforce"
			}],
		"/usr/lib/frr/bgpd":	[{
				"profile":	"/usr/lib/frr/bgpd",
				"pid":	"88735",
				"status":	"complain"
			}],
		"/usr/lib/frr/staticd":	[{
				"profile":	"/usr/lib/frr/staticd",
				"pid":	"88742",
				"status":	"complain"
			}],
		"/usr/lib/frr/watchfrr":	[{
				"profile":	"/usr/lib/frr/watchfrr",
				"pid":	"88717",
				"status":	"complain"
			}],
		"/usr/lib/frr/zebra":	[{
				"profile":	"/usr/lib/frr/zebra",
				"pid":	"88730",
				"status":	"complain"
			}],
		"/usr/local/fabcon/fabcon_server":	[{
				"profile":	"/usr/local/fabcon/fabcon_server",
				"pid":	"1184052",
				"status":	"complain"
			}],
		"/usr/local/iobricks/iobricksd":	[{
				"profile":	"/usr/local/iobricks/iobricksd",
				"pid":	"340363",
				"status":	"complain"
			}],
		"/usr/local/skydive/skydive":	[{
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"338670",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"338700",
				"status":	"complain"
			}, {
				"profile":	"/usr/local/skydive/skydive",
				"pid":	"338811",
				"status":	"complain"
			}]
	}
}
'
<i>2024-12-17 17:36:57.159983</i> <b style="color:rgb(231 29 50);">[ERROR]</b> Traceback (most recent call last):
  File "/home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/basetest.py", line 218, in assertEqual
    super().assertEqual(first=first, second=second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 845, in assertEqual
    assertion_func(first, second, msg=msg)
  File "/usr/lib/python3.10/unittest/case.py", line 1226, in assertMultiLineEqual
    self.fail(self._formatMessage(msg, standardMsg))
  File "/usr/lib/python3.10/unittest/case.py", line 675, in fail
    raise self.failureException(msg)
AssertionError: '{"pr[333 chars]", "/opt/Tanium/TaniumClient/TaniumClient": "c[1637 chars]e"}}' != '{"pr[333 chars]", "/usr/bin/prometheus-node-exporter": "enfor[1584 chars]e"}}'
Diff is 4397 characters long. Set self.maxDiff to None to see it. : 
<b>Observed the following discrepancies</b>:
<b style="color:Tomato;">Missing profiles:</b>
/opt/Tanium/TaniumClient/TaniumClient
<b style="color:Orange;">Unidentified Profiles:</b>

<b style="color:rgb(239, 193, 0);">Mismatching Profiles:</b>



<i>2024-12-17 17:36:57.160063</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_groupprofile_diff :Verify if group profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.284294</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.284282</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.284289</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:57.284291</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.284323</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.284339</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.331957</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/group  | awk -F: '{print $1}'
<i>2024-12-17 17:36:57.334247</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root
daemon
bin
sys
adm
tty
disk
lp
mail
news
uucp
man
proxy
kmem
dialout
fax
voice
cdrom
floppy
tape
sudo
audio
dip
www-data
backup
operator
list
irc
src
gnats
shadow
utmp
video
sasl
plugdev
staff
games
users
nogroup
systemd-journal
systemd-network
systemd-resolve
messagebus
systemd-timesync
input
sgx
kvm
render
lxd
tss
_ssh
fwupd-refresh
admin
netdev
syslog
sysop
crontab
nslcd
tcpdump
_lldpd
rdma
libvirt
libvirt-qemu
libvirt-dnsmasq
swtpm
ssl-cert
postfix
postdrop
frrvty
frr
vault
host-logging
prometheus
docker
sugroup
sysgt
no_user
'
<i>2024-12-17 17:36:57.334314</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_userprofile_diff :Verify if user profiles on all nodes match the records in the baseline file</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.334393</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.334384</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.334388</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:57.334391</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.334420</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.334437</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/users_groups_data/profile_data_6.yml : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/users_groups_data/profile_data_6.yml
<i>2024-12-17 17:36:57.379294</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /etc/passwd | cut -d':' -f1,5-
<i>2024-12-17 17:36:57.381084</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'root:root:/root:/bin/bash
daemon:daemon:/usr/sbin:/usr/sbin/nologin
bin:bin:/bin:/usr/sbin/nologin
sys:sys:/dev:/usr/sbin/nologin
sync:sync:/bin:/bin/sync
games:games:/usr/games:/usr/sbin/nologin
man:man:/var/cache/man:/usr/sbin/nologin
lp:lp:/var/spool/lpd:/usr/sbin/nologin
mail:mail:/var/mail:/usr/sbin/nologin
news:news:/var/spool/news:/usr/sbin/nologin
uucp:uucp:/var/spool/uucp:/usr/sbin/nologin
proxy:proxy:/bin:/usr/sbin/nologin
www-data:www-data:/var/www:/usr/sbin/nologin
backup:backup:/var/backups:/usr/sbin/nologin
list:Mailing List Manager:/var/list:/usr/sbin/nologin
irc:ircd:/run/ircd:/usr/sbin/nologin
gnats:Gnats Bug-Reporting System (admin):/var/lib/gnats:/usr/sbin/nologin
nobody:nobody:/nonexistent:/usr/sbin/nologin
_apt::/nonexistent:/usr/sbin/nologin
systemd-network:systemd Network Management,,,:/run/systemd:/usr/sbin/nologin
systemd-resolve:systemd Resolver,,,:/run/systemd:/usr/sbin/nologin
messagebus::/nonexistent:/usr/sbin/nologin
systemd-timesync:systemd Time Synchronization,,,:/run/systemd:/usr/sbin/nologin
tss:TPM software stack,,,:/var/lib/tpm:/bin/false
sshd::/run/sshd:/usr/sbin/nologin
fwupd-refresh:fwupd-refresh user,,,:/run/systemd:/usr/sbin/nologin
syslog::/home/syslog:/usr/sbin/nologin
sysop::/home/sysop:/bin/bash
nslcd:nslcd name service LDAP connection daemon,,,:/run/nslcd:/usr/sbin/nologin
tcpdump::/nonexistent:/usr/sbin/nologin
_lldpd::/run/lldpd:/usr/sbin/nologin
libvirt-qemu:Libvirt Qemu,,,:/var/lib/libvirt:/usr/sbin/nologin
libvirt-dnsmasq:Libvirt Dnsmasq,,,:/var/lib/libvirt/dnsmasq:/usr/sbin/nologin
swtpm:virtual TPM software stack,,,:/var/lib/swtpm:/bin/false
postfix::/var/spool/postfix:/usr/sbin/nologin
_rpc::/run/rpcbind:/usr/sbin/nologin
statd::/var/lib/nfs:/usr/sbin/nologin
frr:Frr routing suite,,,:/nonexistent:/usr/sbin/nologin
vault::/home/vault:/bin/false
host-logging:Logging account:/home/host-logging:/usr/sbin/nologin
prometheus:Prometheus daemon,,,:/var/lib/prometheus:/usr/sbin/nologin
sysgt::/home/sysgt:/bin/bash
genctl::/home/genctl:/usr/sbin/nologin
no_user:HostOS user for special UID so LDAP will treat as local user:/home/no_user:/usr/sbin/nologin
'
<i>2024-12-17 17:36:57.381179</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_cron_diff :verify if the cron files from node matches the baseline files</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.494569</td>
    <td>0.32</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.494554</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.494562</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:57.494566</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.494631</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.494706</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.494723</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.monthly : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.monthly
<i>2024-12-17 17:36:57.494835</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.494849</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.hourly : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.hourly
<i>2024-12-17 17:36:57.495948</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.495965</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.allow : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.allow
<i>2024-12-17 17:36:57.496055</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.496068</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.496081</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.weekly : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.weekly
<i>2024-12-17 17:36:57.496143</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.496155</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/release6 : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/release6
<i>2024-12-17 17:36:57.496287</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.496299</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.daily : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.daily
<i>2024-12-17 17:36:57.497269</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.497285</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data/cron.d : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data/cron.d
<i>2024-12-17 17:36:57.497534</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_data : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_data
<i>2024-12-17 17:36:57.812358</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - ls -l /tmp/baseline_data
<i>2024-12-17 17:36:57.814360</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'total 4
-rw-r----- 1 root root    0 Dec 17 17:36 cron.allow
drwxr-x--- 2 root root   80 Dec 17 17:36 cron.d
drwxr-x--- 2 root root  260 Dec 17 17:36 cron.daily
drwxr-x--- 2 root root  200 Dec 17 17:36 cron.hourly
drwxr-x--- 2 root root   40 Dec 17 17:36 cron.monthly
drwxr-x--- 2 root root   40 Dec 17 17:36 cron.weekly
-rw-r----- 1 root root 1229 Dec 17 17:36 crontab
'
<i>2024-12-17 17:36:57.814371</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - diff -dr --suppress-common-lines -y -EZbwB /tmp/node_data /tmp/baseline_data
<i>2024-12-17 17:36:57.817319</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.817331</i> <b style="color:rgb(0 133 115);">[INFO]</b> No Difference found in baseline and node data for cron jobs
<i>2024-12-17 17:36:57.817346</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_crontab_diff :verify if the crontab data for each node matches the baseline</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.817441</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.817431</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.817436</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:57.817438</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.817456</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l
<i>2024-12-17 17:36:57.819316</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'* * * * * /opt/cron/pause_restore.sh 2>&1 | logger
'
<i>2024-12-17 17:36:57.819324</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - crontab -l > /tmp/crontab_data
<i>2024-12-17 17:36:57.821013</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.821040</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/crontab_data/release6/observability : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/crontab_data/release6/observability
<i>2024-12-17 17:36:57.821059</i> <b style="color:rgb(0 133 115);">[INFO]</b> shell_artifacts/cronjobs/crontab_data/release6/observability personality folder not present for comparison
<i>2024-12-17 17:36:57.821070</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_validate_cron_service :verify if the cron service after restart has no errors and is running successfully</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:36:57.821155</td>
    <td>7.24</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:36:57.821146</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:36:57.821151</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:36:57.821153</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:36:57.821187</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cp /etc/crontab /etc/crontab_bkp
<i>2024-12-17 17:36:57.823153</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.823161</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - echo -n "* * * * * root echo "Sample scheduled task" 
 " >> /etc/crontab
<i>2024-12-17 17:36:57.823818</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:57.823825</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:36:59.839629</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:36:59.839659</i> <b style="color:rgb(0 133 115);">[INFO]</b> restart successful , no error found
<i>2024-12-17 17:36:59.839693</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/cronjobs/cron_service_verify.sh : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.839697</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:36:59.839701</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/cronjobs/cron_service_verify.sh
<i>2024-12-17 17:37:03.039193</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'checking crontab
.
good
'
<i>2024-12-17 17:37:03.039219</i> <b style="color:rgb(0 133 115);">[INFO]</b> Crontab status healthy
<i>2024-12-17 17:37:03.039226</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - mv /etc/crontab_bkp /etc/crontab
<i>2024-12-17 17:37:03.041493</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:03.041508</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - systemctl restart cron;sleep 2;systemctl status cron --no-pager |grep -i error
<i>2024-12-17 17:37:05.056694</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b''
<i>2024-12-17 17:37:05.056803</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_collect_info :Collect information for Security Agent</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.175568</td>
    <td>0.18</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.175555</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.175562</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:37:05.175565</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.175601</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/securityagent/nessus_info_collector.sh : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.175604</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.175607</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/securityagent/nessus_info_collector.sh
<i>2024-12-17 17:37:05.357701</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Get the nessus status ##############</b>

Linked to: nmnode2-03-cse.sos.ibm.com:8834
'
<i>2024-12-17 17:37:05.357815</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password :Check if there is a password for sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.468442</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.468429</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.468437</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:37:05.468439</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.468473</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysgt : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.468477</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.468480</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysgt
<i>2024-12-17 17:37:05.516613</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysgt password ##############</b>

sysgt:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.516713</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password :Check if there is a password for sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.516824</td>
    <td>0.05</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.516813</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.516818</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:37:05.516821</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.516867</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/userpassword_check/user_password_check.sh sysop : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.516870</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.516873</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/userpassword_check/user_password_check.sh sysop
<i>2024-12-17 17:37:05.562610</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'
<b>############ Check sysop password ##############</b>

sysop:!:20073:1::7:::
'
<i>2024-12-17 17:37:05.562705</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_root_password_expiry :Verify password and account expiry for a user root</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.673872</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.673859</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.673866</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:37:05.673869</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.673905</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.673909</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.673912</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh root
<i>2024-12-17 17:37:05.679900</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for root##############</b>
'
<i>2024-12-17 17:37:05.679955</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysgt_password_expiry :Verify password and account expiry for a user sysgt</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.680040</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.680029</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.680035</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:37:05.680037</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.680067</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.680070</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.680073</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysgt
<i>2024-12-17 17:37:05.685531</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysgt##############</b>
'
<i>2024-12-17 17:37:05.685578</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_password_expiry :Verify password and account expiry for a user sysop</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.685650</td>
    <td>0.01</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.685641</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.685645</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:37:05.685648</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.685677</i> <b style="color:rgb(0 133 115);">[INFO]</b> Absolute Path to file -
shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop : /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.685681</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Script - /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.685684</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - bash /home/sysop/nextgen_1734457014290_515/hostos-validate_1.0.0-e5d742db_all/share/shell_artifacts/passwd_expiry_check/passwd_expiry_verify.sh sysop
<i>2024-12-17 17:37:05.691005</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'<b>############ Bootstrap account settings info for sysop##############</b>
'
<i>2024-12-17 17:37:05.691054</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>

<tr>
    <td><i onclick="toggleRow(this)" class="fa fa-plus add-btn"></i>test_sysop_ssh_login :Verify is sysop login happens from ssh key</td>
    <td class='passed status'>passed</td>
    <td>2024-12-17 17:37:05.800720</td>
    <td>0.0</td>
    <td>dal1-qz2-sr2-rk204-s34 (observability)</td>
    <td>Ubuntu-22.04.4-LTS-(Jammy-Jellyfish), Kernel: 5.15.0-1057-ibm-gt
</td>
    <td class='expanded-row-content hide-row'><i>2024-12-17 17:37:05.800707</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Platform:</b> Ubuntu-22.04.4-LTS-(Jammy-Jellyfish)
<i>2024-12-17 17:37:05.800714</i> <b style="color:rgb(0 133 115);">[INFO]</b> <b>Installed Release Bundles:</b>
hostos-boot-release:6.3.3-20240530T201009Z_619216f (Dec 16 2024 06:53:53 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 06:54:11 UTC, STATUS=success, EXPANSION=False)

hostos-base-os-sw-release:6.5.5-20241202T143329Z_dc85a86 (Dec 16 2024 06:56:42 UTC, STATUS=success)

hostos-base-net-sw-release:6.14.44-20241211T074932Z_1b617343 (Dec 16 2024 07:03:13 UTC, STATUS=success)

hostos-nextgen-os-sw-release:6.2.1-20241125T082238Z_5743bdd (Dec 16 2024 14:47:36 UTC, STATUS=success)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 14:54:43 UTC, STATUS=success, EXPANSION=False)

hostos-config-release:6.6.6-20241115T002642Z_09bc8fc (Dec 16 2024 15:44:05 UTC, STATUS=success, EXPANSION=True)

etcd-base-release:16.0.1_20241120T221203Z_1c5386c (Dec 16 2024 15:50:58 UTC)

kube-base-release:16.0.3_20241211T144954Z_0fba0f4 (Dec 16 2024 15:51:57 UTC)

kube-define-release:16.0.0_20241011T205327Z_b0169fa (Dec 16 2024 16:03:26 UTC)

kube-addon-release:16.0.0_20241011T205239Z_afc9669 (Dec 16 2024 16:04:48 UTC)

hostos-base-os-sw-release:6.5.6-20241216T171927Z_1857723 (Dec 17 2024 05:08:42 UTC, STATUS=success)

hostos-base-os-sw-release:6.5.6-20241217T130833Z_ab63835 (Dec 17 2024 13:34:06 UTC, STATUS=success)

<i>2024-12-17 17:37:05.800717</i> <b style="color:rgb(0 133 115);">[INFO]</b> In setUp
<i>2024-12-17 17:37:05.800739</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - env | grep SSH_USER_AUTH | awk -F"=" {'print $2'}
<i>2024-12-17 17:37:05.803174</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'/tmp/sshauth.XXXXXXXXXoIP9O2
'
<i>2024-12-17 17:37:05.803184</i> <b style="color:rgb(0 133 115);">[INFO]</b> Executing Command - cat /tmp/sshauth.XXXXXXXXXoIP9O2 | grep "publickey ssh-rsa"
<i>2024-12-17 17:37:05.805132</i> <b style="color:rgb(0 133 115);">[INFO]</b> Command output -
b'publickey ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQCwPAtWF4ExYdN3/LFcm6FDJLKc1XQU312COUdnOBMaT/03t5itzX2YNmPTyYKaWsVXIm+EOTwJIX45ykxVoYBU8Vvze0aFp8BE7HZjrVsW1gtOty+h/nkd1S1uLrVCHVPoMaFCOE9IjlCcnka6hyx+vugHV7DDX8dX4dOoTKEdN5/HsEgMHWhs7ZquT5nbQknuD5dMEWSybW/u75QFvRQ3ADpwBhm0/m20a8aCem26aLdWLic1ZvosgtJ/xVrHZyiNOzAGBXnfwe/eTbBvbZgeaiL+5sSN6KdewqB2VYbQg6qWgVW9XFhsWO3qU8MT5RPah6zjsU7iiexDo3KXbMu/
'
<i>2024-12-17 17:37:05.805174</i> <b style="color:rgb(0 133 115);">[INFO]</b> In tearDown</td>
</tr>
</table>